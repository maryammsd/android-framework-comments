{
  "filePath" : "/home/maryam/clearblue/files/android-source-35/android/speech/RecognizerIntent.java",
  "packageName" : "android.speech",
  "className" : "RecognizerIntent",
  "comment" : "\n * Constants for supporting speech recognition through starting an {@link Intent}\n ",
  "links" : [ "android.content.Intent" ],
  "variables" : [ {
    "name" : "ACTION_RECOGNIZE_SPEECH",
    "type" : "String",
    "comment" : "\n     * Starts an activity that will prompt the user for speech and send it through a\n     * speech recognizer.  The results will be returned via activity results (in\n     * {@link Activity#onActivityResult}, if you start the intent using\n     * {@link Activity#startActivityForResult(Intent, int)}), or forwarded via a PendingIntent\n     * if one is provided.\n     *\n     * <p>Starting this intent with just {@link Activity#startActivity(Intent)} is not supported.\n     * You must either use {@link Activity#startActivityForResult(Intent, int)}, or provide a\n     * PendingIntent, to receive recognition results.\n     *\n     * <p>The implementation of this API is likely to stream audio to remote servers to perform\n     * speech recognition which can use a substantial amount of bandwidth.\n     *\n     * <p>Required extras:\n     * <ul>\n     *   <li>{@link #EXTRA_LANGUAGE_MODEL}\n     * </ul>\n     *\n     * <p>Optional extras:\n     * <ul>\n     *   <li>{@link #EXTRA_PROMPT}\n     *   <li>{@link #EXTRA_LANGUAGE}\n     *   <li>{@link #EXTRA_MAX_RESULTS}\n     *   <li>{@link #EXTRA_RESULTS_PENDINGINTENT}\n     *   <li>{@link #EXTRA_RESULTS_PENDINGINTENT_BUNDLE}\n     * </ul>\n     *\n     * <p> Result extras (returned in the result, not to be specified in the request):\n     * <ul>\n     *   <li>{@link #EXTRA_RESULTS}\n     * </ul>\n     *\n     * <p>NOTE: There may not be any applications installed to handle this action, so you should\n     * make sure to catch {@link ActivityNotFoundException}.\n     ",
    "links" : [ "#EXTRA_LANGUAGE_MODEL", "#EXTRA_PROMPT", "android.app.Activity#startActivityForResult(Intent", "#EXTRA_RESULTS_PENDINGINTENT", "android.app.Activity#startActivity(Intent)", "android.content.ActivityNotFoundException", "android.app.Activity#onActivityResult", "#EXTRA_RESULTS_PENDINGINTENT_BUNDLE", "#EXTRA_LANGUAGE", "#EXTRA_MAX_RESULTS", "#EXTRA_RESULTS" ]
  }, {
    "name" : "ACTION_WEB_SEARCH",
    "type" : "String",
    "comment" : "\n     * Starts an activity that will prompt the user for speech, send it through a\n     * speech recognizer, and either display a web search result or trigger\n     * another type of action based on the user's speech.\n     *\n     * <p>If you want to avoid triggering any type of action besides web search, you can use\n     * the {@link #EXTRA_WEB_SEARCH_ONLY} extra.\n     *\n     * <p>Required extras:\n     * <ul>\n     *   <li>{@link #EXTRA_LANGUAGE_MODEL}\n     * </ul>\n     *\n     * <p>Optional extras:\n     * <ul>\n     *   <li>{@link #EXTRA_PROMPT}\n     *   <li>{@link #EXTRA_LANGUAGE}\n     *   <li>{@link #EXTRA_MAX_RESULTS}\n     *   <li>{@link #EXTRA_PARTIAL_RESULTS}\n     *   <li>{@link #EXTRA_WEB_SEARCH_ONLY}\n     *   <li>{@link #EXTRA_ORIGIN}\n     * </ul>\n     *\n     * <p> Result extras (returned in the result, not to be specified in the request):\n     * <ul>\n     *   <li>{@link #EXTRA_RESULTS}\n     *   <li>{@link #EXTRA_CONFIDENCE_SCORES} (optional)\n     * </ul>\n     *\n     * <p>NOTE: There may not be any applications installed to handle this action, so you should\n     * make sure to catch {@link ActivityNotFoundException}.\n     ",
    "links" : [ "#EXTRA_WEB_SEARCH_ONLY", "#EXTRA_LANGUAGE_MODEL", "#EXTRA_PROMPT", "#EXTRA_CONFIDENCE_SCORES", "#EXTRA_ORIGIN", "android.content.ActivityNotFoundException", "#EXTRA_PARTIAL_RESULTS", "#EXTRA_LANGUAGE", "#EXTRA_MAX_RESULTS", "#EXTRA_RESULTS" ]
  }, {
    "name" : "ACTION_VOICE_SEARCH_HANDS_FREE",
    "type" : "String",
    "comment" : "\n     * Starts an activity that will prompt the user for speech without requiring the user's\n     * visual attention or touch input. It will send it through a speech recognizer,\n     * and either synthesize speech for a web search result or trigger\n     * another type of action based on the user's speech.\n     *\n     * This activity may be launched while device is locked in a secure mode.\n     * Special care must be taken to ensure that the voice actions that are performed while\n     * hands free cannot compromise the device's security.\n     * The activity should check the value of the {@link #EXTRA_SECURE} extra to determine\n     * whether the device has been securely locked. If so, the activity should either restrict\n     * the set of voice actions that are permitted or require some form of secure\n     * authentication before proceeding.\n     *\n     * To ensure that the activity's user interface is visible while the lock screen is showing,\n     * the activity should set the\n     * {@link android.view.WindowManager.LayoutParams#FLAG_SHOW_WHEN_LOCKED} window flag.\n     * Otherwise the activity's user interface may be hidden by the lock screen. The activity\n     * should take care not to leak private information when the device is securely locked.\n     *\n     * <p>Optional extras:\n     * <ul>\n     *   <li>{@link #EXTRA_SECURE}\n     * </ul>\n     *\n     * <p class=\"note\">\n     * In some cases, a matching Activity may not exist, so ensure you\n     * safeguard against this.\n     ",
    "links" : [ "#EXTRA_SECURE", "android.view.WindowManager.LayoutParams#FLAG_SHOW_WHEN_LOCKED" ]
  }, {
    "name" : "EXTRA_AUDIO_SOURCE",
    "type" : "String",
    "comment" : "\n     * Optional {@link android.os.ParcelFileDescriptor} pointing to an already opened audio\n     * source for the recognizer to use. The caller of the recognizer is responsible for closing\n     * the audio. If this extra is not set or the recognizer does not support this feature, the\n     * recognizer will open the mic for audio and close it when the recognition is finished.\n     *\n     * <p>Along with this extra, please send {@link #EXTRA_AUDIO_SOURCE_CHANNEL_COUNT},\n     * {@link #EXTRA_AUDIO_SOURCE_ENCODING}, and {@link #EXTRA_AUDIO_SOURCE_SAMPLING_RATE}\n     * extras, otherwise the default values of these extras will be used.\n     *\n     * <p>Additionally, {@link #EXTRA_ENABLE_BIASING_DEVICE_CONTEXT} may have no effect when this\n     * extra is set.\n     *\n     * <p>This can also be used as the string value for {@link #EXTRA_SEGMENTED_SESSION} to\n     * enable segmented session mode. The audio must be passed in using this extra. The\n     * recognition session will end when and only when the audio is closed.\n     *\n     * @see #EXTRA_SEGMENTED_SESSION\n     ",
    "links" : [ "#EXTRA_AUDIO_SOURCE_CHANNEL_COUNT", "android.os.ParcelFileDescriptor", "#EXTRA_AUDIO_SOURCE_ENCODING", "#EXTRA_AUDIO_SOURCE_SAMPLING_RATE", "#EXTRA_SEGMENTED_SESSION", "#EXTRA_ENABLE_BIASING_DEVICE_CONTEXT" ]
  }, {
    "name" : "EXTRA_AUDIO_SOURCE_CHANNEL_COUNT",
    "type" : "String",
    "comment" : "\n     * Optional integer, to be used with {@link #EXTRA_AUDIO_SOURCE}, to indicate the number of\n     * channels in the audio. The default value is 1.\n     ",
    "links" : [ "#EXTRA_AUDIO_SOURCE" ]
  }, {
    "name" : "EXTRA_AUDIO_SOURCE_ENCODING",
    "type" : "String",
    "comment" : "\n     * Optional integer (from {@link android.media.AudioFormat}), to be used with\n     * {@link #EXTRA_AUDIO_SOURCE}, to indicate the audio encoding. The default value is\n     * {@link android.media.AudioFormat#ENCODING_PCM_16BIT}.\n     ",
    "links" : [ "#EXTRA_AUDIO_SOURCE", "android.media.AudioFormat", "android.media.AudioFormat#ENCODING_PCM_16BIT" ]
  }, {
    "name" : "EXTRA_AUDIO_SOURCE_SAMPLING_RATE",
    "type" : "String",
    "comment" : "\n     * Optional integer, to be used with {@link #EXTRA_AUDIO_SOURCE}, to indicate the sampling\n     * rate of the audio. The default value is 16000.\n     ",
    "links" : [ "#EXTRA_AUDIO_SOURCE" ]
  }, {
    "name" : "EXTRA_ENABLE_BIASING_DEVICE_CONTEXT",
    "type" : "String",
    "comment" : "\n     * Optional boolean to enable biasing towards device context. The recognizer will use the\n     * device context to tune the recognition results.\n     *\n     * <p>Depending on the recognizer implementation, this value may have no effect.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_BIASING_STRINGS",
    "type" : "String",
    "comment" : "\n     * Optional list of strings, towards which the recognizer should bias the recognition results.\n     * These are separate from the device context.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_ENABLE_FORMATTING",
    "type" : "String",
    "comment" : "\n     * Optional string to enable text formatting (e.g. unspoken punctuation (examples: question\n     * mark, comma, period, etc.), capitalization, etc.) and specify the optimization strategy.\n     * If set, the partial and final result texts will be formatted. Each result list will\n     * contain two hypotheses in the order of 1) formatted text 2) raw text.\n     *\n     * <p>Depending on the recognizer implementation, this value may have no effect.\n     *\n     * @see #FORMATTING_OPTIMIZE_QUALITY\n     * @see #FORMATTING_OPTIMIZE_LATENCY\n     ",
    "links" : [ ]
  }, {
    "name" : "FORMATTING_OPTIMIZE_QUALITY",
    "type" : "String",
    "comment" : "\n     * Optimizes formatting quality. This will increase latency but provide the highest\n     * punctuation quality. This is a value to use for {@link #EXTRA_ENABLE_FORMATTING}.\n     *\n     * @see #EXTRA_ENABLE_FORMATTING\n     ",
    "links" : [ "#EXTRA_ENABLE_FORMATTING" ]
  }, {
    "name" : "FORMATTING_OPTIMIZE_LATENCY",
    "type" : "String",
    "comment" : "\n     * Optimizes formatting latency. This will result in a slightly lower quality of punctuation\n     * but can improve the experience for real-time use cases. This is a value to use for\n     * {@link #EXTRA_ENABLE_FORMATTING}.\n     *\n     * @see #EXTRA_ENABLE_FORMATTING\n     ",
    "links" : [ "#EXTRA_ENABLE_FORMATTING" ]
  }, {
    "name" : "EXTRA_HIDE_PARTIAL_TRAILING_PUNCTUATION",
    "type" : "String",
    "comment" : "\n     * Optional boolean, to be used with {@link #EXTRA_ENABLE_FORMATTING}, to prevent the\n     * recognizer adding punctuation after the last word of the partial results. The default is\n     * false.\n     ",
    "links" : [ "#EXTRA_ENABLE_FORMATTING" ]
  }, {
    "name" : "EXTRA_MASK_OFFENSIVE_WORDS",
    "type" : "String",
    "comment" : "\n     * Optional boolean indicating whether the recognizer should mask the offensive words in\n     * recognition results. The Default is true.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_CALLING_PACKAGE",
    "type" : "String",
    "comment" : "\n     * The extra key used in an intent to the speech recognizer for voice search. Not\n     * generally to be used by developers. The system search dialog uses this, for example,\n     * to set a calling package for identification by a voice search API. If this extra\n     * is set by anyone but the system process, it should be overridden by the voice search\n     * implementation.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_AUDIO_INJECT_SOURCE",
    "type" : "String",
    "comment" : "\n     * The extra key used in an intent which is providing an already opened audio source for the\n     * RecognitionService to use. Data should be a URI to an audio resource.\n     *\n     * <p>Depending on the recognizer implementation, this value may have no effect.\n     *\n     * @deprecated Replaced with {@link #EXTRA_AUDIO_SOURCE}\n     ",
    "links" : [ "#EXTRA_AUDIO_SOURCE" ]
  }, {
    "name" : "EXTRA_SECURE",
    "type" : "String",
    "comment" : "\n     * Optional boolean to indicate that a \"hands free\" voice search was performed while the device\n     * was in a secure mode. An example of secure mode is when the device's screen lock is active,\n     * and it requires some form of authentication to be unlocked.\n     *\n     * When the device is securely locked, the voice search activity should either restrict\n     * the set of voice actions that are permitted, or require some form of secure authentication\n     * before proceeding.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS",
    "type" : "String",
    "comment" : "\n     * Optional integer to indicate the minimum length of the recognition session. The recognizer\n     * will not stop recognizing speech before this amount of time.\n     *\n     * <p>Note that it is extremely rare you'd want to specify this value in an intent.\n     * Generally, it should be specified only when it is also used as the value for\n     * {@link #EXTRA_SEGMENTED_SESSION} to enable segmented session mode. Note also that certain\n     * values may cause undesired or unexpected results - use judiciously!\n     *\n     * <p>Depending on the recognizer implementation, these values may have no effect.\n     ",
    "links" : [ "#EXTRA_SEGMENTED_SESSION" ]
  }, {
    "name" : "EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS",
    "type" : "String",
    "comment" : "\n     * The amount of time that it should take after the recognizer stops hearing speech to\n     * consider the input complete hence end the recognition session.\n     *\n     * <p>Note that it is extremely rare you'd want to specify this value in an intent.\n     * Generally, it should be specified only when it is also used as the value for\n     * {@link #EXTRA_SEGMENTED_SESSION} to enable segmented session mode. Note also that certain\n     * values may cause undesired or unexpected results - use judiciously!\n     *\n     * <p>Depending on the recognizer implementation, these values may have no effect.\n     ",
    "links" : [ "#EXTRA_SEGMENTED_SESSION" ]
  }, {
    "name" : "EXTRA_SPEECH_INPUT_POSSIBLY_COMPLETE_SILENCE_LENGTH_MILLIS",
    "type" : "String",
    "comment" : "\n     * The amount of time that it should take after we stop hearing speech to consider the input\n     * possibly complete. This is used to prevent the endpointer cutting off during very short\n     * mid-speech pauses.\n     *\n     * Note that it is extremely rare you'd want to specify this value in an intent. If\n     * you don't have a very good reason to change these, you should leave them as they are. Note\n     * also that certain values may cause undesired or unexpected results - use judiciously!\n     * Additionally, depending on the recognizer implementation, these values may have no effect.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_LANGUAGE_MODEL",
    "type" : "String",
    "comment" : "\n     * Informs the recognizer which speech model to prefer when performing\n     * {@link #ACTION_RECOGNIZE_SPEECH}. The recognizer uses this\n     * information to fine tune the results. This extra is required. Activities implementing\n     * {@link #ACTION_RECOGNIZE_SPEECH} may interpret the values as they see fit.\n     *\n     *  @see #LANGUAGE_MODEL_FREE_FORM\n     *  @see #LANGUAGE_MODEL_WEB_SEARCH\n     ",
    "links" : [ "#ACTION_RECOGNIZE_SPEECH" ]
  }, {
    "name" : "LANGUAGE_MODEL_FREE_FORM",
    "type" : "String",
    "comment" : "\n     * Use a language model based on free-form speech recognition.  This is a value to use for\n     * {@link #EXTRA_LANGUAGE_MODEL}.\n     * @see #EXTRA_LANGUAGE_MODEL\n     ",
    "links" : [ "#EXTRA_LANGUAGE_MODEL" ]
  }, {
    "name" : "LANGUAGE_MODEL_WEB_SEARCH",
    "type" : "String",
    "comment" : "\n     * Use a language model based on web search terms.  This is a value to use for\n     * {@link #EXTRA_LANGUAGE_MODEL}.\n     * @see #EXTRA_LANGUAGE_MODEL\n     ",
    "links" : [ "#EXTRA_LANGUAGE_MODEL" ]
  }, {
    "name" : "EXTRA_PROMPT",
    "type" : "String",
    "comment" : " Optional text prompt to show to the user when asking them to speak. ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_LANGUAGE",
    "type" : "String",
    "comment" : "\n     * Optional IETF language tag (as defined by BCP 47), for example \"en-US\". This tag informs the\n     * recognizer to perform speech recognition in a language different than the one set in the\n     * {@link java.util.Locale#getDefault()}.\n     ",
    "links" : [ "java.util.Locale#getDefault()" ]
  }, {
    "name" : "EXTRA_ORIGIN",
    "type" : "String",
    "comment" : "\n     * Optional value which can be used to indicate the referer url of a page in which\n     * speech was requested. For example, a web browser may choose to provide this for\n     * uses of speech on a given page.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_MAX_RESULTS",
    "type" : "String",
    "comment" : "\n     * Optional limit on the maximum number of results to return. If omitted the recognizer\n     * will choose how many results to return. Must be an integer.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_WEB_SEARCH_ONLY",
    "type" : "String",
    "comment" : "\n     * Optional boolean, to be used with {@link #ACTION_WEB_SEARCH}, to indicate whether to\n     * only fire web searches in response to a user's speech. The default is false, meaning\n     * that other types of actions can be taken based on the user's speech.\n     ",
    "links" : [ "#ACTION_WEB_SEARCH" ]
  }, {
    "name" : "EXTRA_PARTIAL_RESULTS",
    "type" : "String",
    "comment" : "\n     * Optional boolean to indicate whether partial results should be returned by the recognizer\n     * as the user speaks (default is false).  The server may ignore a request for partial\n     * results in some or all cases.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_RESULTS_PENDINGINTENT",
    "type" : "String",
    "comment" : "\n     * When the intent is {@link #ACTION_RECOGNIZE_SPEECH}, the speech input activity will\n     * return results to you via the activity results mechanism.  Alternatively, if you use this\n     * extra to supply a PendingIntent, the results will be added to its bundle and the\n     * PendingIntent will be sent to its target.\n     ",
    "links" : [ "#ACTION_RECOGNIZE_SPEECH" ]
  }, {
    "name" : "EXTRA_RESULTS_PENDINGINTENT_BUNDLE",
    "type" : "String",
    "comment" : "\n     * If you use {@link #EXTRA_RESULTS_PENDINGINTENT} to supply a forwarding intent, you can\n     * also use this extra to supply additional extras for the final intent.  The search results\n     * will be added to this bundle, and the combined bundle will be sent to the target.\n     ",
    "links" : [ "#EXTRA_RESULTS_PENDINGINTENT" ]
  }, {
    "name" : "RESULT_NO_MATCH",
    "type" : "int",
    "comment" : " Result code returned when no matches are found for the given speech ",
    "links" : [ ]
  }, {
    "name" : "RESULT_CLIENT_ERROR",
    "type" : "int",
    "comment" : " Result code returned when there is a generic client error ",
    "links" : [ ]
  }, {
    "name" : "RESULT_SERVER_ERROR",
    "type" : "int",
    "comment" : " Result code returned when the recognition server returns an error ",
    "links" : [ ]
  }, {
    "name" : "RESULT_NETWORK_ERROR",
    "type" : "int",
    "comment" : " Result code returned when a network error was encountered ",
    "links" : [ ]
  }, {
    "name" : "RESULT_AUDIO_ERROR",
    "type" : "int",
    "comment" : " Result code returned when an audio error was encountered ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_RESULTS",
    "type" : "String",
    "comment" : "\n     * An ArrayList&lt;String&gt; of the recognition results when performing\n     * {@link #ACTION_RECOGNIZE_SPEECH}. Generally this list should be ordered in\n     * descending order of speech recognizer confidence. (See {@link #EXTRA_CONFIDENCE_SCORES}).\n     * Returned in the results; not to be specified in the recognition request. Only present\n     * when {@link Activity#RESULT_OK} is returned in an activity result. In a PendingIntent,\n     * the lack of this extra indicates failure.\n     ",
    "links" : [ "#EXTRA_CONFIDENCE_SCORES", "#ACTION_RECOGNIZE_SPEECH", "android.app.Activity#RESULT_OK" ]
  }, {
    "name" : "EXTRA_CONFIDENCE_SCORES",
    "type" : "String",
    "comment" : "\n     * A float array of confidence scores of the recognition results when performing\n     * {@link #ACTION_RECOGNIZE_SPEECH}. The array should be the same size as the ArrayList\n     * returned in {@link #EXTRA_RESULTS}, and should contain values ranging from 0.0 to 1.0,\n     * or -1 to represent an unavailable confidence score.\n     * <p>\n     * Confidence values close to 1.0 indicate high confidence (the speech recognizer is\n     * confident that the recognition result is correct), while values close to 0.0 indicate\n     * low confidence.\n     * <p>\n     * Returned in the results; not to be specified in the recognition request. This extra is\n     * optional and might not be provided. Only present when {@link Activity#RESULT_OK} is\n     * returned in an activity result.\n     ",
    "links" : [ "#ACTION_RECOGNIZE_SPEECH", "android.app.Activity#RESULT_OK", "#EXTRA_RESULTS" ]
  }, {
    "name" : "DETAILS_META_DATA",
    "type" : "String",
    "comment" : "\n     * Meta-data name under which an {@link Activity} implementing {@link #ACTION_WEB_SEARCH} can\n     * use to expose the class name of a {@link BroadcastReceiver} which can respond to request for\n     * more information, from any of the broadcast intents specified in this class.\n     * <p>\n     * Broadcast intents can be directed to the class name specified in the meta-data by creating\n     * an {@link Intent}, setting the component with\n     * {@link Intent#setComponent(android.content.ComponentName)}, and using\n     * {@link Context#sendOrderedBroadcast(Intent, String, BroadcastReceiver, android.os.Handler, int, String, android.os.Bundle)}\n     * with another {@link BroadcastReceiver} which can receive the results.\n     * <p>\n     * The {@link #getVoiceDetailsIntent(Context)} method is provided as a convenience to create\n     * a broadcast intent based on the value of this meta-data, if available.\n     * <p>\n     * This is optional and not all {@link Activity}s which implement {@link #ACTION_WEB_SEARCH}\n     * are required to implement this. Thus retrieving this meta-data may be null.\n     ",
    "links" : [ "#ACTION_WEB_SEARCH", "android.content.Intent#setComponent(android.content.ComponentName)", "android.content.Intent", "android.content.Context#sendOrderedBroadcast(Intent", "android.app.Activity", "android.content.BroadcastReceiver", "#getVoiceDetailsIntent(Context)" ]
  }, {
    "name" : "ACTION_GET_LANGUAGE_DETAILS",
    "type" : "String",
    "comment" : "\n     * A broadcast intent which can be fired to the {@link BroadcastReceiver} component specified\n     * in the meta-data defined in the {@link #DETAILS_META_DATA} meta-data of an\n     * {@link Activity} satisfying {@link #ACTION_WEB_SEARCH}.\n     * <p>\n     * When fired with\n     * {@link Context#sendOrderedBroadcast(Intent, String, BroadcastReceiver, android.os.Handler, int, String, android.os.Bundle)},\n     * a {@link Bundle} of extras will be returned to the provided result receiver, and should\n     * ideally contain values for {@link #EXTRA_LANGUAGE_PREFERENCE} and\n     * {@link #EXTRA_SUPPORTED_LANGUAGES}.\n     * <p>\n     * (Whether these are actually provided is up to the particular implementation. It is\n     * recommended that {@link Activity}s implementing {@link #ACTION_WEB_SEARCH} provide this\n     * information, but it is not required.)\n     ",
    "links" : [ "#EXTRA_LANGUAGE_PREFERENCE", "android.os.Bundle", "#ACTION_WEB_SEARCH", "android.content.Context#sendOrderedBroadcast(Intent", "android.content.BroadcastReceiver", "#DETAILS_META_DATA", "android.app.Activity", "#EXTRA_SUPPORTED_LANGUAGES" ]
  }, {
    "name" : "EXTRA_ONLY_RETURN_LANGUAGE_PREFERENCE",
    "type" : "String",
    "comment" : "\n     * Specify this boolean extra in a broadcast of {@link #ACTION_GET_LANGUAGE_DETAILS} to\n     * indicate that only the current language preference is needed in the response. This\n     * avoids any additional computation if all you need is {@link #EXTRA_LANGUAGE_PREFERENCE}\n     * in the response.\n     ",
    "links" : [ "#ACTION_GET_LANGUAGE_DETAILS", "#EXTRA_LANGUAGE_PREFERENCE" ]
  }, {
    "name" : "EXTRA_LANGUAGE_PREFERENCE",
    "type" : "String",
    "comment" : "\n     * The key to the extra in the {@link Bundle} returned by {@link #ACTION_GET_LANGUAGE_DETAILS}\n     * which is a {@link String} that represents the current language preference this user has\n     * specified - a locale string like \"en-US\".\n     ",
    "links" : [ "#ACTION_GET_LANGUAGE_DETAILS", "android.os.Bundle", "String" ]
  }, {
    "name" : "EXTRA_SUPPORTED_LANGUAGES",
    "type" : "String",
    "comment" : "\n     * The key to the extra in the {@link Bundle} returned by {@link #ACTION_GET_LANGUAGE_DETAILS}\n     * which is an {@link ArrayList} of {@link String}s that represents the languages supported by\n     * this implementation of voice recognition - a list of strings like \"en-US\", \"cmn-Hans-CN\",\n     * etc.\n     ",
    "links" : [ "#ACTION_GET_LANGUAGE_DETAILS", "android.os.Bundle", "String", "java.util.ArrayList" ]
  }, {
    "name" : "EXTRA_PREFER_OFFLINE",
    "type" : "String",
    "comment" : "\n     * Optional boolean, to be used with {@link #ACTION_RECOGNIZE_SPEECH},\n     * {@link #ACTION_VOICE_SEARCH_HANDS_FREE}, {@link #ACTION_WEB_SEARCH} to indicate whether to\n     * only use an offline speech recognition engine. The default is false, meaning that either\n     * network or offline recognition engines may be used.\n     *\n     * <p>Depending on the recognizer implementation, these values may have\n     * no effect.</p>\n     *\n     ",
    "links" : [ "#ACTION_RECOGNIZE_SPEECH", "#ACTION_WEB_SEARCH", "#ACTION_VOICE_SEARCH_HANDS_FREE" ]
  }, {
    "name" : "EXTRA_SEGMENTED_SESSION",
    "type" : "String",
    "comment" : "\n     * Optional string to enable segmented session mode of the specified type, which can be\n     * {@link #EXTRA_AUDIO_SOURCE}, {@link #EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS} or\n     * {@link #EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS}. When segmented session mode is\n     * supported by the recognizer implementation and this extra is set, it will return the\n     * recognition results in segments via {@link RecognitionListener#onSegmentResults(Bundle)}\n     * and terminate the session with {@link RecognitionListener#onEndOfSegmentedSession()}.\n     *\n     * <p>When setting this extra, make sure the extra used as the string value here is also set\n     * in the same intent with proper value.\n     *\n     * <p>Depending on the recognizer implementation, this value may have no effect.\n     *\n     * @see #EXTRA_AUDIO_SOURCE\n     * @see #EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS\n     * @see #EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS\n     ",
    "links" : [ "#EXTRA_AUDIO_SOURCE", "#EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS", "android.speech.RecognitionListener#onEndOfSegmentedSession()", "android.speech.RecognitionListener#onSegmentResults(Bundle)", "#EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS" ]
  }, {
    "name" : "EXTRA_REQUEST_WORD_TIMING",
    "type" : "String",
    "comment" : "\n     * Optional boolean indicating whether the recognizer should return the timestamp\n     * of each word in the final recognition results.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_REQUEST_WORD_CONFIDENCE",
    "type" : "String",
    "comment" : "\n     * Optional boolean indicating whether the recognizer should return the confidence\n     * level of each word in the final recognition results.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_ENABLE_LANGUAGE_DETECTION",
    "type" : "String",
    "comment" : "\n     * Optional boolean indicating whether to enable language detection. When enabled, the\n     * recognizer will consistently identify the language of the current spoken utterance and\n     * provide that info via {@link RecognitionListener#onLanguageDetection(Bundle)}.\n     *\n     * <p> Depending on the recognizer implementation, this flag may have no effect.\n     ",
    "links" : [ "android.speech.RecognitionListener#onLanguageDetection(Bundle)" ]
  }, {
    "name" : "EXTRA_LANGUAGE_DETECTION_ALLOWED_LANGUAGES",
    "type" : "String",
    "comment" : "\n     * Optional list of IETF language tags (as defined by BCP 47, e.g. \"en-US\", \"de-DE\").\n     * This extra is to be used with {@link #EXTRA_ENABLE_LANGUAGE_DETECTION}.\n     * If set, the recognizer will constrain the language detection output\n     * to this list of languages, potentially improving detection accuracy.\n     ",
    "links" : [ "#EXTRA_ENABLE_LANGUAGE_DETECTION" ]
  }, {
    "name" : "EXTRA_ENABLE_LANGUAGE_SWITCH",
    "type" : "String",
    "comment" : "\n     * Optional string to enable automatic switching to the language being spoken with\n     * the desired sensitivity level, instead of being restricted to a single language.\n     * The corresponding language models must be downloaded to support the switch.\n     * Otherwise, the recognizer will report an error on a switch failure. The recognizer\n     * provides the switch results via {@link RecognitionListener#onLanguageDetection(Bundle)}.\n     *\n     * <p> Since detection is a necessary requirement for the language switching,\n     * setting this value implicitly enables {@link #EXTRA_ENABLE_LANGUAGE_DETECTION}.\n     *\n     * <p> Depending on the recognizer implementation, this value may have no effect.\n     *\n     * @see #LANGUAGE_SWITCH_HIGH_PRECISION\n     * @see #LANGUAGE_SWITCH_BALANCED\n     * @see #LANGUAGE_SWITCH_QUICK_RESPONSE\n     ",
    "links" : [ "#EXTRA_ENABLE_LANGUAGE_DETECTION", "android.speech.RecognitionListener#onLanguageDetection(Bundle)" ]
  }, {
    "name" : "LANGUAGE_SWITCH_HIGH_PRECISION",
    "type" : "String",
    "comment" : "\n     * A value to use for {@link #EXTRA_ENABLE_LANGUAGE_SWITCH}.\n     *\n     * <p> Enables language switch only when a new language is detected as\n     * {@link SpeechRecognizer#LANGUAGE_DETECTION_CONFIDENCE_LEVEL_HIGHLY_CONFIDENT},\n     * which means the service may wait for longer before switching.\n     *\n     * @see #EXTRA_ENABLE_LANGUAGE_SWITCH\n     ",
    "links" : [ "android.speech.SpeechRecognizer#LANGUAGE_DETECTION_CONFIDENCE_LEVEL_HIGHLY_CONFIDENT", "#EXTRA_ENABLE_LANGUAGE_SWITCH" ]
  }, {
    "name" : "LANGUAGE_SWITCH_BALANCED",
    "type" : "String",
    "comment" : "\n     * A value to use for {@link #EXTRA_ENABLE_LANGUAGE_SWITCH}.\n     *\n     * <p> Enables language switch only when a new language is detected as at least\n     * {@link SpeechRecognizer#LANGUAGE_DETECTION_CONFIDENCE_LEVEL_CONFIDENT}, which means\n     * the service is balancing between detecting a new language confidently and switching early.\n     *\n     * @see #EXTRA_ENABLE_LANGUAGE_SWITCH\n     ",
    "links" : [ "android.speech.SpeechRecognizer#LANGUAGE_DETECTION_CONFIDENCE_LEVEL_CONFIDENT", "#EXTRA_ENABLE_LANGUAGE_SWITCH" ]
  }, {
    "name" : "LANGUAGE_SWITCH_QUICK_RESPONSE",
    "type" : "String",
    "comment" : "\n     * A value to use for {@link #EXTRA_ENABLE_LANGUAGE_SWITCH}.\n     *\n     * <p> Enables language switch only when a new language is detected as at least\n     * {@link SpeechRecognizer#LANGUAGE_DETECTION_CONFIDENCE_LEVEL_NOT_CONFIDENT},\n     * which means the service should switch at the earliest moment possible.\n     *\n     * @see #EXTRA_ENABLE_LANGUAGE_SWITCH\n     ",
    "links" : [ "android.speech.SpeechRecognizer#LANGUAGE_DETECTION_CONFIDENCE_LEVEL_NOT_CONFIDENT", "#EXTRA_ENABLE_LANGUAGE_SWITCH" ]
  }, {
    "name" : "EXTRA_LANGUAGE_SWITCH_ALLOWED_LANGUAGES",
    "type" : "String",
    "comment" : "\n     * Optional list of IETF language tags (as defined by BCP 47, e.g. \"en-US\", \"de-DE\"). This extra\n     * is to be used with {@link #EXTRA_ENABLE_LANGUAGE_SWITCH}. If set, the recognizer will apply\n     * the auto switch only to these languages, even if the speech models of other languages also\n     * exist. The corresponding language models must be downloaded to support the switch.\n     * Otherwise, the recognizer will report an error on a switch failure.\n     ",
    "links" : [ "#EXTRA_ENABLE_LANGUAGE_SWITCH" ]
  }, {
    "name" : "EXTRA_LANGUAGE_SWITCH_MAX_SWITCHES",
    "type" : "String",
    "comment" : "\n     * Optional integer to use for {@link #EXTRA_ENABLE_LANGUAGE_SWITCH}. If set, the language\n     * switch will be deactivated when LANGUAGE_SWITCH_MAX_SWITCHES reached.\n     *\n     * <p> Depending on the recognizer implementation, this flag may have no effect.\n     *\n     * @see #EXTRA_ENABLE_LANGUAGE_SWITCH\n     ",
    "links" : [ "#EXTRA_ENABLE_LANGUAGE_SWITCH" ]
  }, {
    "name" : "EXTRA_LANGUAGE_SWITCH_INITIAL_ACTIVE_DURATION_TIME_MILLIS",
    "type" : "String",
    "comment" : "\n     * Optional integer to use for {@link #EXTRA_ENABLE_LANGUAGE_SWITCH}. If set, the language\n     * switch will only be activated for this value of ms of audio since the START_OF_SPEECH. This\n     * could provide a more stable recognition result when the language switch is only required in\n     * the beginning of the session.\n     *\n     * <p> Depending on the recognizer implementation, this flag may have no effect.\n     *\n     * @see #EXTRA_ENABLE_LANGUAGE_SWITCH\n     ",
    "links" : [ "#EXTRA_ENABLE_LANGUAGE_SWITCH" ]
  } ],
  "methods" : [ {
    "name" : "public static final Intent getVoiceDetailsIntent(Context context)",
    "returnType" : "Intent",
    "comment" : "\n     * Returns the broadcast intent to fire with\n     * {@link Context#sendOrderedBroadcast(Intent, String, BroadcastReceiver, android.os.Handler, int, String, Bundle)}\n     * to receive details from the package that implements voice search.\n     * <p>\n     * This is based on the value specified by the voice search {@link Activity} in\n     * {@link #DETAILS_META_DATA}, and if this is not specified, will return null. Also if there\n     * is no chosen default to resolve for {@link #ACTION_WEB_SEARCH}, this will return null.\n     * <p>\n     * If an intent is returned and is fired, a {@link Bundle} of extras will be returned to the\n     * provided result receiver, and should ideally contain values for\n     * {@link #EXTRA_LANGUAGE_PREFERENCE} and {@link #EXTRA_SUPPORTED_LANGUAGES}.\n     * <p>\n     * (Whether these are actually provided is up to the particular implementation. It is\n     * recommended that {@link Activity}s implementing {@link #ACTION_WEB_SEARCH} provide this\n     * information, but it is not required.)\n     *\n     * @param context a context object\n     * @return the broadcast intent to fire or null if not available\n     ",
    "links" : [ "#EXTRA_LANGUAGE_PREFERENCE", "android.os.Bundle", "#ACTION_WEB_SEARCH", "android.content.Context#sendOrderedBroadcast(Intent", "android.app.Activity", "#DETAILS_META_DATA", "#EXTRA_SUPPORTED_LANGUAGES" ]
  } ],
  "methodNames" : [ "public static final Intent getVoiceDetailsIntent(Context context)" ],
  "variableNames" : [ "ACTION_RECOGNIZE_SPEECH", "ACTION_WEB_SEARCH", "ACTION_VOICE_SEARCH_HANDS_FREE", "EXTRA_AUDIO_SOURCE", "EXTRA_AUDIO_SOURCE_CHANNEL_COUNT", "EXTRA_AUDIO_SOURCE_ENCODING", "EXTRA_AUDIO_SOURCE_SAMPLING_RATE", "EXTRA_ENABLE_BIASING_DEVICE_CONTEXT", "EXTRA_BIASING_STRINGS", "EXTRA_ENABLE_FORMATTING", "FORMATTING_OPTIMIZE_QUALITY", "FORMATTING_OPTIMIZE_LATENCY", "EXTRA_HIDE_PARTIAL_TRAILING_PUNCTUATION", "EXTRA_MASK_OFFENSIVE_WORDS", "EXTRA_CALLING_PACKAGE", "EXTRA_AUDIO_INJECT_SOURCE", "EXTRA_SECURE", "EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS", "EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS", "EXTRA_SPEECH_INPUT_POSSIBLY_COMPLETE_SILENCE_LENGTH_MILLIS", "EXTRA_LANGUAGE_MODEL", "LANGUAGE_MODEL_FREE_FORM", "LANGUAGE_MODEL_WEB_SEARCH", "EXTRA_PROMPT", "EXTRA_LANGUAGE", "EXTRA_ORIGIN", "EXTRA_MAX_RESULTS", "EXTRA_WEB_SEARCH_ONLY", "EXTRA_PARTIAL_RESULTS", "EXTRA_RESULTS_PENDINGINTENT", "EXTRA_RESULTS_PENDINGINTENT_BUNDLE", "RESULT_NO_MATCH", "RESULT_CLIENT_ERROR", "RESULT_SERVER_ERROR", "RESULT_NETWORK_ERROR", "RESULT_AUDIO_ERROR", "EXTRA_RESULTS", "EXTRA_CONFIDENCE_SCORES", "DETAILS_META_DATA", "ACTION_GET_LANGUAGE_DETAILS", "EXTRA_ONLY_RETURN_LANGUAGE_PREFERENCE", "EXTRA_LANGUAGE_PREFERENCE", "EXTRA_SUPPORTED_LANGUAGES", "EXTRA_PREFER_OFFLINE", "EXTRA_SEGMENTED_SESSION", "EXTRA_REQUEST_WORD_TIMING", "EXTRA_REQUEST_WORD_CONFIDENCE", "EXTRA_ENABLE_LANGUAGE_DETECTION", "EXTRA_LANGUAGE_DETECTION_ALLOWED_LANGUAGES", "EXTRA_ENABLE_LANGUAGE_SWITCH", "LANGUAGE_SWITCH_HIGH_PRECISION", "LANGUAGE_SWITCH_BALANCED", "LANGUAGE_SWITCH_QUICK_RESPONSE", "EXTRA_LANGUAGE_SWITCH_ALLOWED_LANGUAGES", "EXTRA_LANGUAGE_SWITCH_MAX_SWITCHES", "EXTRA_LANGUAGE_SWITCH_INITIAL_ACTIVE_DURATION_TIME_MILLIS" ]
}