{
  "filePath" : "/home/maryam/clearblue/files/android-source-30/android/speech/RecognizerIntent.java",
  "packageName" : "android.speech",
  "className" : "RecognizerIntent",
  "comment" : "\n * Constants for supporting speech recognition through starting an {@link Intent}\n ",
  "variables" : [ {
    "name" : "EXTRA_CALLING_PACKAGE",
    "type" : "String",
    "comment" : "\n     * The extra key used in an intent to the speech recognizer for voice search. Not\n     * generally to be used by developers. The system search dialog uses this, for example,\n     * to set a calling package for identification by a voice search API. If this extra\n     * is set by anyone but the system process, it should be overridden by the voice search\n     * implementation.\n     ",
    "links" : [ ]
  }, {
    "name" : "ACTION_RECOGNIZE_SPEECH",
    "type" : "String",
    "comment" : "\n     * Starts an activity that will prompt the user for speech and send it through a\n     * speech recognizer.  The results will be returned via activity results (in\n     * {@link Activity#onActivityResult}, if you start the intent using\n     * {@link Activity#startActivityForResult(Intent, int)}), or forwarded via a PendingIntent\n     * if one is provided.\n     * \n     * <p>Starting this intent with just {@link Activity#startActivity(Intent)} is not supported.\n     * You must either use {@link Activity#startActivityForResult(Intent, int)}, or provide a\n     * PendingIntent, to receive recognition results.\n     *\n     * <p>The implementation of this API is likely to stream audio to remote servers to perform\n     * speech recognition which can use a substantial amount of bandwidth.\n     *\n     * <p>Required extras:\n     * <ul>\n     *   <li>{@link #EXTRA_LANGUAGE_MODEL}\n     * </ul>\n     * \n     * <p>Optional extras:\n     * <ul>\n     *   <li>{@link #EXTRA_PROMPT}\n     *   <li>{@link #EXTRA_LANGUAGE}\n     *   <li>{@link #EXTRA_MAX_RESULTS}\n     *   <li>{@link #EXTRA_RESULTS_PENDINGINTENT}\n     *   <li>{@link #EXTRA_RESULTS_PENDINGINTENT_BUNDLE}\n     * </ul>\n     * \n     * <p> Result extras (returned in the result, not to be specified in the request):\n     * <ul>\n     *   <li>{@link #EXTRA_RESULTS}\n     * </ul>\n     * \n     * <p>NOTE: There may not be any applications installed to handle this action, so you should\n     * make sure to catch {@link ActivityNotFoundException}.\n     ",
    "links" : [ "#EXTRA_LANGUAGE_MODEL", "#EXTRA_PROMPT", "android.app.Activity#startActivityForResult(Intent", "#EXTRA_RESULTS_PENDINGINTENT", "android.app.Activity#startActivity(Intent)", "android.content.ActivityNotFoundException", "android.app.Activity#onActivityResult", "#EXTRA_RESULTS_PENDINGINTENT_BUNDLE", "#EXTRA_LANGUAGE", "#EXTRA_MAX_RESULTS", "#EXTRA_RESULTS" ]
  }, {
    "name" : "ACTION_WEB_SEARCH",
    "type" : "String",
    "comment" : "\n     * Starts an activity that will prompt the user for speech, send it through a\n     * speech recognizer, and either display a web search result or trigger\n     * another type of action based on the user's speech.\n     *\n     * <p>If you want to avoid triggering any type of action besides web search, you can use\n     * the {@link #EXTRA_WEB_SEARCH_ONLY} extra.\n     * \n     * <p>Required extras:\n     * <ul>\n     *   <li>{@link #EXTRA_LANGUAGE_MODEL}\n     * </ul>\n     * \n     * <p>Optional extras:\n     * <ul>\n     *   <li>{@link #EXTRA_PROMPT}\n     *   <li>{@link #EXTRA_LANGUAGE}\n     *   <li>{@link #EXTRA_MAX_RESULTS}\n     *   <li>{@link #EXTRA_PARTIAL_RESULTS}\n     *   <li>{@link #EXTRA_WEB_SEARCH_ONLY}\n     *   <li>{@link #EXTRA_ORIGIN}\n     * </ul>\n     * \n     * <p> Result extras (returned in the result, not to be specified in the request):\n     * <ul>\n     *   <li>{@link #EXTRA_RESULTS}\n     *   <li>{@link #EXTRA_CONFIDENCE_SCORES} (optional)\n     * </ul>\n     * \n     * <p>NOTE: There may not be any applications installed to handle this action, so you should\n     * make sure to catch {@link ActivityNotFoundException}.\n     ",
    "links" : [ "#EXTRA_WEB_SEARCH_ONLY", "#EXTRA_LANGUAGE_MODEL", "#EXTRA_PROMPT", "#EXTRA_CONFIDENCE_SCORES", "#EXTRA_ORIGIN", "android.content.ActivityNotFoundException", "#EXTRA_PARTIAL_RESULTS", "#EXTRA_LANGUAGE", "#EXTRA_MAX_RESULTS", "#EXTRA_RESULTS" ]
  }, {
    "name" : "ACTION_VOICE_SEARCH_HANDS_FREE",
    "type" : "String",
    "comment" : "\n     * Starts an activity that will prompt the user for speech without requiring the user's\n     * visual attention or touch input. It will send it through a speech recognizer,\n     * and either synthesize speech for a web search result or trigger\n     * another type of action based on the user's speech.\n     *\n     * This activity may be launched while device is locked in a secure mode.\n     * Special care must be taken to ensure that the voice actions that are performed while\n     * hands free cannot compromise the device's security.\n     * The activity should check the value of the {@link #EXTRA_SECURE} extra to determine\n     * whether the device has been securely locked. If so, the activity should either restrict\n     * the set of voice actions that are permitted or require some form of secure\n     * authentication before proceeding.\n     *\n     * To ensure that the activity's user interface is visible while the lock screen is showing,\n     * the activity should set the\n     * {@link android.view.WindowManager.LayoutParams#FLAG_SHOW_WHEN_LOCKED} window flag.\n     * Otherwise the activity's user interface may be hidden by the lock screen. The activity\n     * should take care not to leak private information when the device is securely locked.\n     *\n     * <p>Optional extras:\n     * <ul>\n     *   <li>{@link #EXTRA_SECURE}\n     * </ul>\n     *\n     * <p class=\"note\">\n     * In some cases, a matching Activity may not exist, so ensure you\n     * safeguard against this.\n     ",
    "links" : [ "#EXTRA_SECURE", "android.view.WindowManager.LayoutParams#FLAG_SHOW_WHEN_LOCKED" ]
  }, {
    "name" : "EXTRA_SECURE",
    "type" : "String",
    "comment" : "\n     * Optional boolean to indicate that a \"hands free\" voice search was performed while the device\n     * was in a secure mode. An example of secure mode is when the device's screen lock is active,\n     * and it requires some form of authentication to be unlocked.\n     *\n     * When the device is securely locked, the voice search activity should either restrict\n     * the set of voice actions that are permitted, or require some form of secure authentication\n     * before proceeding.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS",
    "type" : "String",
    "comment" : "\n     * The minimum length of an utterance. We will not stop recording before this amount of time.\n     * \n     * Note that it is extremely rare you'd want to specify this value in an intent. If you don't\n     * have a very good reason to change these, you should leave them as they are. Note also that\n     * certain values may cause undesired or unexpected results - use judiciously! Additionally,\n     * depending on the recognizer implementation, these values may have no effect.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS",
    "type" : "String",
    "comment" : "\n     * The amount of time that it should take after we stop hearing speech to consider the input\n     * complete. \n     * \n     * Note that it is extremely rare you'd want to specify this value in an intent. If\n     * you don't have a very good reason to change these, you should leave them as they are. Note\n     * also that certain values may cause undesired or unexpected results - use judiciously!\n     * Additionally, depending on the recognizer implementation, these values may have no effect.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_SPEECH_INPUT_POSSIBLY_COMPLETE_SILENCE_LENGTH_MILLIS",
    "type" : "String",
    "comment" : "\n     * The amount of time that it should take after we stop hearing speech to consider the input\n     * possibly complete. This is used to prevent the endpointer cutting off during very short\n     * mid-speech pauses. \n     * \n     * Note that it is extremely rare you'd want to specify this value in an intent. If\n     * you don't have a very good reason to change these, you should leave them as they are. Note\n     * also that certain values may cause undesired or unexpected results - use judiciously!\n     * Additionally, depending on the recognizer implementation, these values may have no effect.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_LANGUAGE_MODEL",
    "type" : "String",
    "comment" : "\n     * Informs the recognizer which speech model to prefer when performing\n     * {@link #ACTION_RECOGNIZE_SPEECH}. The recognizer uses this\n     * information to fine tune the results. This extra is required. Activities implementing\n     * {@link #ACTION_RECOGNIZE_SPEECH} may interpret the values as they see fit.\n     * \n     *  @see #LANGUAGE_MODEL_FREE_FORM\n     *  @see #LANGUAGE_MODEL_WEB_SEARCH\n     ",
    "links" : [ "#ACTION_RECOGNIZE_SPEECH" ]
  }, {
    "name" : "LANGUAGE_MODEL_FREE_FORM",
    "type" : "String",
    "comment" : " \n     * Use a language model based on free-form speech recognition.  This is a value to use for \n     * {@link #EXTRA_LANGUAGE_MODEL}. \n     * @see #EXTRA_LANGUAGE_MODEL\n     ",
    "links" : [ "#EXTRA_LANGUAGE_MODEL" ]
  }, {
    "name" : "LANGUAGE_MODEL_WEB_SEARCH",
    "type" : "String",
    "comment" : " \n     * Use a language model based on web search terms.  This is a value to use for \n     * {@link #EXTRA_LANGUAGE_MODEL}. \n     * @see #EXTRA_LANGUAGE_MODEL\n     ",
    "links" : [ "#EXTRA_LANGUAGE_MODEL" ]
  }, {
    "name" : "EXTRA_PROMPT",
    "type" : "String",
    "comment" : " Optional text prompt to show to the user when asking them to speak. ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_LANGUAGE",
    "type" : "String",
    "comment" : "\n     * Optional IETF language tag (as defined by BCP 47), for example \"en-US\". This tag informs the\n     * recognizer to perform speech recognition in a language different than the one set in the\n     * {@link java.util.Locale#getDefault()}.\n     ",
    "links" : [ "java.util.Locale#getDefault()" ]
  }, {
    "name" : "EXTRA_ORIGIN",
    "type" : "String",
    "comment" : "\n     * Optional value which can be used to indicate the referer url of a page in which\n     * speech was requested. For example, a web browser may choose to provide this for\n     * uses of speech on a given page.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_MAX_RESULTS",
    "type" : "String",
    "comment" : " \n     * Optional limit on the maximum number of results to return. If omitted the recognizer\n     * will choose how many results to return. Must be an integer.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_WEB_SEARCH_ONLY",
    "type" : "String",
    "comment" : "\n     * Optional boolean, to be used with {@link #ACTION_WEB_SEARCH}, to indicate whether to\n     * only fire web searches in response to a user's speech. The default is false, meaning\n     * that other types of actions can be taken based on the user's speech.\n     ",
    "links" : [ "#ACTION_WEB_SEARCH" ]
  }, {
    "name" : "EXTRA_PARTIAL_RESULTS",
    "type" : "String",
    "comment" : "\n     * Optional boolean to indicate whether partial results should be returned by the recognizer\n     * as the user speaks (default is false).  The server may ignore a request for partial\n     * results in some or all cases.\n     ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_RESULTS_PENDINGINTENT",
    "type" : "String",
    "comment" : "\n     * When the intent is {@link #ACTION_RECOGNIZE_SPEECH}, the speech input activity will\n     * return results to you via the activity results mechanism.  Alternatively, if you use this\n     * extra to supply a PendingIntent, the results will be added to its bundle and the \n     * PendingIntent will be sent to its target.\n     ",
    "links" : [ "#ACTION_RECOGNIZE_SPEECH" ]
  }, {
    "name" : "EXTRA_RESULTS_PENDINGINTENT_BUNDLE",
    "type" : "String",
    "comment" : "\n     * If you use {@link #EXTRA_RESULTS_PENDINGINTENT} to supply a forwarding intent, you can\n     * also use this extra to supply additional extras for the final intent.  The search results\n     * will be added to this bundle, and the combined bundle will be sent to the target.\n     ",
    "links" : [ "#EXTRA_RESULTS_PENDINGINTENT" ]
  }, {
    "name" : "RESULT_NO_MATCH",
    "type" : "int",
    "comment" : " Result code returned when no matches are found for the given speech ",
    "links" : [ ]
  }, {
    "name" : "RESULT_CLIENT_ERROR",
    "type" : "int",
    "comment" : " Result code returned when there is a generic client error ",
    "links" : [ ]
  }, {
    "name" : "RESULT_SERVER_ERROR",
    "type" : "int",
    "comment" : " Result code returned when the recognition server returns an error ",
    "links" : [ ]
  }, {
    "name" : "RESULT_NETWORK_ERROR",
    "type" : "int",
    "comment" : " Result code returned when a network error was encountered ",
    "links" : [ ]
  }, {
    "name" : "RESULT_AUDIO_ERROR",
    "type" : "int",
    "comment" : " Result code returned when an audio error was encountered ",
    "links" : [ ]
  }, {
    "name" : "EXTRA_RESULTS",
    "type" : "String",
    "comment" : "\n     * An ArrayList&lt;String&gt; of the recognition results when performing\n     * {@link #ACTION_RECOGNIZE_SPEECH}. Generally this list should be ordered in\n     * descending order of speech recognizer confidence. (See {@link #EXTRA_CONFIDENCE_SCORES}).\n     * Returned in the results; not to be specified in the recognition request. Only present\n     * when {@link Activity#RESULT_OK} is returned in an activity result. In a PendingIntent,\n     * the lack of this extra indicates failure.\n     ",
    "links" : [ "#EXTRA_CONFIDENCE_SCORES", "#ACTION_RECOGNIZE_SPEECH", "android.app.Activity#RESULT_OK" ]
  }, {
    "name" : "EXTRA_CONFIDENCE_SCORES",
    "type" : "String",
    "comment" : "\n     * A float array of confidence scores of the recognition results when performing\n     * {@link #ACTION_RECOGNIZE_SPEECH}. The array should be the same size as the ArrayList\n     * returned in {@link #EXTRA_RESULTS}, and should contain values ranging from 0.0 to 1.0,\n     * or -1 to represent an unavailable confidence score.\n     * <p>\n     * Confidence values close to 1.0 indicate high confidence (the speech recognizer is\n     * confident that the recognition result is correct), while values close to 0.0 indicate\n     * low confidence.\n     * <p>\n     * Returned in the results; not to be specified in the recognition request. This extra is\n     * optional and might not be provided. Only present when {@link Activity#RESULT_OK} is\n     * returned in an activity result.\n     ",
    "links" : [ "#ACTION_RECOGNIZE_SPEECH", "android.app.Activity#RESULT_OK", "#EXTRA_RESULTS" ]
  }, {
    "name" : "DETAILS_META_DATA",
    "type" : "String",
    "comment" : "\n     * Meta-data name under which an {@link Activity} implementing {@link #ACTION_WEB_SEARCH} can\n     * use to expose the class name of a {@link BroadcastReceiver} which can respond to request for\n     * more information, from any of the broadcast intents specified in this class.\n     * <p>\n     * Broadcast intents can be directed to the class name specified in the meta-data by creating\n     * an {@link Intent}, setting the component with\n     * {@link Intent#setComponent(android.content.ComponentName)}, and using\n     * {@link Context#sendOrderedBroadcast(Intent, String, BroadcastReceiver, android.os.Handler, int, String, android.os.Bundle)}\n     * with another {@link BroadcastReceiver} which can receive the results.\n     * <p>\n     * The {@link #getVoiceDetailsIntent(Context)} method is provided as a convenience to create\n     * a broadcast intent based on the value of this meta-data, if available.\n     * <p>\n     * This is optional and not all {@link Activity}s which implement {@link #ACTION_WEB_SEARCH}\n     * are required to implement this. Thus retrieving this meta-data may be null.\n     ",
    "links" : [ "#ACTION_WEB_SEARCH", "android.content.Intent#setComponent(android.content.ComponentName)", "android.content.Intent", "android.content.Context#sendOrderedBroadcast(Intent", "android.app.Activity", "android.content.BroadcastReceiver", "#getVoiceDetailsIntent(Context)" ]
  }, {
    "name" : "ACTION_GET_LANGUAGE_DETAILS",
    "type" : "String",
    "comment" : "\n     * A broadcast intent which can be fired to the {@link BroadcastReceiver} component specified\n     * in the meta-data defined in the {@link #DETAILS_META_DATA} meta-data of an\n     * {@link Activity} satisfying {@link #ACTION_WEB_SEARCH}.\n     * <p>\n     * When fired with\n     * {@link Context#sendOrderedBroadcast(Intent, String, BroadcastReceiver, android.os.Handler, int, String, android.os.Bundle)},\n     * a {@link Bundle} of extras will be returned to the provided result receiver, and should\n     * ideally contain values for {@link #EXTRA_LANGUAGE_PREFERENCE} and\n     * {@link #EXTRA_SUPPORTED_LANGUAGES}.\n     * <p>\n     * (Whether these are actually provided is up to the particular implementation. It is\n     * recommended that {@link Activity}s implementing {@link #ACTION_WEB_SEARCH} provide this\n     * information, but it is not required.)\n     ",
    "links" : [ "#EXTRA_LANGUAGE_PREFERENCE", "android.os.Bundle", "#ACTION_WEB_SEARCH", "android.content.Context#sendOrderedBroadcast(Intent", "android.content.BroadcastReceiver", "#DETAILS_META_DATA", "android.app.Activity", "#EXTRA_SUPPORTED_LANGUAGES" ]
  }, {
    "name" : "EXTRA_ONLY_RETURN_LANGUAGE_PREFERENCE",
    "type" : "String",
    "comment" : "\n     * Specify this boolean extra in a broadcast of {@link #ACTION_GET_LANGUAGE_DETAILS} to\n     * indicate that only the current language preference is needed in the response. This\n     * avoids any additional computation if all you need is {@link #EXTRA_LANGUAGE_PREFERENCE}\n     * in the response.\n     ",
    "links" : [ "#ACTION_GET_LANGUAGE_DETAILS", "#EXTRA_LANGUAGE_PREFERENCE" ]
  }, {
    "name" : "EXTRA_LANGUAGE_PREFERENCE",
    "type" : "String",
    "comment" : "\n     * The key to the extra in the {@link Bundle} returned by {@link #ACTION_GET_LANGUAGE_DETAILS}\n     * which is a {@link String} that represents the current language preference this user has\n     * specified - a locale string like \"en-US\".\n     ",
    "links" : [ "#ACTION_GET_LANGUAGE_DETAILS", "android.os.Bundle", "String" ]
  }, {
    "name" : "EXTRA_SUPPORTED_LANGUAGES",
    "type" : "String",
    "comment" : "\n     * The key to the extra in the {@link Bundle} returned by {@link #ACTION_GET_LANGUAGE_DETAILS}\n     * which is an {@link ArrayList} of {@link String}s that represents the languages supported by\n     * this implementation of voice recognition - a list of strings like \"en-US\", \"cmn-Hans-CN\",\n     * etc.\n     ",
    "links" : [ "#ACTION_GET_LANGUAGE_DETAILS", "android.os.Bundle", "String", "java.util.ArrayList" ]
  }, {
    "name" : "EXTRA_PREFER_OFFLINE",
    "type" : "String",
    "comment" : "\n     * Optional boolean, to be used with {@link #ACTION_RECOGNIZE_SPEECH},\n     * {@link #ACTION_VOICE_SEARCH_HANDS_FREE}, {@link #ACTION_WEB_SEARCH} to indicate whether to\n     * only use an offline speech recognition engine. The default is false, meaning that either\n     * network or offline recognition engines may be used.\n     *\n     * <p>Depending on the recognizer implementation, these values may have\n     * no effect.</p>\n     *\n     ",
    "links" : [ "#ACTION_RECOGNIZE_SPEECH", "#ACTION_WEB_SEARCH", "#ACTION_VOICE_SEARCH_HANDS_FREE" ]
  } ],
  "methods" : [ {
    "name" : "public static final Intent getVoiceDetailsIntent(Context context)",
    "returnType" : "Intent",
    "comment" : "\n     * Returns the broadcast intent to fire with\n     * {@link Context#sendOrderedBroadcast(Intent, String, BroadcastReceiver, android.os.Handler, int, String, Bundle)}\n     * to receive details from the package that implements voice search.\n     * <p>\n     * This is based on the value specified by the voice search {@link Activity} in\n     * {@link #DETAILS_META_DATA}, and if this is not specified, will return null. Also if there\n     * is no chosen default to resolve for {@link #ACTION_WEB_SEARCH}, this will return null.\n     * <p>\n     * If an intent is returned and is fired, a {@link Bundle} of extras will be returned to the\n     * provided result receiver, and should ideally contain values for\n     * {@link #EXTRA_LANGUAGE_PREFERENCE} and {@link #EXTRA_SUPPORTED_LANGUAGES}.\n     * <p>\n     * (Whether these are actually provided is up to the particular implementation. It is\n     * recommended that {@link Activity}s implementing {@link #ACTION_WEB_SEARCH} provide this\n     * information, but it is not required.)\n     * \n     * @param context a context object\n     * @return the broadcast intent to fire or null if not available\n     ",
    "links" : [ "#EXTRA_LANGUAGE_PREFERENCE", "android.os.Bundle", "#ACTION_WEB_SEARCH", "android.content.Context#sendOrderedBroadcast(Intent", "android.app.Activity", "#DETAILS_META_DATA", "#EXTRA_SUPPORTED_LANGUAGES" ]
  } ],
  "variableNames" : [ "EXTRA_CALLING_PACKAGE", "ACTION_RECOGNIZE_SPEECH", "ACTION_WEB_SEARCH", "ACTION_VOICE_SEARCH_HANDS_FREE", "EXTRA_SECURE", "EXTRA_SPEECH_INPUT_MINIMUM_LENGTH_MILLIS", "EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS", "EXTRA_SPEECH_INPUT_POSSIBLY_COMPLETE_SILENCE_LENGTH_MILLIS", "EXTRA_LANGUAGE_MODEL", "LANGUAGE_MODEL_FREE_FORM", "LANGUAGE_MODEL_WEB_SEARCH", "EXTRA_PROMPT", "EXTRA_LANGUAGE", "EXTRA_ORIGIN", "EXTRA_MAX_RESULTS", "EXTRA_WEB_SEARCH_ONLY", "EXTRA_PARTIAL_RESULTS", "EXTRA_RESULTS_PENDINGINTENT", "EXTRA_RESULTS_PENDINGINTENT_BUNDLE", "RESULT_NO_MATCH", "RESULT_CLIENT_ERROR", "RESULT_SERVER_ERROR", "RESULT_NETWORK_ERROR", "RESULT_AUDIO_ERROR", "EXTRA_RESULTS", "EXTRA_CONFIDENCE_SCORES", "DETAILS_META_DATA", "ACTION_GET_LANGUAGE_DETAILS", "EXTRA_ONLY_RETURN_LANGUAGE_PREFERENCE", "EXTRA_LANGUAGE_PREFERENCE", "EXTRA_SUPPORTED_LANGUAGES", "EXTRA_PREFER_OFFLINE" ],
  "methodNames" : [ "public static final Intent getVoiceDetailsIntent(Context context)" ]
}