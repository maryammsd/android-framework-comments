{
  "filePath" : "/home/maryam/clearblue/files/android-source-30/android/media/MediaSync.java",
  "packageName" : "android.media",
  "className" : "MediaSync",
  "comment" : "\n * MediaSync class can be used to synchronously play audio and video streams.\n * It can be used to play audio-only or video-only stream, too.\n *\n * <p>MediaSync is generally used like this:\n * <pre>\n * MediaSync sync = new MediaSync();\n * sync.setSurface(surface);\n * Surface inputSurface = sync.createInputSurface();\n * ...\n * // MediaCodec videoDecoder = ...;\n * videoDecoder.configure(format, inputSurface, ...);\n * ...\n * sync.setAudioTrack(audioTrack);\n * sync.setCallback(new MediaSync.Callback() {\n *     {@literal @Override}\n *     public void onAudioBufferConsumed(MediaSync sync, ByteBuffer audioBuffer, int bufferId) {\n *         ...\n *     }\n * }, null);\n * // This needs to be done since sync is paused on creation.\n * sync.setPlaybackParams(new PlaybackParams().setSpeed(1.f));\n *\n * for (;;) {\n *   ...\n *   // send video frames to surface for rendering, e.g., call\n *   // videoDecoder.releaseOutputBuffer(videoOutputBufferIx, videoPresentationTimeNs);\n *   // More details are available as below.\n *   ...\n *   sync.queueAudio(audioByteBuffer, bufferId, audioPresentationTimeUs); // non-blocking.\n *   // The audioByteBuffer and bufferId will be returned via callback.\n *   // More details are available as below.\n *   ...\n *     ...\n * }\n * sync.setPlaybackParams(new PlaybackParams().setSpeed(0.f));\n * sync.release();\n * sync = null;\n *\n * // The following code snippet illustrates how video/audio raw frames are created by\n * // MediaCodec's, how they are fed to MediaSync and how they are returned by MediaSync.\n * // This is the callback from MediaCodec.\n * onOutputBufferAvailable(MediaCodec codec, int bufferId, BufferInfo info) {\n *     // ...\n *     if (codec == videoDecoder) {\n *         // surface timestamp must contain media presentation time in nanoseconds.\n *         codec.releaseOutputBuffer(bufferId, 1000 * info.presentationTime);\n *     } else {\n *         ByteBuffer audioByteBuffer = codec.getOutputBuffer(bufferId);\n *         sync.queueAudio(audioByteBuffer, bufferId, info.presentationTime);\n *     }\n *     // ...\n * }\n *\n * // This is the callback from MediaSync.\n * onAudioBufferConsumed(MediaSync sync, ByteBuffer buffer, int bufferId) {\n *     // ...\n *     audioDecoder.releaseBuffer(bufferId, false);\n *     // ...\n * }\n *\n * </pre>\n *\n * The client needs to configure corresponding sink by setting the Surface and/or AudioTrack\n * based on the stream type it will play.\n * <p>\n * For video, the client needs to call {@link #createInputSurface} to obtain a surface on\n * which it will render video frames.\n * <p>\n * For audio, the client needs to set up audio track correctly, e.g., using {@link\n * AudioTrack#MODE_STREAM}. The audio buffers are sent to MediaSync directly via {@link\n * #queueAudio}, and are returned to the client via {@link Callback#onAudioBufferConsumed}\n * asynchronously. The client should not modify an audio buffer till it's returned.\n * <p>\n * The client can optionally pre-fill audio/video buffers by setting playback rate to 0.0,\n * and then feed audio/video buffers to corresponding components. This can reduce possible\n * initial underrun.\n * <p>\n ",
  "variables" : [ {
    "name" : "MEDIASYNC_ERROR_AUDIOTRACK_FAIL",
    "type" : "int",
    "comment" : " Audio track failed.\n     * @see android.media.MediaSync.OnErrorListener\n     ",
    "links" : [ ]
  }, {
    "name" : "MEDIASYNC_ERROR_SURFACE_FAIL",
    "type" : "int",
    "comment" : " The surface failed to handle video buffers.\n     * @see android.media.MediaSync.OnErrorListener\n     ",
    "links" : [ ]
  }, {
    "name" : "TAG",
    "type" : "String",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "EVENT_CALLBACK",
    "type" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "EVENT_SET_CALLBACK",
    "type" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "CB_RETURN_AUDIO_BUFFER",
    "type" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mCallbackLock",
    "type" : "Object",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mCallbackHandler",
    "type" : "Handler",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mCallback",
    "type" : "MediaSync.Callback",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mOnErrorListenerLock",
    "type" : "Object",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mOnErrorListenerHandler",
    "type" : "Handler",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mOnErrorListener",
    "type" : "MediaSync.OnErrorListener",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mAudioThread",
    "type" : "Thread",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mAudioHandler",
    "type" : "Handler",
    "comment" : " be guarded by checking mAudioThread.",
    "links" : [ ]
  }, {
    "name" : "mAudioLooper",
    "type" : "Looper",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mAudioLock",
    "type" : "Object",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mAudioTrack",
    "type" : "AudioTrack",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mAudioBuffers",
    "type" : "List<AudioBuffer>",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mPlaybackRate",
    "type" : "float",
    "comment" : " this is only used for paused/running decisions, so it is not affected by clock drift",
    "links" : [ ]
  }, {
    "name" : "mNativeContext",
    "type" : "long",
    "comment" : "",
    "links" : [ ]
  } ],
  "methods" : [ {
    "name" : "private final native void native_setup()",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "protected void finalize()",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private final native void native_finalize()",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public final void release()",
    "returnType" : "void",
    "comment" : "\n     * Make sure you call this when you're done to free up any opened\n     * component instance instead of relying on the garbage collector\n     * to do this for you at some point in the future.\n     ",
    "links" : [ ]
  }, {
    "name" : "private final native void native_release()",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public void setCallback(@Nullable Callback cb, @Nullable Handler handler)",
    "returnType" : "void",
    "comment" : "\n     * Sets an asynchronous callback for actionable MediaSync events.\n     * <p>\n     * This method can be called multiple times to update a previously set callback. If the\n     * handler is changed, undelivered notifications scheduled for the old handler may be dropped.\n     * <p>\n     * <b>Do not call this inside callback.</b>\n     *\n     * @param cb The callback that will run. Use {@code null} to stop receiving callbacks.\n     * @param handler The Handler that will run the callback. Use {@code null} to use MediaSync's\n     *     internal handler if it exists.\n     ",
    "links" : [ ]
  }, {
    "name" : "public void setOnErrorListener(@Nullable OnErrorListener listener, @Nullable Handler handler)",
    "returnType" : "void",
    "comment" : "\n     * Sets an asynchronous callback for error events.\n     * <p>\n     * This method can be called multiple times to update a previously set listener. If the\n     * handler is changed, undelivered notifications scheduled for the old handler may be dropped.\n     * <p>\n     * <b>Do not call this inside callback.</b>\n     *\n     * @param listener The callback that will run. Use {@code null} to stop receiving callbacks.\n     * @param handler The Handler that will run the callback. Use {@code null} to use MediaSync's\n     *     internal handler if it exists.\n     ",
    "links" : [ ]
  }, {
    "name" : "public void setSurface(@Nullable Surface surface)",
    "returnType" : "void",
    "comment" : "\n     * Sets the output surface for MediaSync.\n     * <p>\n     * Currently, this is only supported in the Initialized state.\n     *\n     * @param surface Specify a surface on which to render the video data.\n     * @throws IllegalArgumentException if the surface has been released, is invalid,\n     *     or can not be connected.\n     * @throws IllegalStateException if setting the surface is not supported, e.g.\n     *     not in the Initialized state, or another surface has already been set.\n     ",
    "links" : [ ]
  }, {
    "name" : "private final native void native_setSurface(@Nullable Surface surface)",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public void setAudioTrack(@Nullable AudioTrack audioTrack)",
    "returnType" : "void",
    "comment" : "\n     * Sets the audio track for MediaSync.\n     * <p>\n     * Currently, this is only supported in the Initialized state.\n     *\n     * @param audioTrack Specify an AudioTrack through which to render the audio data.\n     * @throws IllegalArgumentException if the audioTrack has been released, or is invalid.\n     * @throws IllegalStateException if setting the audio track is not supported, e.g.\n     *     not in the Initialized state, or another audio track has already been set.\n     ",
    "links" : [ ]
  }, {
    "name" : "private final native void native_setAudioTrack(@Nullable AudioTrack audioTrack)",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public final native Surface createInputSurface()",
    "returnType" : "Surface",
    "comment" : "\n     * Requests a Surface to use as the input. This may only be called after\n     * {@link #setSurface}.\n     * <p>\n     * The application is responsible for calling release() on the Surface when\n     * done.\n     * @throws IllegalStateException if not set, or another input surface has\n     *     already been created.\n     ",
    "links" : [ "#setSurface" ]
  }, {
    "name" : "public void setPlaybackParams(@NonNull PlaybackParams params)",
    "returnType" : "void",
    "comment" : "\n     * Sets playback rate using {@link PlaybackParams}.\n     * <p>\n     * When using MediaSync with {@link AudioTrack}, set playback params using this\n     * call instead of calling it directly on the track, so that the sync is aware of\n     * the params change.\n     * <p>\n     * This call also works if there is no audio track.\n     *\n     * @param params the playback params to use. {@link PlaybackParams#getSpeed\n     *     Speed} is the ratio between desired playback rate and normal one. 1.0 means\n     *     normal playback speed. 0.0 means pause. Value larger than 1.0 means faster playback,\n     *     while value between 0.0 and 1.0 for slower playback. <b>Note:</b> the normal rate\n     *     does not change as a result of this call. To restore the original rate at any time,\n     *     use speed of 1.0.\n     *\n     * @throws IllegalStateException if the internal sync engine or the audio track has not\n     *     been initialized.\n     * @throws IllegalArgumentException if the params are not supported.\n     ",
    "links" : [ "PlaybackParams", "AudioTrack", "PlaybackParams#getSpeed" ]
  }, {
    "name" : "public native PlaybackParams getPlaybackParams()",
    "returnType" : "PlaybackParams",
    "comment" : "\n     * Gets the playback rate using {@link PlaybackParams}.\n     *\n     * @return the playback rate being used.\n     *\n     * @throws IllegalStateException if the internal sync engine or the audio track has not\n     *     been initialized.\n     ",
    "links" : [ "PlaybackParams" ]
  }, {
    "name" : "private native float native_setPlaybackParams(@NonNull PlaybackParams params)",
    "returnType" : "float",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public void setSyncParams(@NonNull SyncParams params)",
    "returnType" : "void",
    "comment" : "\n     * Sets A/V sync mode.\n     *\n     * @param params the A/V sync params to apply\n     *\n     * @throws IllegalStateException if the internal player engine has not been\n     * initialized.\n     * @throws IllegalArgumentException if params are not supported.\n     ",
    "links" : [ ]
  }, {
    "name" : "private native float native_setSyncParams(@NonNull SyncParams params)",
    "returnType" : "float",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public native SyncParams getSyncParams()",
    "returnType" : "SyncParams",
    "comment" : "\n     * Gets the A/V sync mode.\n     *\n     * @return the A/V sync params\n     *\n     * @throws IllegalStateException if the internal player engine has not been\n     * initialized.\n     ",
    "links" : [ ]
  }, {
    "name" : "public void flush()",
    "returnType" : "void",
    "comment" : "\n     * Flushes all buffers from the sync object.\n     * <p>\n     * All pending unprocessed audio and video buffers are discarded. If an audio track was\n     * configured, it is flushed and stopped. If a video output surface was configured, the\n     * last frame queued to it is left on the frame. Queue a blank video frame to clear the\n     * surface,\n     * <p>\n     * No callbacks are received for the flushed buffers.\n     *\n     * @throws IllegalStateException if the internal player engine has not been\n     * initialized.\n     ",
    "links" : [ ]
  }, {
    "name" : "private final native void native_flush()",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public MediaTimestamp getTimestamp()",
    "returnType" : "MediaTimestamp",
    "comment" : "\n     * Get current playback position.\n     * <p>\n     * The MediaTimestamp represents how the media time correlates to the system time in\n     * a linear fashion using an anchor and a clock rate. During regular playback, the media\n     * time moves fairly constantly (though the anchor frame may be rebased to a current\n     * system time, the linear correlation stays steady). Therefore, this method does not\n     * need to be called often.\n     * <p>\n     * To help users get current playback position, this method always anchors the timestamp\n     * to the current {@link System#nanoTime system time}, so\n     * {@link MediaTimestamp#getAnchorMediaTimeUs} can be used as current playback position.\n     *\n     * @return a MediaTimestamp object if a timestamp is available, or {@code null} if no timestamp\n     *         is available, e.g. because the media player has not been initialized.\n     *\n     * @see MediaTimestamp\n     ",
    "links" : [ "System#nanoTime", "MediaTimestamp#getAnchorMediaTimeUs" ]
  }, {
    "name" : "private final native boolean native_getTimestamp(@NonNull MediaTimestamp timestamp)",
    "returnType" : "boolean",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public void queueAudio(@NonNull ByteBuffer audioData, int bufferId, long presentationTimeUs)",
    "returnType" : "void",
    "comment" : "\n     * Queues the audio data asynchronously for playback (AudioTrack must be in streaming mode).\n     * If the audio track was flushed as a result of {@link #flush}, it will be restarted.\n     * @param audioData the buffer that holds the data to play. This buffer will be returned\n     *     to the client via registered callback.\n     * @param bufferId an integer used to identify audioData. It will be returned to\n     *     the client along with audioData. This helps applications to keep track of audioData,\n     *     e.g., it can be used to store the output buffer index used by the audio codec.\n     * @param presentationTimeUs the presentation timestamp in microseconds for the first frame\n     *     in the buffer.\n     * @throws IllegalStateException if audio track is not set or internal configureation\n     *     has not been done correctly.\n     ",
    "links" : [ "#flush" ]
  }, {
    "name" : "private void postRenderAudio(long delayMillis)",
    "returnType" : "void",
    "comment" : " When called on user thread, make sure to check mAudioThread != null.",
    "links" : [ ]
  }, {
    "name" : "private final native void native_updateQueuedAudioData(int sizeInBytes, long presentationTimeUs)",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private final native long native_getPlayTimeForPendingAudioFrames()",
    "returnType" : "long",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private final void postReturnByteBuffer(@NonNull final AudioBuffer audioBuffer)",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private final void returnAudioBuffers()",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private void createAudioThread()",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private static final native void native_init()",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  } ],
  "variableNames" : [ "MEDIASYNC_ERROR_AUDIOTRACK_FAIL", "MEDIASYNC_ERROR_SURFACE_FAIL", "TAG", "EVENT_CALLBACK", "EVENT_SET_CALLBACK", "CB_RETURN_AUDIO_BUFFER", "mCallbackLock", "mCallbackHandler", "mCallback", "mOnErrorListenerLock", "mOnErrorListenerHandler", "mOnErrorListener", "mAudioThread", "mAudioHandler", "mAudioLooper", "mAudioLock", "mAudioTrack", "mAudioBuffers", "mPlaybackRate", "mNativeContext" ],
  "methodNames" : [ "private final native void native_setup()", "protected void finalize()", "private final native void native_finalize()", "public final void release()", "private final native void native_release()", "public void setCallback(@Nullable Callback cb, @Nullable Handler handler)", "public void setOnErrorListener(@Nullable OnErrorListener listener, @Nullable Handler handler)", "public void setSurface(@Nullable Surface surface)", "private final native void native_setSurface(@Nullable Surface surface)", "public void setAudioTrack(@Nullable AudioTrack audioTrack)", "private final native void native_setAudioTrack(@Nullable AudioTrack audioTrack)", "public final native Surface createInputSurface()", "public void setPlaybackParams(@NonNull PlaybackParams params)", "public native PlaybackParams getPlaybackParams()", "private native float native_setPlaybackParams(@NonNull PlaybackParams params)", "public void setSyncParams(@NonNull SyncParams params)", "private native float native_setSyncParams(@NonNull SyncParams params)", "public native SyncParams getSyncParams()", "public void flush()", "private final native void native_flush()", "public MediaTimestamp getTimestamp()", "private final native boolean native_getTimestamp(@NonNull MediaTimestamp timestamp)", "public void queueAudio(@NonNull ByteBuffer audioData, int bufferId, long presentationTimeUs)", "private void postRenderAudio(long delayMillis)", "private final native void native_updateQueuedAudioData(int sizeInBytes, long presentationTimeUs)", "private final native long native_getPlayTimeForPendingAudioFrames()", "private final void postReturnByteBuffer(@NonNull final AudioBuffer audioBuffer)", "private final void returnAudioBuffers()", "private void createAudioThread()", "private static final native void native_init()" ]
}