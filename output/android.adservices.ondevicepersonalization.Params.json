{
  "filePath" : "/home/maryam/clearblue/files/android-source-35/android/adservices/ondevicepersonalization/InferenceInput.java",
  "packageName" : "android.adservices.ondevicepersonalization",
  "className" : "Params",
  "comment" : "",
  "links" : [ ],
  "variables" : [ {
    "name" : "mKeyValueStore",
    "type" : "KeyValueStore",
    "comment" : "\n         * A {@link KeyValueStore} where pre-trained model is stored. Only supports TFLite model\n         * now.\n         ",
    "links" : [ "android.adservices.ondevicepersonalization.KeyValueStore" ]
  }, {
    "name" : "mModelKey",
    "type" : "String",
    "comment" : "\n         * The key of the table where the corresponding value stores a pre-trained model. Only\n         * supports TFLite model now.\n         ",
    "links" : [ ]
  }, {
    "name" : "DELEGATE_CPU",
    "type" : "int",
    "comment" : " The model inference will run on CPU. ",
    "links" : [ ]
  }, {
    "name" : "mDelegateType",
    "type" : "int",
    "comment" : "\n         * The delegate to run model inference. If not set, the default value is {@link\n         * #DELEGATE_CPU}.\n         ",
    "links" : [ "#DELEGATE_CPU" ]
  }, {
    "name" : "MODEL_TYPE_TENSORFLOW_LITE",
    "type" : "int",
    "comment" : " The model is a tensorflow lite model. ",
    "links" : [ ]
  }, {
    "name" : "mModelType",
    "type" : "int",
    "comment" : "\n         * The type of the pre-trained model. If not set, the default value is {@link\n         * #MODEL_TYPE_TENSORFLOW_LITE} . Only supports {@link #MODEL_TYPE_TENSORFLOW_LITE} for now.\n         ",
    "links" : [ "#MODEL_TYPE_TENSORFLOW_LITE" ]
  }, {
    "name" : "mRecommendedNumThreads",
    "type" : "int",
    "comment" : "\n         * The number of threads used for intraop parallelism on CPU, must be positive number.\n         * Adopters can set this field based on model architecture. The actual thread number depends\n         * on system resources and other constraints.\n         ",
    "links" : [ ]
  } ],
  "methods" : [ {
    "name" : "public KeyValueStore getKeyValueStore()",
    "returnType" : "KeyValueStore",
    "comment" : "\n         * A {@link KeyValueStore} where pre-trained model is stored. Only supports TFLite model\n         * now.\n         ",
    "links" : [ "android.adservices.ondevicepersonalization.KeyValueStore" ]
  }, {
    "name" : "public String getModelKey()",
    "returnType" : "String",
    "comment" : "\n         * The key of the table where the corresponding value stores a pre-trained model. Only\n         * supports TFLite model now.\n         ",
    "links" : [ ]
  }, {
    "name" : "public int getDelegateType()",
    "returnType" : "int",
    "comment" : "\n         * The delegate to run model inference. If not set, the default value is {@link\n         * #DELEGATE_CPU}.\n         ",
    "links" : [ "#DELEGATE_CPU" ]
  }, {
    "name" : "public int getModelType()",
    "returnType" : "int",
    "comment" : "\n         * The type of the pre-trained model. If not set, the default value is {@link\n         * #MODEL_TYPE_TENSORFLOW_LITE} . Only supports {@link #MODEL_TYPE_TENSORFLOW_LITE} for now.\n         ",
    "links" : [ "#MODEL_TYPE_TENSORFLOW_LITE" ]
  }, {
    "name" : "public int getRecommendedNumThreads()",
    "returnType" : "int",
    "comment" : "\n         * The number of threads used for intraop parallelism on CPU, must be positive number.\n         * Adopters can set this field based on model architecture. The actual thread number depends\n         * on system resources and other constraints.\n         ",
    "links" : [ ]
  }, {
    "name" : "public boolean equals(@android.annotation.Nullable Object o)",
    "returnType" : "boolean",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public int hashCode()",
    "returnType" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private void __metadata()",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  } ],
  "methodNames" : [ "public KeyValueStore getKeyValueStore()", "public String getModelKey()", "public int getDelegateType()", "public int getModelType()", "public int getRecommendedNumThreads()", "public boolean equals(@android.annotation.Nullable Object o)", "public int hashCode()", "private void __metadata()" ],
  "variableNames" : [ "mKeyValueStore", "mModelKey", "DELEGATE_CPU", "mDelegateType", "MODEL_TYPE_TENSORFLOW_LITE", "mModelType", "mRecommendedNumThreads" ]
}