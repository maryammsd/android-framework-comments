{
  "filePath" : "/home/maryam/clearblue/files/android-source-35/android/media/Image.java",
  "packageName" : "android.media",
  "className" : "Image",
  "comment" : "\n * <p>A single complete image buffer to use with a media source such as a\n * {@link MediaCodec} or a\n * {@link android.hardware.camera2.CameraDevice CameraDevice}.</p>\n *\n * <p>This class allows for efficient direct application access to the pixel\n * data of the Image through one or more\n * {@link java.nio.ByteBuffer ByteBuffers}. Each buffer is encapsulated in a\n * {@link Plane} that describes the layout of the pixel data in that plane. Due\n * to this direct access, and unlike the {@link android.graphics.Bitmap Bitmap} class,\n * Images are not directly usable as UI resources.</p>\n *\n * <p>Since Images are often directly produced or consumed by hardware\n * components, they are a limited resource shared across the system, and should\n * be closed as soon as they are no longer needed.</p>\n *\n * <p>For example, when using the {@link ImageReader} class to read out Images\n * from various media sources, not closing old Image objects will prevent the\n * availability of new Images once\n * {@link ImageReader#getMaxImages the maximum outstanding image count} is\n * reached. When this happens, the function acquiring new Images will typically\n * throw an {@link IllegalStateException}.</p>\n *\n * @see ImageReader\n ",
  "links" : [ "android.media.MediaCodec", "IllegalStateException", "Plane", "android.graphics.Bitmap", "android.hardware.camera2.CameraDevice", "android.media.ImageReader#getMaxImages", "android.media.ImageReader", "java.nio.ByteBuffer" ],
  "variables" : [ {
    "name" : "mIsImageValid",
    "type" : "boolean",
    "comment" : "\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "mDataSpace",
    "type" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mCropRect",
    "type" : "Rect",
    "comment" : "",
    "links" : [ ]
  } ],
  "methods" : [ {
    "name" : "protected void throwISEIfImageIsInvalid()",
    "returnType" : "void",
    "comment" : "\n     * Throw IllegalStateException if the image is invalid (already closed).\n     *\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "public abstract int getFormat()",
    "returnType" : "int",
    "comment" : "\n     * Get the format for this image. This format determines the number of\n     * ByteBuffers needed to represent the image, and the general layout of the\n     * pixel data in each ByteBuffer.\n     *\n     * <p>\n     * The format is one of the values from\n     * {@link android.graphics.ImageFormat ImageFormat},\n     * {@link android.graphics.PixelFormat PixelFormat}, or\n     * {@link android.hardware.HardwareBuffer HardwareBuffer}. The mapping between the\n     * formats and the planes is as follows (any formats not listed will have 1 plane):\n     * </p>\n     *\n     * <table>\n     * <tr>\n     *   <th>Format</th>\n     *   <th>Plane count</th>\n     *   <th>Layout details</th>\n     * </tr>\n     * <tr>\n     *   <td>{@link android.graphics.ImageFormat#JPEG JPEG}</td>\n     *   <td>1</td>\n     *   <td>Compressed data, so row and pixel strides are 0. To uncompress, use\n     *      {@link android.graphics.BitmapFactory#decodeByteArray BitmapFactory#decodeByteArray}.\n     *   </td>\n     * </tr>\n     * <tr>\n     *   <td>{@link android.graphics.ImageFormat#YUV_420_888 YUV_420_888}</td>\n     *   <td>3</td>\n     *   <td>A luminance plane followed by the Cb and Cr chroma planes.\n     *     The chroma planes have half the width and height of the luminance\n     *     plane (4:2:0 subsampling). Each pixel sample in each plane has 8 bits.\n     *     Each plane has its own row stride and pixel stride.</td>\n     * </tr>\n     * <tr>\n     *   <td>{@link android.graphics.ImageFormat#YUV_422_888 YUV_422_888}</td>\n     *   <td>3</td>\n     *   <td>A luminance plane followed by the Cb and Cr chroma planes.\n     *     The chroma planes have half the width and the full height of the luminance\n     *     plane (4:2:2 subsampling). Each pixel sample in each plane has 8 bits.\n     *     Each plane has its own row stride and pixel stride.</td>\n     * </tr>\n     * <tr>\n     *   <td>{@link android.graphics.ImageFormat#YUV_444_888 YUV_444_888}</td>\n     *   <td>3</td>\n     *   <td>A luminance plane followed by the Cb and Cr chroma planes.\n     *     The chroma planes have the same width and height as that of the luminance\n     *     plane (4:4:4 subsampling). Each pixel sample in each plane has 8 bits.\n     *     Each plane has its own row stride and pixel stride.</td>\n     * </tr>\n     * <tr>\n     *   <td>{@link android.graphics.ImageFormat#FLEX_RGB_888 FLEX_RGB_888}</td>\n     *   <td>3</td>\n     *   <td>A R (red) plane followed by the G (green) and B (blue) planes.\n     *     All planes have the same widths and heights.\n     *     Each pixel sample in each plane has 8 bits.\n     *     Each plane has its own row stride and pixel stride.</td>\n     * </tr>\n     * <tr>\n     *   <td>{@link android.graphics.ImageFormat#FLEX_RGBA_8888 FLEX_RGBA_8888}</td>\n     *   <td>4</td>\n     *   <td>A R (red) plane followed by the G (green), B (blue), and\n     *     A (alpha) planes. All planes have the same widths and heights.\n     *     Each pixel sample in each plane has 8 bits.\n     *     Each plane has its own row stride and pixel stride.</td>\n     * </tr>\n     * <tr>\n     *   <td>{@link android.graphics.ImageFormat#RAW_SENSOR RAW_SENSOR}</td>\n     *   <td>1</td>\n     *   <td>A single plane of raw sensor image data, with 16 bits per color\n     *     sample. The details of the layout need to be queried from the source of\n     *     the raw sensor data, such as\n     *     {@link android.hardware.camera2.CameraDevice CameraDevice}.\n     *   </td>\n     * </tr>\n     * <tr>\n     *   <td>{@link android.graphics.ImageFormat#RAW_PRIVATE RAW_PRIVATE}</td>\n     *   <td>1</td>\n     *   <td>A single plane of raw sensor image data of private layout.\n     *   The details of the layout is implementation specific. Row stride and\n     *   pixel stride are undefined for this format. Calling {@link Plane#getRowStride()}\n     *   or {@link Plane#getPixelStride()} on RAW_PRIVATE image will cause\n     *   UnSupportedOperationException being thrown.\n     *   </td>\n     * </tr>\n     * <tr>\n     *   <td>{@link android.graphics.ImageFormat#HEIC HEIC}</td>\n     *   <td>1</td>\n     *   <td>Compressed data, so row and pixel strides are 0. To uncompress, use\n     *      {@link android.graphics.BitmapFactory#decodeByteArray BitmapFactory#decodeByteArray}.\n     *   </td>\n     * </tr>\n     * <tr>\n     *   <td>{@link android.graphics.ImageFormat#YCBCR_P010 YCBCR_P010}</td>\n     *   <td>3</td>\n     *   <td>P010 is a 4:2:0 YCbCr semiplanar format comprised of a WxH Y plane\n     *     followed by a Wx(H/2) Cb and Cr planes. Each sample is represented by a 16-bit\n     *     little-endian value, with the lower 6 bits set to zero. Since this is guaranteed to be\n     *     a semi-planar format, the Cb plane can also be treated as an interleaved Cb/Cr plane.\n     *   </td>\n     * </tr>\n     * </table>\n     *\n     * @see android.graphics.ImageFormat\n     * @see android.graphics.PixelFormat\n     * @see android.hardware.HardwareBuffer\n     ",
    "links" : [ "android.graphics.ImageFormat#JPEG", "android.graphics.ImageFormat#RAW_SENSOR", "android.graphics.ImageFormat", "android.graphics.BitmapFactory#decodeByteArray", "android.graphics.ImageFormat#YUV_422_888", "#getPixelStride()", "#getRowStride()", "android.graphics.ImageFormat#YCBCR_P010", "android.graphics.ImageFormat#YUV_420_888", "android.graphics.ImageFormat#FLEX_RGB_888", "android.hardware.HardwareBuffer", "android.graphics.PixelFormat", "android.graphics.ImageFormat#YUV_444_888", "android.graphics.ImageFormat#RAW_PRIVATE", "android.graphics.ImageFormat#FLEX_RGBA_8888", "android.graphics.ImageFormat#HEIC", "android.hardware.camera2.CameraDevice" ]
  }, {
    "name" : "public abstract int getWidth()",
    "returnType" : "int",
    "comment" : "\n     * The width of the image in pixels. For formats where some color channels\n     * are subsampled, this is the width of the largest-resolution plane.\n     ",
    "links" : [ ]
  }, {
    "name" : "public abstract int getHeight()",
    "returnType" : "int",
    "comment" : "\n     * The height of the image in pixels. For formats where some color channels\n     * are subsampled, this is the height of the largest-resolution plane.\n     ",
    "links" : [ ]
  }, {
    "name" : "public abstract long getTimestamp()",
    "returnType" : "long",
    "comment" : "\n     * Get the timestamp associated with this frame.\n     * <p>\n     * The timestamp is measured in nanoseconds, and is normally monotonically\n     * increasing. The timestamps for the images from different sources may have\n     * different timebases therefore may not be comparable. The specific meaning and\n     * timebase of the timestamp depend on the source providing images. See\n     * {@link android.hardware.Camera Camera},\n     * {@link android.hardware.camera2.CameraDevice CameraDevice},\n     * {@link MediaPlayer} and {@link MediaCodec} for more details.\n     * </p>\n     ",
    "links" : [ "android.media.MediaCodec", "android.hardware.camera2.CameraDevice", "android.media.MediaPlayer", "android.hardware.Camera" ]
  }, {
    "name" : "public abstract int getTransform()",
    "returnType" : "int",
    "comment" : "\n     * Get the transformation associated with this frame.\n     * @return The window transformation that needs to be applied for this frame.\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "public abstract int getScalingMode()",
    "returnType" : "int",
    "comment" : "\n     * Get the scaling mode associated with this frame.\n     * @return The scaling mode that needs to be applied for this frame.\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "public SyncFence getFence() throws IOException",
    "returnType" : "SyncFence",
    "comment" : "\n     * Get the SyncFence object associated with this frame.\n     *\n     * <p>This function returns an invalid SyncFence after {@link #getPlanes()} on the image\n     * dequeued from {@link ImageWriter} via {@link ImageWriter#dequeueInputImage()}.</p>\n     *\n     * @return The SyncFence for this frame.\n     * @throws IOException if there is an error when a SyncFence object returns.\n     * @see android.hardware.SyncFence\n     ",
    "links" : [ "#getPlanes()", "android.media.ImageWriter", "android.media.ImageWriter#dequeueInputImage()" ]
  }, {
    "name" : "public int getPlaneCount()",
    "returnType" : "int",
    "comment" : "\n     * Get the number of planes.\n     * @return The number of expected planes.\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "public HardwareBuffer getHardwareBuffer()",
    "returnType" : "HardwareBuffer",
    "comment" : "\n     * Get the {@link android.hardware.HardwareBuffer HardwareBuffer} handle of the input image\n     * intended for GPU and/or hardware access.\n     * <p>\n     * The returned {@link android.hardware.HardwareBuffer HardwareBuffer} shall not be used\n     * after  {@link Image#close Image.close()} has been called.\n     * </p>\n     * @return the HardwareBuffer associated with this Image or null if this Image doesn't support\n     * this feature. (Unsupported use cases include Image instances obtained through\n     * {@link android.media.MediaCodec MediaCodec}, and on versions prior to Android P,\n     * {@link android.media.ImageWriter ImageWriter}).\n     ",
    "links" : [ "android.media.MediaCodec", "android.media.Image#close", "android.media.ImageWriter", "android.hardware.HardwareBuffer" ]
  }, {
    "name" : "public void setTimestamp(long timestamp)",
    "returnType" : "void",
    "comment" : "\n     * Set the timestamp associated with this frame.\n     * <p>\n     * The timestamp is measured in nanoseconds, and is normally monotonically\n     * increasing. The timestamps for the images from different sources may have\n     * different timebases therefore may not be comparable. The specific meaning and\n     * timebase of the timestamp depend on the source providing images. See\n     * {@link android.hardware.Camera Camera},\n     * {@link android.hardware.camera2.CameraDevice CameraDevice},\n     * {@link MediaPlayer} and {@link MediaCodec} for more details.\n     * </p>\n     * <p>\n     * For images dequeued from {@link ImageWriter} via\n     * {@link ImageWriter#dequeueInputImage()}, it's up to the application to\n     * set the timestamps correctly before sending them back to the\n     * {@link ImageWriter}, or the timestamp will be generated automatically when\n     * {@link ImageWriter#queueInputImage queueInputImage()} is called.\n     * </p>\n     *\n     * @param timestamp The timestamp to be set for this image.\n     ",
    "links" : [ "android.media.MediaCodec", "android.media.ImageWriter#queueInputImage", "android.media.ImageWriter", "android.hardware.camera2.CameraDevice", "android.media.MediaPlayer", "android.media.ImageWriter#dequeueInputImage()", "android.hardware.Camera" ]
  }, {
    "name" : "public void setFence(@NonNull SyncFence fence) throws IOException",
    "returnType" : "void",
    "comment" : "\n     * Set the fence file descriptor with this frame.\n     * @param fence The fence file descriptor to be set for this frame.\n     * @throws IOException if there is an error when setting a SyncFence.\n     * @see android.hardware.SyncFence\n     ",
    "links" : [ ]
  }, {
    "name" : "public int getDataSpace()",
    "returnType" : "int",
    "comment" : "\n     * Get the dataspace associated with this frame.\n     ",
    "links" : [ ]
  }, {
    "name" : "public void setDataSpace(@NamedDataSpace int dataSpace)",
    "returnType" : "void",
    "comment" : "\n     * Set the dataspace associated with this frame.\n     * <p>\n     * If dataspace for an image is not set, dataspace value depends on {@link android.view.Surface}\n     * that is provided in the {@link ImageWriter} constructor.\n     * </p>\n     *\n     * @param dataSpace The Dataspace to be set for this image\n     ",
    "links" : [ "android.view.Surface", "android.media.ImageWriter" ]
  }, {
    "name" : "public Rect getCropRect()",
    "returnType" : "Rect",
    "comment" : "\n     * Get the crop rectangle associated with this frame.\n     * <p>\n     * The crop rectangle specifies the region of valid pixels in the image,\n     * using coordinates in the largest-resolution plane.\n     ",
    "links" : [ ]
  }, {
    "name" : "public void setCropRect(Rect cropRect)",
    "returnType" : "void",
    "comment" : "\n     * Set the crop rectangle associated with this frame.\n     * <p>\n     * The crop rectangle specifies the region of valid pixels in the image,\n     * using coordinates in the largest-resolution plane.\n     ",
    "links" : [ ]
  }, {
    "name" : "public abstract Plane[] getPlanes()",
    "returnType" : "Plane[]",
    "comment" : "\n     * Get the array of pixel planes for this Image. The number of planes is\n     * determined by the format of the Image. The application will get an empty\n     * array if the image format is {@link android.graphics.ImageFormat#PRIVATE\n     * PRIVATE}, because the image pixel data is not directly accessible. The\n     * application can check the image format by calling\n     * {@link Image#getFormat()}.\n     ",
    "links" : [ "android.media.Image#getFormat()", "android.graphics.ImageFormat#PRIVATEPRIVATE" ]
  }, {
    "name" : "public abstract void close()",
    "returnType" : "void",
    "comment" : "\n     * Free up this frame for reuse.\n     * <p>\n     * After calling this method, calling any methods on this {@code Image} will\n     * result in an {@link IllegalStateException}, and attempting to read from\n     * or write to {@link ByteBuffer ByteBuffers} returned by an earlier\n     * {@link Plane#getBuffer} call will have undefined behavior. If the image\n     * was obtained from {@link ImageWriter} via\n     * {@link ImageWriter#dequeueInputImage()}, after calling this method, any\n     * image data filled by the application will be lost and the image will be\n     * returned to {@link ImageWriter} for reuse. Images given to\n     * {@link ImageWriter#queueInputImage queueInputImage()} are automatically\n     * closed.\n     * </p>\n     ",
    "links" : [ "IllegalStateException", "android.media.ImageWriter#queueInputImage", "android.media.ImageWriter", "android.media.ImageWriter#dequeueInputImage()", "java.nio.ByteBuffer", "#getBuffer" ]
  }, {
    "name" : "public boolean isAttachable()",
    "returnType" : "boolean",
    "comment" : "\n     * <p>\n     * Check if the image can be attached to a new owner (e.g. {@link ImageWriter}).\n     * </p>\n     * <p>\n     * This is a package private method that is only used internally.\n     * </p>\n     *\n     * @return true if the image is attachable to a new owner, false if the image is still attached\n     *         to its current owner, or the image is a stand-alone image and is not attachable to\n     *         a new owner.\n     * @hide\n     ",
    "links" : [ "android.media.ImageWriter" ]
  }, {
    "name" : " Object getOwner()",
    "returnType" : "Object",
    "comment" : "\n     * <p>\n     * Get the owner of the {@link Image}.\n     * </p>\n     * <p>\n     * The owner of an {@link Image} could be {@link ImageReader}, {@link ImageWriter},\n     * {@link MediaCodec} etc. This method returns the owner that produces this image, or null\n     * if the image is stand-alone image or the owner is unknown.\n     * </p>\n     * <p>\n     * This is a package private method that is only used internally.\n     * </p>\n     *\n     * @return The owner of the Image.\n     ",
    "links" : [ "android.media.MediaCodec", "android.media.Image", "android.media.ImageWriter", "android.media.ImageReader" ]
  }, {
    "name" : " long getNativeContext()",
    "returnType" : "long",
    "comment" : "\n     * Get native context (buffer pointer) associated with this image.\n     * <p>\n     * This is a package private method that is only used internally. It can be\n     * used to get the native buffer pointer and passed to native, which may be\n     * passed to {@link ImageWriter#attachAndQueueInputImage} to avoid a reverse\n     * JNI call.\n     * </p>\n     *\n     * @return native context associated with this Image.\n     ",
    "links" : [ "android.media.ImageWriter#attachAndQueueInputImage" ]
  } ],
  "methodNames" : [ "protected void throwISEIfImageIsInvalid()", "public abstract int getFormat()", "public abstract int getWidth()", "public abstract int getHeight()", "public abstract long getTimestamp()", "public abstract int getTransform()", "public abstract int getScalingMode()", "public SyncFence getFence() throws IOException", "public int getPlaneCount()", "public HardwareBuffer getHardwareBuffer()", "public void setTimestamp(long timestamp)", "public void setFence(@NonNull SyncFence fence) throws IOException", "public int getDataSpace()", "public void setDataSpace(@NamedDataSpace int dataSpace)", "public Rect getCropRect()", "public void setCropRect(Rect cropRect)", "public abstract Plane[] getPlanes()", "public abstract void close()", "public boolean isAttachable()", " Object getOwner()", " long getNativeContext()" ],
  "variableNames" : [ "mIsImageValid", "mDataSpace", "mCropRect" ]
}