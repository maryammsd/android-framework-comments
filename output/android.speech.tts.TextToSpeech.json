{
  "filePath" : "/home/maryam/clearblue/files/android-source-35/android/speech/tts/TextToSpeech.java",
  "packageName" : "android.speech.tts",
  "className" : "TextToSpeech",
  "comment" : "\n *\n * Synthesizes speech from text for immediate playback or to create a sound file.\n * <p>A TextToSpeech instance can only be used to synthesize text once it has completed its\n * initialization. Implement the {@link TextToSpeech.OnInitListener} to be\n * notified of the completion of the initialization.<br>\n * When you are done using the TextToSpeech instance, call the {@link #shutdown()} method\n * to release the native resources used by the TextToSpeech engine.\n *\n * Apps targeting Android 11 that use text-to-speech should declare {@link\n * TextToSpeech.Engine#INTENT_ACTION_TTS_SERVICE} in the {@code queries} elements of their\n * manifest:\n *\n * <pre>\n * &lt;queries&gt;\n *   ...\n *  &lt;intent&gt;\n *      &lt;action android:name=\"android.intent.action.TTS_SERVICE\" /&gt;\n *  &lt;/intent&gt;\n * &lt;/queries&gt;\n * </pre>\n ",
  "links" : [ "TextToSpeech.OnInitListener", "TextToSpeech.Engine#INTENT_ACTION_TTS_SERVICE", "#shutdown()" ],
  "variables" : [ {
    "name" : "TAG",
    "type" : "String",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "SUCCESS",
    "type" : "int",
    "comment" : "\n     * Denotes a successful operation.\n     ",
    "links" : [ ]
  }, {
    "name" : "ERROR",
    "type" : "int",
    "comment" : "\n     * Denotes a generic operation failure.\n     ",
    "links" : [ ]
  }, {
    "name" : "STOPPED",
    "type" : "int",
    "comment" : "\n     * Denotes a stop requested by a client. It's used only on the service side of the API,\n     * client should never expect to see this result code.\n     ",
    "links" : [ ]
  }, {
    "name" : "ERROR_SYNTHESIS",
    "type" : "int",
    "comment" : "\n     * Denotes a failure of a TTS engine to synthesize the given input.\n     ",
    "links" : [ ]
  }, {
    "name" : "ERROR_SERVICE",
    "type" : "int",
    "comment" : "\n     * Denotes a failure of a TTS service.\n     ",
    "links" : [ ]
  }, {
    "name" : "ERROR_OUTPUT",
    "type" : "int",
    "comment" : "\n     * Denotes a failure related to the output (audio device or a file).\n     ",
    "links" : [ ]
  }, {
    "name" : "ERROR_NETWORK",
    "type" : "int",
    "comment" : "\n     * Denotes a failure caused by a network connectivity problems.\n     ",
    "links" : [ ]
  }, {
    "name" : "ERROR_NETWORK_TIMEOUT",
    "type" : "int",
    "comment" : "\n     * Denotes a failure caused by network timeout.\n     ",
    "links" : [ ]
  }, {
    "name" : "ERROR_INVALID_REQUEST",
    "type" : "int",
    "comment" : "\n     * Denotes a failure caused by an invalid request.\n     ",
    "links" : [ ]
  }, {
    "name" : "ERROR_NOT_INSTALLED_YET",
    "type" : "int",
    "comment" : "\n     * Denotes a failure caused by an unfinished download of the voice data.\n     * @see Engine#KEY_FEATURE_NOT_INSTALLED\n     ",
    "links" : [ ]
  }, {
    "name" : "QUEUE_FLUSH",
    "type" : "int",
    "comment" : "\n     * Queue mode where all entries in the playback queue (media to be played\n     * and text to be synthesized) are dropped and replaced by the new entry.\n     * Queues are flushed with respect to a given calling app. Entries in the queue\n     * from other callees are not discarded.\n     ",
    "links" : [ ]
  }, {
    "name" : "QUEUE_ADD",
    "type" : "int",
    "comment" : "\n     * Queue mode where the new entry is added at the end of the playback queue.\n     ",
    "links" : [ ]
  }, {
    "name" : "QUEUE_DESTROY",
    "type" : "int",
    "comment" : "\n     * Queue mode where the entire playback queue is purged. This is different\n     * from {@link #QUEUE_FLUSH} in that all entries are purged, not just entries\n     * from a given caller.\n     *\n     * @hide\n     ",
    "links" : [ "#QUEUE_FLUSH" ]
  }, {
    "name" : "LANG_COUNTRY_VAR_AVAILABLE",
    "type" : "int",
    "comment" : "\n     * Denotes the language is available exactly as specified by the locale.\n     ",
    "links" : [ ]
  }, {
    "name" : "LANG_COUNTRY_AVAILABLE",
    "type" : "int",
    "comment" : "\n     * Denotes the language is available for the language and country specified\n     * by the locale, but not the variant.\n     ",
    "links" : [ ]
  }, {
    "name" : "LANG_AVAILABLE",
    "type" : "int",
    "comment" : "\n     * Denotes the language is available for the language by the locale,\n     * but not the country and variant.\n     ",
    "links" : [ ]
  }, {
    "name" : "LANG_MISSING_DATA",
    "type" : "int",
    "comment" : "\n     * Denotes the language data is missing.\n     ",
    "links" : [ ]
  }, {
    "name" : "LANG_NOT_SUPPORTED",
    "type" : "int",
    "comment" : "\n     * Denotes the language is not supported.\n     ",
    "links" : [ ]
  }, {
    "name" : "ACTION_TTS_QUEUE_PROCESSING_COMPLETED",
    "type" : "String",
    "comment" : "\n     * Broadcast Action: The TextToSpeech synthesizer has completed processing\n     * of all the text in the speech queue.\n     *\n     * Note that this notifies callers when the <b>engine</b> has finished has\n     * processing text data. Audio playback might not have completed (or even started)\n     * at this point. If you wish to be notified when this happens, see\n     * {@link OnUtteranceCompletedListener}.\n     ",
    "links" : [ "OnUtteranceCompletedListener" ]
  }, {
    "name" : "DEBUG",
    "type" : "boolean",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mContext",
    "type" : "Context",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mConnectingServiceConnection",
    "type" : "Connection",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mServiceConnection",
    "type" : "Connection",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mInitListener",
    "type" : "OnInitListener",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mUtteranceProgressListener",
    "type" : "UtteranceProgressListener",
    "comment" : " a binder thread.",
    "links" : [ ]
  }, {
    "name" : "mStartLock",
    "type" : "Object",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mRequestedEngine",
    "type" : "String",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mUseFallback",
    "type" : "boolean",
    "comment" : " too.",
    "links" : [ ]
  }, {
    "name" : "mEarcons",
    "type" : "Map<String, Uri>",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mUtterances",
    "type" : "Map<CharSequence, Uri>",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mParams",
    "type" : "Bundle",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mEnginesHelper",
    "type" : "TtsEngines",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mIsSystem",
    "type" : "boolean",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mInitExecutor",
    "type" : "Executor",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mCurrentEngine",
    "type" : "String",
    "comment" : "",
    "links" : [ ]
  } ],
  "methods" : [ {
    "name" : "private static void addDeviceSpecificSessionIdToParams(@NonNull Context context, @NonNull Bundle params)",
    "returnType" : "void",
    "comment" : "\n     * Add {@link VirtualDevice} specific playback audio session associated with context to\n     * parameters {@link Bundle} if applicable.\n     *\n     * @param context - {@link Context} context instance to extract the device specific audio\n     *      session id from.\n     * @param params - {@link Bundle} to add the device specific audio session id to.\n     ",
    "links" : [ "android.content.Context", "android.os.Bundle", "android.companion.virtual.VirtualDevice" ]
  }, {
    "name" : "private static int getDeviceSpecificPlaybackSessionId(@NonNull Context context)",
    "returnType" : "int",
    "comment" : "\n     * Helper method to fetch {@link VirtualDevice} specific playback audio session id for given\n     * {@link Context} instance.\n     *\n     * @param context - {@link Context} to fetch the audio sesion id for.\n     * @return audio session id corresponding to {@link VirtualDevice} in case the context is\n     *      associated with {@link VirtualDevice} configured with specific audio session id,\n     *      {@link AudioManager#AUDIO_SESSION_ID_GENERATE} otherwise.\n     * @see android.companion.virtual.VirtualDeviceManager#getAudioPlaybackSessionId(int)\n     ",
    "links" : [ "android.content.Context", "android.companion.virtual.VirtualDevice", "android.media.AudioManager#AUDIO_SESSION_ID_GENERATE" ]
  }, {
    "name" : "private R runActionNoReconnect(Action<R> action, R errorResult, String method, boolean onlyEstablishedConnection)",
    "returnType" : "R",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private R runAction(Action<R> action, R errorResult, String method)",
    "returnType" : "R",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private R runAction(Action<R> action, R errorResult, String method, boolean reconnect, boolean onlyEstablishedConnection)",
    "returnType" : "R",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private int initTts()",
    "returnType" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private boolean connectToEngine(String engine)",
    "returnType" : "boolean",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private void dispatchOnInit(int result)",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private IBinder getCallerIdentity()",
    "returnType" : "IBinder",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public void shutdown()",
    "returnType" : "void",
    "comment" : "\n     * Releases the resources used by the TextToSpeech engine.\n     * It is good practice for instance to call this method in the onDestroy() method of an Activity\n     * so the TextToSpeech engine can be cleanly stopped.\n     ",
    "links" : [ ]
  }, {
    "name" : "public int addSpeech(String text, String packagename, @RawRes int resourceId)",
    "returnType" : "int",
    "comment" : "\n     * Adds a mapping between a string of text and a sound resource in a\n     * package. After a call to this method, subsequent calls to\n     * {@link #speak(CharSequence, int, Bundle, String)} will play the specified sound resource\n     * if it is available, or synthesize the text it is missing.\n     *\n     * @param text\n     *            The string of text. Example: <code>\"south_south_east\"</code>\n     *\n     * @param packagename\n     *            Pass the packagename of the application that contains the\n     *            resource. If the resource is in your own application (this is\n     *            the most common case), then put the packagename of your\n     *            application here.<br/>\n     *            Example: <b>\"com.google.marvin.compass\"</b><br/>\n     *            The packagename can be found in the AndroidManifest.xml of\n     *            your application.\n     *            <p>\n     *            <code>&lt;manifest xmlns:android=&quot;...&quot;\n     *      package=&quot;<b>com.google.marvin.compass</b>&quot;&gt;</code>\n     *            </p>\n     *\n     * @param resourceId\n     *            Example: <code>R.raw.south_south_east</code>\n     *\n     * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.\n     ",
    "links" : [ "#speak(CharSequence", "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int addSpeech(CharSequence text, String packagename, @RawRes int resourceId)",
    "returnType" : "int",
    "comment" : "\n     * Adds a mapping between a CharSequence (may be spanned with TtsSpans) of text\n     * and a sound resource in a package. After a call to this method, subsequent calls to\n     * {@link #speak(CharSequence, int, Bundle, String)} will play the specified sound resource\n     * if it is available, or synthesize the text it is missing.\n     *\n     * @param text\n     *            The string of text. Example: <code>\"south_south_east\"</code>\n     *\n     * @param packagename\n     *            Pass the packagename of the application that contains the\n     *            resource. If the resource is in your own application (this is\n     *            the most common case), then put the packagename of your\n     *            application here.<br/>\n     *            Example: <b>\"com.google.marvin.compass\"</b><br/>\n     *            The packagename can be found in the AndroidManifest.xml of\n     *            your application.\n     *            <p>\n     *            <code>&lt;manifest xmlns:android=&quot;...&quot;\n     *      package=&quot;<b>com.google.marvin.compass</b>&quot;&gt;</code>\n     *            </p>\n     *\n     * @param resourceId\n     *            Example: <code>R.raw.south_south_east</code>\n     *\n     * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.\n     ",
    "links" : [ "#speak(CharSequence", "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int addSpeech(String text, String filename)",
    "returnType" : "int",
    "comment" : "\n     * Adds a mapping between a string of text and a sound file. Using this, it is possible to\n     * add custom pronounciations for a string of text. After a call to this method, subsequent\n     * calls to {@link #speak(CharSequence, int, Bundle, String)} will play the specified sound\n     * resource if it is available, or synthesize the text it is missing.\n     *\n     * @param text\n     *            The string of text. Example: <code>\"south_south_east\"</code>\n     * @param filename\n     *            The full path to the sound file (for example:\n     *            \"/sdcard/mysounds/hello.wav\")\n     *\n     * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.\n     ",
    "links" : [ "#speak(CharSequence", "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int addSpeech(CharSequence text, File file)",
    "returnType" : "int",
    "comment" : "\n     * Adds a mapping between a CharSequence (may be spanned with TtsSpans) and a sound file.\n     * Using this, it is possible to add custom pronounciations for a string of text. After a call\n     * to this method, subsequent calls to {@link #speak(CharSequence, int, Bundle, String)}\n     * will play the specified sound resource if it is available, or synthesize the text it is\n     * missing.\n     *\n     * @param text\n     *            The string of text. Example: <code>\"south_south_east\"</code>\n     * @param file\n     *            File object pointing to the sound file.\n     *\n     * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.\n     ",
    "links" : [ "#speak(CharSequence", "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int addSpeech(@NonNull CharSequence text, @NonNull Uri uri)",
    "returnType" : "int",
    "comment" : "\n     * Adds a mapping between a CharSequence (may be spanned with TtsSpans) and a sound file.\n     * Using this, it is possible to add custom pronounciations for a string of text. After a call\n     * to this method, subsequent calls to {@link #speak(CharSequence, int, Bundle, String)}\n     * will play the specified sound resource if it is available, or synthesize the text it is\n     * missing.\n     *\n     * @param text\n     *            The string of text. Example: <code>\"south_south_east\"</code>\n     * @param uri\n     *            Uri object pointing to the sound file.\n     *\n     * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.\n     ",
    "links" : [ "#speak(CharSequence", "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int addEarcon(String earcon, String packagename, @RawRes int resourceId)",
    "returnType" : "int",
    "comment" : "\n     * Adds a mapping between a string of text and a sound resource in a\n     * package. Use this to add custom earcons.\n     *\n     * @see #playEarcon(String, int, HashMap)\n     *\n     * @param earcon The name of the earcon.\n     *            Example: <code>\"[tick]\"</code><br/>\n     *\n     * @param packagename\n     *            the package name of the application that contains the\n     *            resource. This can for instance be the package name of your own application.\n     *            Example: <b>\"com.google.marvin.compass\"</b><br/>\n     *            The package name can be found in the AndroidManifest.xml of\n     *            the application containing the resource.\n     *            <p>\n     *            <code>&lt;manifest xmlns:android=&quot;...&quot;\n     *      package=&quot;<b>com.google.marvin.compass</b>&quot;&gt;</code>\n     *            </p>\n     *\n     * @param resourceId\n     *            Example: <code>R.raw.tick_snd</code>\n     *\n     * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.\n     ",
    "links" : [ "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int addEarcon(String earcon, String filename)",
    "returnType" : "int",
    "comment" : "\n     * Adds a mapping between a string of text and a sound file.\n     * Use this to add custom earcons.\n     *\n     * @see #playEarcon(String, int, HashMap)\n     *\n     * @param earcon\n     *            The name of the earcon.\n     *            Example: <code>\"[tick]\"</code>\n     * @param filename\n     *            The full path to the sound file (for example:\n     *            \"/sdcard/mysounds/tick.wav\")\n     *\n     * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.\n     *\n     * @deprecated As of API level 21, replaced by\n     *         {@link #addEarcon(String, File)}.\n     ",
    "links" : [ "#ERROR", "#SUCCESS", "#addEarcon(String" ]
  }, {
    "name" : "public int addEarcon(String earcon, File file)",
    "returnType" : "int",
    "comment" : "\n     * Adds a mapping between a string of text and a sound file.\n     * Use this to add custom earcons.\n     *\n     * @see #playEarcon(String, int, HashMap)\n     *\n     * @param earcon\n     *            The name of the earcon.\n     *            Example: <code>\"[tick]\"</code>\n     * @param file\n     *            File object pointing to the sound file.\n     *\n     * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.\n     ",
    "links" : [ "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int addEarcon(@NonNull String earcon, @NonNull Uri uri)",
    "returnType" : "int",
    "comment" : "\n     * Adds a mapping between a string of text and a sound file.\n     * Use this to add custom earcons.\n     *\n     * @see #playEarcon(String, int, HashMap)\n     *\n     * @param earcon\n     *            The name of the earcon.\n     *            Example: <code>\"[tick]\"</code>\n     * @param uri\n     *            Uri object pointing to the sound file.\n     *\n     * @return Code indicating success or failure. See {@link #ERROR} and {@link #SUCCESS}.\n     ",
    "links" : [ "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "private Uri makeResourceUri(String packageName, int resourceId)",
    "returnType" : "Uri",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public int speak(final CharSequence text, final int queueMode, final Bundle params, final String utteranceId)",
    "returnType" : "int",
    "comment" : "\n     * Speaks the text using the specified queuing strategy and speech parameters, the text may\n     * be spanned with TtsSpans.\n     * This method is asynchronous, i.e. the method just adds the request to the queue of TTS\n     * requests and then returns. The synthesis might not have finished (or even started!) at the\n     * time when this method returns. In order to reliably detect errors during synthesis,\n     * we recommend setting an utterance progress listener (see\n     * {@link #setOnUtteranceProgressListener}) and using the\n     * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.\n     *\n     * @param text The string of text to be spoken. No longer than\n     *            {@link #getMaxSpeechInputLength()} characters.\n     * @param queueMode The queuing strategy to use, {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.\n     * @param params Parameters for the request. Can be null.\n     *            Supported parameter names:\n     *            {@link Engine#KEY_PARAM_STREAM},\n     *            {@link Engine#KEY_PARAM_VOLUME},\n     *            {@link Engine#KEY_PARAM_PAN}.\n     *            Engine specific parameters may be passed in but the parameter keys\n     *            must be prefixed by the name of the engine they are intended for. For example\n     *            the keys \"com.svox.pico_foo\" and \"com.svox.pico:bar\" will be passed to the\n     *            engine named \"com.svox.pico\" if it is being used.\n     * @param utteranceId An unique identifier for this request.\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the speak operation.\n     ",
    "links" : [ "#QUEUE_FLUSH", "#KEY_PARAM_STREAM", "#KEY_PARAM_PAN", "#KEY_PARAM_UTTERANCE_ID", "#QUEUE_ADD", "#KEY_PARAM_VOLUME", "#ERROR", "#SUCCESS", "#getMaxSpeechInputLength()", "#setOnUtteranceProgressListener" ]
  }, {
    "name" : "public int speak(final String text, final int queueMode, final HashMap<String, String> params)",
    "returnType" : "int",
    "comment" : "\n     * Speaks the string using the specified queuing strategy and speech parameters.\n     * This method is asynchronous, i.e. the method just adds the request to the queue of TTS\n     * requests and then returns. The synthesis might not have finished (or even started!) at the\n     * time when this method returns. In order to reliably detect errors during synthesis,\n     * we recommend setting an utterance progress listener (see\n     * {@link #setOnUtteranceProgressListener}) and using the\n     * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.\n     *\n     * @param text The string of text to be spoken. No longer than\n     *            {@link #getMaxSpeechInputLength()} characters.\n     * @param queueMode The queuing strategy to use, {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.\n     * @param params Parameters for the request. Can be null.\n     *            Supported parameter names:\n     *            {@link Engine#KEY_PARAM_STREAM},\n     *            {@link Engine#KEY_PARAM_UTTERANCE_ID},\n     *            {@link Engine#KEY_PARAM_VOLUME},\n     *            {@link Engine#KEY_PARAM_PAN}.\n     *            Engine specific parameters may be passed in but the parameter keys\n     *            must be prefixed by the name of the engine they are intended for. For example\n     *            the keys \"com.svox.pico_foo\" and \"com.svox.pico:bar\" will be passed to the\n     *            engine named \"com.svox.pico\" if it is being used.\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the speak operation.\n     * @deprecated As of API level 21, replaced by\n     *         {@link #speak(CharSequence, int, Bundle, String)}.\n     ",
    "links" : [ "#speak(CharSequence", "#QUEUE_FLUSH", "#KEY_PARAM_STREAM", "#KEY_PARAM_PAN", "#KEY_PARAM_UTTERANCE_ID", "#QUEUE_ADD", "#KEY_PARAM_VOLUME", "#ERROR", "#SUCCESS", "#getMaxSpeechInputLength()", "#setOnUtteranceProgressListener" ]
  }, {
    "name" : "public int playEarcon(final String earcon, final int queueMode, final Bundle params, final String utteranceId)",
    "returnType" : "int",
    "comment" : "\n     * Plays the earcon using the specified queueing mode and parameters.\n     * The earcon must already have been added with {@link #addEarcon(String, String)} or\n     * {@link #addEarcon(String, String, int)}.\n     * This method is asynchronous, i.e. the method just adds the request to the queue of TTS\n     * requests and then returns. The synthesis might not have finished (or even started!) at the\n     * time when this method returns. In order to reliably detect errors during synthesis,\n     * we recommend setting an utterance progress listener (see\n     * {@link #setOnUtteranceProgressListener}) and using the\n     * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.\n     *\n     * @param earcon The earcon that should be played\n     * @param queueMode {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.\n     * @param params Parameters for the request. Can be null.\n     *            Supported parameter names:\n     *            {@link Engine#KEY_PARAM_STREAM},\n     *            Engine specific parameters may be passed in but the parameter keys\n     *            must be prefixed by the name of the engine they are intended for. For example\n     *            the keys \"com.svox.pico_foo\" and \"com.svox.pico:bar\" will be passed to the\n     *            engine named \"com.svox.pico\" if it is being used.\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the playEarcon operation.\n     ",
    "links" : [ "#QUEUE_FLUSH", "#KEY_PARAM_STREAM", "#KEY_PARAM_UTTERANCE_ID", "#QUEUE_ADD", "#addEarcon(String", "#ERROR", "#SUCCESS", "#setOnUtteranceProgressListener" ]
  }, {
    "name" : "public int playEarcon(final String earcon, final int queueMode, final HashMap<String, String> params)",
    "returnType" : "int",
    "comment" : "\n     * Plays the earcon using the specified queueing mode and parameters.\n     * The earcon must already have been added with {@link #addEarcon(String, String)} or\n     * {@link #addEarcon(String, String, int)}.\n     * This method is asynchronous, i.e. the method just adds the request to the queue of TTS\n     * requests and then returns. The synthesis might not have finished (or even started!) at the\n     * time when this method returns. In order to reliably detect errors during synthesis,\n     * we recommend setting an utterance progress listener (see\n     * {@link #setOnUtteranceProgressListener}) and using the\n     * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.\n     *\n     * @param earcon The earcon that should be played\n     * @param queueMode {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.\n     * @param params Parameters for the request. Can be null.\n     *            Supported parameter names:\n     *            {@link Engine#KEY_PARAM_STREAM},\n     *            {@link Engine#KEY_PARAM_UTTERANCE_ID}.\n     *            Engine specific parameters may be passed in but the parameter keys\n     *            must be prefixed by the name of the engine they are intended for. For example\n     *            the keys \"com.svox.pico_foo\" and \"com.svox.pico:bar\" will be passed to the\n     *            engine named \"com.svox.pico\" if it is being used.\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the playEarcon operation.\n     * @deprecated As of API level 21, replaced by\n     *         {@link #playEarcon(String, int, Bundle, String)}.\n     ",
    "links" : [ "#QUEUE_FLUSH", "#KEY_PARAM_STREAM", "#KEY_PARAM_UTTERANCE_ID", "#playEarcon(String", "#QUEUE_ADD", "#addEarcon(String", "#ERROR", "#SUCCESS", "#setOnUtteranceProgressListener" ]
  }, {
    "name" : "public int playSilentUtterance(final long durationInMs, final int queueMode, final String utteranceId)",
    "returnType" : "int",
    "comment" : "\n     * Plays silence for the specified amount of time using the specified\n     * queue mode.\n     * This method is asynchronous, i.e. the method just adds the request to the queue of TTS\n     * requests and then returns. The synthesis might not have finished (or even started!) at the\n     * time when this method returns. In order to reliably detect errors during synthesis,\n     * we recommend setting an utterance progress listener (see\n     * {@link #setOnUtteranceProgressListener}) and using the\n     * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.\n     *\n     * @param durationInMs The duration of the silence.\n     * @param queueMode {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.\n     * @param utteranceId An unique identifier for this request.\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the playSilentUtterance operation.\n     ",
    "links" : [ "#QUEUE_FLUSH", "#KEY_PARAM_UTTERANCE_ID", "#QUEUE_ADD", "#ERROR", "#SUCCESS", "#setOnUtteranceProgressListener" ]
  }, {
    "name" : "public int playSilence(final long durationInMs, final int queueMode, final HashMap<String, String> params)",
    "returnType" : "int",
    "comment" : "\n     * Plays silence for the specified amount of time using the specified\n     * queue mode.\n     * This method is asynchronous, i.e. the method just adds the request to the queue of TTS\n     * requests and then returns. The synthesis might not have finished (or even started!) at the\n     * time when this method returns. In order to reliably detect errors during synthesis,\n     * we recommend setting an utterance progress listener (see\n     * {@link #setOnUtteranceProgressListener}) and using the\n     * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.\n     *\n     * @param durationInMs The duration of the silence.\n     * @param queueMode {@link #QUEUE_ADD} or {@link #QUEUE_FLUSH}.\n     * @param params Parameters for the request. Can be null.\n     *            Supported parameter names:\n     *            {@link Engine#KEY_PARAM_UTTERANCE_ID}.\n     *            Engine specific parameters may be passed in but the parameter keys\n     *            must be prefixed by the name of the engine they are intended for. For example\n     *            the keys \"com.svox.pico_foo\" and \"com.svox.pico:bar\" will be passed to the\n     *            engine named \"com.svox.pico\" if it is being used.\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the playSilence operation.\n     * @deprecated As of API level 21, replaced by\n     *         {@link #playSilentUtterance(long, int, String)}.\n     ",
    "links" : [ "#QUEUE_FLUSH", "#KEY_PARAM_UTTERANCE_ID", "#playSilentUtterance(long", "#QUEUE_ADD", "#ERROR", "#SUCCESS", "#setOnUtteranceProgressListener" ]
  }, {
    "name" : "public Set<String> getFeatures(final Locale locale)",
    "returnType" : "Set<String>",
    "comment" : "\n     * Queries the engine for the set of features it supports for a given locale.\n     * Features can either be framework defined, e.g.\n     * {@link TextToSpeech.Engine#KEY_FEATURE_NETWORK_SYNTHESIS} or engine specific.\n     * Engine specific keys must be prefixed by the name of the engine they\n     * are intended for. These keys can be used as parameters to\n     * {@link TextToSpeech#speak(String, int, java.util.HashMap)} and\n     * {@link TextToSpeech#synthesizeToFile(String, java.util.HashMap, String)}.\n     *\n     * Features values are strings and their values must meet restrictions described in their\n     * documentation.\n     *\n     * @param locale The locale to query features for.\n     * @return Set instance. May return {@code null} on error.\n     * @deprecated As of API level 21, please use voices. In order to query features of the voice,\n     * call {@link #getVoices()} to retrieve the list of available voices and\n     * {@link Voice#getFeatures()} to retrieve the set of features.\n     ",
    "links" : [ "TextToSpeech.Engine#KEY_FEATURE_NETWORK_SYNTHESIS", "#getVoices()", "android.speech.tts.TextToSpeech#speak(String", "android.speech.tts.Voice#getFeatures()", "android.speech.tts.TextToSpeech#synthesizeToFile(String" ]
  }, {
    "name" : "public boolean isSpeaking()",
    "returnType" : "boolean",
    "comment" : "\n     * Checks whether the TTS engine is busy speaking. Note that a speech item is\n     * considered complete once it's audio data has been sent to the audio mixer, or\n     * written to a file. There might be a finite lag between this point, and when\n     * the audio hardware completes playback.\n     *\n     * @return {@code true} if the TTS engine is speaking.\n     ",
    "links" : [ ]
  }, {
    "name" : "public int stop()",
    "returnType" : "int",
    "comment" : "\n     * Interrupts the current utterance (whether played or rendered to file) and discards other\n     * utterances in the queue.\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS}.\n     ",
    "links" : [ "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int setSpeechRate(float speechRate)",
    "returnType" : "int",
    "comment" : "\n     * Sets the speech rate.\n     *\n     * This has no effect on any pre-recorded speech.\n     *\n     * @param speechRate Speech rate. {@code 1.0} is the normal speech rate,\n     *            lower values slow down the speech ({@code 0.5} is half the normal speech rate),\n     *            greater values accelerate it ({@code 2.0} is twice the normal speech rate).\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS}.\n     ",
    "links" : [ "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int setPitch(float pitch)",
    "returnType" : "int",
    "comment" : "\n     * Sets the speech pitch for the TextToSpeech engine.\n     *\n     * This has no effect on any pre-recorded speech.\n     *\n     * @param pitch Speech pitch. {@code 1.0} is the normal pitch,\n     *            lower values lower the tone of the synthesized voice,\n     *            greater values increase it.\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS}.\n     ",
    "links" : [ "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int setAudioAttributes(AudioAttributes audioAttributes)",
    "returnType" : "int",
    "comment" : "\n     * Sets the audio attributes to be used when speaking text or playing\n     * back a file.\n     *\n     * @param audioAttributes Valid AudioAttributes instance.\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS}.\n     ",
    "links" : [ "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public String getCurrentEngine()",
    "returnType" : "String",
    "comment" : "\n     * @return the engine currently in use by this TextToSpeech instance.\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "public Locale getDefaultLanguage()",
    "returnType" : "Locale",
    "comment" : "\n     * Returns a Locale instance describing the language currently being used as the default\n     * Text-to-speech language.\n     *\n     * The locale object returned by this method is NOT a valid one. It has identical form to the\n     * one in {@link #getLanguage()}. Please refer to {@link #getLanguage()} for more information.\n     *\n     * @return language, country (if any) and variant (if any) used by the client stored in a\n     *     Locale instance, or {@code null} on error.\n     * @deprecated As of API level 21, use <code>getDefaultVoice().getLocale()</code> ({@link\n     *   #getDefaultVoice()})\n     ",
    "links" : [ "#getLanguage()", "#getDefaultVoice()" ]
  }, {
    "name" : "public int setLanguage(final Locale loc)",
    "returnType" : "int",
    "comment" : "\n     * Sets the text-to-speech language.\n     * The TTS engine will try to use the closest match to the specified\n     * language as represented by the Locale, but there is no guarantee that the exact same Locale\n     * will be used. Use {@link #isLanguageAvailable(Locale)} to check the level of support\n     * before choosing the language to use for the next utterances.\n     *\n     * This method sets the current voice to the default one for the given Locale;\n     * {@link #getVoice()} can be used to retrieve it.\n     *\n     * @param loc The locale describing the language to be used.\n     *\n     * @return Code indicating the support status for the locale. See {@link #LANG_AVAILABLE},\n     *         {@link #LANG_COUNTRY_AVAILABLE}, {@link #LANG_COUNTRY_VAR_AVAILABLE},\n     *         {@link #LANG_MISSING_DATA} and {@link #LANG_NOT_SUPPORTED}.\n     ",
    "links" : [ "#getVoice()", "#LANG_COUNTRY_VAR_AVAILABLE", "#LANG_MISSING_DATA", "#isLanguageAvailable(Locale)", "#LANG_NOT_SUPPORTED", "#LANG_AVAILABLE", "#LANG_COUNTRY_AVAILABLE" ]
  }, {
    "name" : "public Locale getLanguage()",
    "returnType" : "Locale",
    "comment" : "\n     * Returns a Locale instance describing the language currently being used for synthesis\n     * requests sent to the TextToSpeech engine.\n     *\n     * In Android 4.2 and before (API <= 17) this function returns the language that is currently\n     * being used by the TTS engine. That is the last language set by this or any other\n     * client by a {@link TextToSpeech#setLanguage} call to the same engine.\n     *\n     * In Android versions after 4.2 this function returns the language that is currently being\n     * used for the synthesis requests sent from this client. That is the last language set\n     * by a {@link TextToSpeech#setLanguage} call on this instance.\n     *\n     * If a voice is set (by {@link #setVoice(Voice)}), getLanguage will return the language of\n     * the currently set voice.\n     *\n     * Please note that the Locale object returned by this method is NOT a valid Locale object. Its\n     * language field contains a three-letter ISO 639-2/T code (where a proper Locale would use\n     * a two-letter ISO 639-1 code), and the country field contains a three-letter ISO 3166 country\n     * code (where a proper Locale would use a two-letter ISO 3166-1 code).\n     *\n     * @return language, country (if any) and variant (if any) used by the client stored in a\n     *     Locale instance, or {@code null} on error.\n     *\n     * @deprecated As of API level 21, please use <code>getVoice().getLocale()</code>\n     * ({@link #getVoice()}).\n     ",
    "links" : [ "#setVoice(Voice)", "#getVoice()", "android.speech.tts.TextToSpeech#setLanguage" ]
  }, {
    "name" : "public Set<Locale> getAvailableLanguages()",
    "returnType" : "Set<Locale>",
    "comment" : "\n     * Query the engine about the set of available languages.\n     ",
    "links" : [ ]
  }, {
    "name" : "public Set<Voice> getVoices()",
    "returnType" : "Set<Voice>",
    "comment" : "\n     * Query the engine about the set of available voices.\n     *\n     * Each TTS Engine can expose multiple voices for each locale, each with a different set of\n     * features.\n     *\n     * @see #setVoice(Voice)\n     * @see Voice\n     ",
    "links" : [ ]
  }, {
    "name" : "public int setVoice(final Voice voice)",
    "returnType" : "int",
    "comment" : "\n     * Sets the text-to-speech voice.\n     *\n     * @param voice One of objects returned by {@link #getVoices()}.\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS}.\n     *\n     * @see #getVoices\n     * @see Voice\n     ",
    "links" : [ "#getVoices()", "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public Voice getVoice()",
    "returnType" : "Voice",
    "comment" : "\n     * Returns a Voice instance describing the voice currently being used for synthesis\n     * requests sent to the TextToSpeech engine.\n     *\n     * @return Voice instance used by the client, or {@code null} if not set or on error.\n     *\n     * @see #getVoices\n     * @see #setVoice\n     * @see Voice\n     ",
    "links" : [ ]
  }, {
    "name" : "private Voice getVoice(ITextToSpeechService service, String voiceName) throws RemoteException",
    "returnType" : "Voice",
    "comment" : "\n     * Returns a Voice instance of the voice with the given voice name.\n     *\n     * @return Voice instance with the given voice name, or {@code null} if not set or on error.\n     *\n     * @see Voice\n     ",
    "links" : [ ]
  }, {
    "name" : "public Voice getDefaultVoice()",
    "returnType" : "Voice",
    "comment" : "\n     * Returns a Voice instance that's the default voice for the default Text-to-speech language.\n     * @return The default voice instance for the default language, or {@code null} if not set or\n     *     on error.\n     ",
    "links" : [ ]
  }, {
    "name" : "public int isLanguageAvailable(final Locale loc)",
    "returnType" : "int",
    "comment" : "\n     * Checks if the specified language as represented by the Locale is available and supported.\n     *\n     * @param loc The Locale describing the language to be used.\n     *\n     * @return Code indicating the support status for the locale. See {@link #LANG_AVAILABLE},\n     *         {@link #LANG_COUNTRY_AVAILABLE}, {@link #LANG_COUNTRY_VAR_AVAILABLE},\n     *         {@link #LANG_MISSING_DATA} and {@link #LANG_NOT_SUPPORTED}.\n     ",
    "links" : [ "#LANG_COUNTRY_VAR_AVAILABLE", "#LANG_MISSING_DATA", "#LANG_NOT_SUPPORTED", "#LANG_AVAILABLE", "#LANG_COUNTRY_AVAILABLE" ]
  }, {
    "name" : "public int synthesizeToFile(@NonNull final CharSequence text, @NonNull final Bundle params, @NonNull final ParcelFileDescriptor fileDescriptor, @NonNull final String utteranceId)",
    "returnType" : "int",
    "comment" : "\n     * Synthesizes the given text to a ParcelFileDescriptor using the specified parameters.\n     * This method is asynchronous, i.e. the method just adds the request to the queue of TTS\n     * requests and then returns. The synthesis might not have finished (or even started!) at the\n     * time when this method returns. In order to reliably detect errors during synthesis,\n     * we recommend setting an utterance progress listener (see\n     * {@link #setOnUtteranceProgressListener}).\n     *\n     * @param text The text that should be synthesized. No longer than\n     *            {@link #getMaxSpeechInputLength()} characters.\n     * @param params Parameters for the request.\n     *            Engine specific parameters may be passed in but the parameter keys\n     *            must be prefixed by the name of the engine they are intended for. For example\n     *            the keys \"com.svox.pico_foo\" and \"com.svox.pico:bar\" will be passed to the engine\n     *            named \"com.svox.pico\" if it is being used.\n     * @param fileDescriptor ParcelFileDescriptor to write the generated audio data to.\n     * @param utteranceId An unique identifier for this request.\n     * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the synthesizeToFile operation.\n     ",
    "links" : [ "#ERROR", "#SUCCESS", "#getMaxSpeechInputLength()", "#setOnUtteranceProgressListener" ]
  }, {
    "name" : "public int synthesizeToFile(final CharSequence text, final Bundle params, final File file, final String utteranceId)",
    "returnType" : "int",
    "comment" : "\n     * Synthesizes the given text to a file using the specified parameters.\n     * This method is asynchronous, i.e. the method just adds the request to the queue of TTS\n     * requests and then returns. The synthesis might not have finished (or even started!) at the\n     * time when this method returns. In order to reliably detect errors during synthesis,\n     * we recommend setting an utterance progress listener (see\n     * {@link #setOnUtteranceProgressListener}).\n     *\n     * @param text The text that should be synthesized. No longer than\n     *            {@link #getMaxSpeechInputLength()} characters.\n     * @param params Parameters for the request. Cannot be null.\n     *            Engine specific parameters may be passed in but the parameter keys\n     *            must be prefixed by the name of the engine they are intended for. For example\n     *            the keys \"com.svox.pico_foo\" and \"com.svox.pico:bar\" will be passed to the\n     *            engine named \"com.svox.pico\" if it is being used.\n     * @param file File to write the generated audio data to.\n     * @param utteranceId An unique identifier for this request.\n     * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the synthesizeToFile operation.\n     ",
    "links" : [ "#ERROR", "#SUCCESS", "#getMaxSpeechInputLength()", "#setOnUtteranceProgressListener" ]
  }, {
    "name" : "public int synthesizeToFile(final String text, final HashMap<String, String> params, final String filename)",
    "returnType" : "int",
    "comment" : "\n     * Synthesizes the given text to a file using the specified parameters.\n     * This method is asynchronous, i.e. the method just adds the request to the queue of TTS\n     * requests and then returns. The synthesis might not have finished (or even started!) at the\n     * time when this method returns. In order to reliably detect errors during synthesis,\n     * we recommend setting an utterance progress listener (see\n     * {@link #setOnUtteranceProgressListener}) and using the\n     * {@link Engine#KEY_PARAM_UTTERANCE_ID} parameter.\n     *\n     * @param text The text that should be synthesized. No longer than\n     *            {@link #getMaxSpeechInputLength()} characters.\n     * @param params Parameters for the request. Cannot be null.\n     *            Supported parameter names:\n     *            {@link Engine#KEY_PARAM_UTTERANCE_ID}.\n     *            Engine specific parameters may be passed in but the parameter keys\n     *            must be prefixed by the name of the engine they are intended for. For example\n     *            the keys \"com.svox.pico_foo\" and \"com.svox.pico:bar\" will be passed to the\n     *            engine named \"com.svox.pico\" if it is being used.\n     * @param filename Absolute file filename to write the generated audio data to.It should be\n     *            something like \"/sdcard/myappsounds/mysound.wav\".\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS} of <b>queuing</b> the synthesizeToFile operation.\n     * @deprecated As of API level 21, replaced by\n     *         {@link #synthesizeToFile(CharSequence, Bundle, File, String)}.\n     ",
    "links" : [ "#KEY_PARAM_UTTERANCE_ID", "#ERROR", "#SUCCESS", "#getMaxSpeechInputLength()", "#synthesizeToFile(CharSequence", "#setOnUtteranceProgressListener" ]
  }, {
    "name" : "private Bundle convertParamsHashMaptoBundle(HashMap<String, String> params)",
    "returnType" : "Bundle",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private Bundle getParams(Bundle params)",
    "returnType" : "Bundle",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private static boolean verifyIntegerBundleParam(Bundle bundle, String key)",
    "returnType" : "boolean",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private static boolean verifyStringBundleParam(Bundle bundle, String key)",
    "returnType" : "boolean",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private static boolean verifyBooleanBundleParam(Bundle bundle, String key)",
    "returnType" : "boolean",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private static boolean verifyFloatBundleParam(Bundle bundle, String key)",
    "returnType" : "boolean",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private void copyStringParam(Bundle bundle, HashMap<String, String> params, String key)",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private void copyIntParam(Bundle bundle, HashMap<String, String> params, String key)",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private void copyFloatParam(Bundle bundle, HashMap<String, String> params, String key)",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public int setOnUtteranceCompletedListener(final OnUtteranceCompletedListener listener)",
    "returnType" : "int",
    "comment" : "\n     * Sets the listener that will be notified when synthesis of an utterance completes.\n     *\n     * @param listener The listener to use.\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS}.\n     *\n     * @deprecated Use {@link #setOnUtteranceProgressListener(UtteranceProgressListener)}\n     *        instead.\n     ",
    "links" : [ "#setOnUtteranceProgressListener(UtteranceProgressListener)", "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int setOnUtteranceProgressListener(UtteranceProgressListener listener)",
    "returnType" : "int",
    "comment" : "\n     * Sets the listener that will be notified of various events related to the\n     * synthesis of a given utterance.\n     *\n     * See {@link UtteranceProgressListener} and\n     * {@link TextToSpeech.Engine#KEY_PARAM_UTTERANCE_ID}.\n     *\n     * @param listener the listener to use.\n     * @return {@link #ERROR} or {@link #SUCCESS}\n     ",
    "links" : [ "TextToSpeech.Engine#KEY_PARAM_UTTERANCE_ID", "android.speech.tts.UtteranceProgressListener", "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public int setEngineByPackageName(String enginePackageName)",
    "returnType" : "int",
    "comment" : "\n     * Sets the TTS engine to use.\n     *\n     * @deprecated This doesn't inform callers when the TTS engine has been\n     *        initialized. {@link #TextToSpeech(Context, OnInitListener, String)}\n     *        can be used with the appropriate engine name. Also, there is no\n     *        guarantee that the engine specified will be loaded. If it isn't\n     *        installed or disabled, the user / system wide defaults will apply.\n     *\n     * @param enginePackageName The package name for the synthesis engine (e.g. \"com.svox.pico\")\n     *\n     * @return {@link #ERROR} or {@link #SUCCESS}.\n     ",
    "links" : [ "#TextToSpeech(Context", "#ERROR", "#SUCCESS" ]
  }, {
    "name" : "public String getDefaultEngine()",
    "returnType" : "String",
    "comment" : "\n     * Gets the package name of the default speech synthesis engine.\n     *\n     * @return Package name of the TTS engine that the user has chosen\n     *        as their default.\n     ",
    "links" : [ ]
  }, {
    "name" : "public boolean areDefaultsEnforced()",
    "returnType" : "boolean",
    "comment" : "\n     * Checks whether the user's settings should override settings requested\n     * by the calling application. As of the Ice cream sandwich release,\n     * user settings never forcibly override the app's settings.\n     ",
    "links" : [ ]
  }, {
    "name" : "public List<EngineInfo> getEngines()",
    "returnType" : "List<EngineInfo>",
    "comment" : "\n     * Gets a list of all installed TTS engines.\n     *\n     * @return A list of engine info objects. The list can be empty, but never {@code null}.\n     ",
    "links" : [ ]
  }, {
    "name" : "public static int getMaxSpeechInputLength()",
    "returnType" : "int",
    "comment" : "\n     * Limit of length of input string passed to speak and synthesizeToFile.\n     *\n     * @see #speak\n     * @see #synthesizeToFile\n     ",
    "links" : [ ]
  } ],
  "methodNames" : [ "private static void addDeviceSpecificSessionIdToParams(@NonNull Context context, @NonNull Bundle params)", "private static int getDeviceSpecificPlaybackSessionId(@NonNull Context context)", "private R runActionNoReconnect(Action<R> action, R errorResult, String method, boolean onlyEstablishedConnection)", "private R runAction(Action<R> action, R errorResult, String method)", "private R runAction(Action<R> action, R errorResult, String method, boolean reconnect, boolean onlyEstablishedConnection)", "private int initTts()", "private boolean connectToEngine(String engine)", "private void dispatchOnInit(int result)", "private IBinder getCallerIdentity()", "public void shutdown()", "public int addSpeech(String text, String packagename, @RawRes int resourceId)", "public int addSpeech(CharSequence text, String packagename, @RawRes int resourceId)", "public int addSpeech(String text, String filename)", "public int addSpeech(CharSequence text, File file)", "public int addSpeech(@NonNull CharSequence text, @NonNull Uri uri)", "public int addEarcon(String earcon, String packagename, @RawRes int resourceId)", "public int addEarcon(String earcon, String filename)", "public int addEarcon(String earcon, File file)", "public int addEarcon(@NonNull String earcon, @NonNull Uri uri)", "private Uri makeResourceUri(String packageName, int resourceId)", "public int speak(final CharSequence text, final int queueMode, final Bundle params, final String utteranceId)", "public int speak(final String text, final int queueMode, final HashMap<String, String> params)", "public int playEarcon(final String earcon, final int queueMode, final Bundle params, final String utteranceId)", "public int playEarcon(final String earcon, final int queueMode, final HashMap<String, String> params)", "public int playSilentUtterance(final long durationInMs, final int queueMode, final String utteranceId)", "public int playSilence(final long durationInMs, final int queueMode, final HashMap<String, String> params)", "public Set<String> getFeatures(final Locale locale)", "public boolean isSpeaking()", "public int stop()", "public int setSpeechRate(float speechRate)", "public int setPitch(float pitch)", "public int setAudioAttributes(AudioAttributes audioAttributes)", "public String getCurrentEngine()", "public Locale getDefaultLanguage()", "public int setLanguage(final Locale loc)", "public Locale getLanguage()", "public Set<Locale> getAvailableLanguages()", "public Set<Voice> getVoices()", "public int setVoice(final Voice voice)", "public Voice getVoice()", "private Voice getVoice(ITextToSpeechService service, String voiceName) throws RemoteException", "public Voice getDefaultVoice()", "public int isLanguageAvailable(final Locale loc)", "public int synthesizeToFile(@NonNull final CharSequence text, @NonNull final Bundle params, @NonNull final ParcelFileDescriptor fileDescriptor, @NonNull final String utteranceId)", "public int synthesizeToFile(final CharSequence text, final Bundle params, final File file, final String utteranceId)", "public int synthesizeToFile(final String text, final HashMap<String, String> params, final String filename)", "private Bundle convertParamsHashMaptoBundle(HashMap<String, String> params)", "private Bundle getParams(Bundle params)", "private static boolean verifyIntegerBundleParam(Bundle bundle, String key)", "private static boolean verifyStringBundleParam(Bundle bundle, String key)", "private static boolean verifyBooleanBundleParam(Bundle bundle, String key)", "private static boolean verifyFloatBundleParam(Bundle bundle, String key)", "private void copyStringParam(Bundle bundle, HashMap<String, String> params, String key)", "private void copyIntParam(Bundle bundle, HashMap<String, String> params, String key)", "private void copyFloatParam(Bundle bundle, HashMap<String, String> params, String key)", "public int setOnUtteranceCompletedListener(final OnUtteranceCompletedListener listener)", "public int setOnUtteranceProgressListener(UtteranceProgressListener listener)", "public int setEngineByPackageName(String enginePackageName)", "public String getDefaultEngine()", "public boolean areDefaultsEnforced()", "public List<EngineInfo> getEngines()", "public static int getMaxSpeechInputLength()" ],
  "variableNames" : [ "TAG", "SUCCESS", "ERROR", "STOPPED", "ERROR_SYNTHESIS", "ERROR_SERVICE", "ERROR_OUTPUT", "ERROR_NETWORK", "ERROR_NETWORK_TIMEOUT", "ERROR_INVALID_REQUEST", "ERROR_NOT_INSTALLED_YET", "QUEUE_FLUSH", "QUEUE_ADD", "QUEUE_DESTROY", "LANG_COUNTRY_VAR_AVAILABLE", "LANG_COUNTRY_AVAILABLE", "LANG_AVAILABLE", "LANG_MISSING_DATA", "LANG_NOT_SUPPORTED", "ACTION_TTS_QUEUE_PROCESSING_COMPLETED", "DEBUG", "mContext", "mConnectingServiceConnection", "mServiceConnection", "mInitListener", "mUtteranceProgressListener", "mStartLock", "mRequestedEngine", "mUseFallback", "mEarcons", "mUtterances", "mParams", "mEnginesHelper", "mIsSystem", "mInitExecutor", "mCurrentEngine" ]
}