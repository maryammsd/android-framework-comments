{
  "filePath" : "/home/maryam/clearblue/files/android-source-30/android/media/AudioTimestamp.java",
  "packageName" : "android.media",
  "className" : "AudioTimestamp",
  "comment" : "\n * Structure that groups a position in frame units relative to an assumed audio stream,\n * together with the estimated time when that frame enters or leaves the audio\n * processing pipeline on that device. This can be used to coordinate events\n * and interactions with the external environment.\n * <p>\n * The time is based on the implementation's best effort, using whatever knowledge\n * is available to the system, but cannot account for any delay unknown to the implementation.\n *\n * @see AudioTrack#getTimestamp AudioTrack.getTimestamp(AudioTimestamp)\n * @see AudioRecord#getTimestamp AudioRecord.getTimestamp(AudioTimestamp, int)\n ",
  "variables" : [ {
    "name" : "TIMEBASE_MONOTONIC",
    "type" : "int",
    "comment" : "\n     * Clock monotonic or its equivalent on the system,\n     * in the same units and timebase as {@link java.lang.System#nanoTime}.\n     ",
    "links" : [ "java.lang.System#nanoTime" ]
  }, {
    "name" : "TIMEBASE_BOOTTIME",
    "type" : "int",
    "comment" : "\n     * Clock monotonic including suspend time or its equivalent on the system,\n     * in the same units and timebase as {@link android.os.SystemClock#elapsedRealtimeNanos}.\n     ",
    "links" : [ "android.os.SystemClock#elapsedRealtimeNanos" ]
  }, {
    "name" : "framePosition",
    "type" : "long",
    "comment" : "\n     * Position in frames relative to start of an assumed audio stream.\n     * <p>\n     * When obtained through\n     * {@link AudioRecord#getTimestamp AudioRecord.getTimestamp(AudioTimestamp, int)},\n     * all 64 bits of position are valid.\n     * <p>\n     * When obtained through\n     * {@link AudioTrack#getTimestamp AudioTrack.getTimestamp(AudioTimestamp)},\n     * the low-order 32 bits of position is in wrapping frame units similar to\n     * {@link AudioTrack#getPlaybackHeadPosition AudioTrack.getPlaybackHeadPosition()}.\n     ",
    "links" : [ "android.media.AudioTrack#getPlaybackHeadPosition", "android.media.AudioTrack#getTimestamp", "android.media.AudioRecord#getTimestamp" ]
  }, {
    "name" : "nanoTime",
    "type" : "long",
    "comment" : "\n     * Time associated with the frame in the audio pipeline.\n     * <p>\n     * When obtained through\n     * {@link AudioRecord#getTimestamp AudioRecord.getTimestamp(AudioTimestamp, int)},\n     * this is the estimated time in nanoseconds when the frame referred to by\n     * {@link #framePosition} was captured. The timebase is either\n     * {@link #TIMEBASE_MONOTONIC} or {@link #TIMEBASE_BOOTTIME}, depending\n     * on the timebase parameter used in\n     * {@link AudioRecord#getTimestamp AudioRecord.getTimestamp(AudioTimestamp, int)}.\n     * <p>\n     * When obtained through\n     * {@link AudioTrack#getTimestamp AudioTrack.getTimestamp(AudioTimestamp)},\n     * this is the estimated time when the frame was presented or is committed to be presented,\n     * with a timebase of {@link #TIMEBASE_MONOTONIC}.\n     ",
    "links" : [ "android.media.AudioTrack#getTimestamp", "#TIMEBASE_MONOTONIC", "#TIMEBASE_BOOTTIME", "android.media.AudioRecord#getTimestamp", "#framePosition" ]
  } ],
  "methods" : [ ],
  "variableNames" : [ "TIMEBASE_MONOTONIC", "TIMEBASE_BOOTTIME", "framePosition", "nanoTime" ],
  "methodNames" : [ ]
}