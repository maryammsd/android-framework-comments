{
  "filePath" : "/home/maryam/clearblue/files/android-source-35/android/adservices/ondevicepersonalization/InferenceInput.java",
  "packageName" : "android.adservices.ondevicepersonalization",
  "className" : "Builder",
  "comment" : " A builder for {@link InferenceInput} ",
  "links" : [ "android.adservices.ondevicepersonalization.InferenceInput" ],
  "variables" : [ {
    "name" : "mParams",
    "type" : "Params",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mInputData",
    "type" : "Object[]",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mBatchSize",
    "type" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mExpectedOutputStructure",
    "type" : "InferenceOutput",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mBuilderFieldsSet",
    "type" : "long",
    "comment" : "",
    "links" : [ ]
  } ],
  "methods" : [ {
    "name" : "public Builder setParams(@NonNull Params value)",
    "returnType" : "Builder",
    "comment" : " The configuration that controls runtime interpreter behavior. ",
    "links" : [ ]
  }, {
    "name" : "public Builder setInputData(@NonNull Object... value)",
    "returnType" : "Builder",
    "comment" : "\n         * An array of input data. The inputs should be in the same order as inputs of the model.\n         *\n         * <p>For example, if a model takes multiple inputs:\n         *\n         * <pre>{@code\n         * String[] input0 = {\"foo\", \"bar\"}; // string tensor shape is [2].\n         * int[] input1 = new int[]{3, 2, 1}; // int tensor shape is [3].\n         * Object[] inputData = {input0, input1, ...};\n         * }</pre>\n         *\n         * For TFLite, this field is mapped to inputs of runForMultipleInputsOutputs:\n         * https://www.tensorflow.org/lite/api_docs/java/org/tensorflow/lite/InterpreterApi#parameters_9\n         ",
    "links" : [ ]
  }, {
    "name" : "public Builder setBatchSize(int value)",
    "returnType" : "Builder",
    "comment" : "\n         * The number of input examples. Adopter can set this field to run batching inference. The\n         * batch size is 1 by default. The batch size should match the input data size.\n         ",
    "links" : [ ]
  }, {
    "name" : "public Builder setExpectedOutputStructure(@NonNull InferenceOutput value)",
    "returnType" : "Builder",
    "comment" : "\n         * The empty InferenceOutput representing the expected output structure. For TFLite, the\n         * inference code will verify whether this expected output structure matches model output\n         * signature.\n         *\n         * <p>If a model produce string tensors:\n         *\n         * <pre>{@code\n         * String[] output = new String[3][2];  // Output tensor shape is [3, 2].\n         * HashMap<Integer, Object> outputs = new HashMap<>();\n         * outputs.put(0, output);\n         * expectedOutputStructure = new InferenceOutput.Builder().setDataOutputs(outputs).build();\n         * }</pre>\n         ",
    "links" : [ ]
  }, {
    "name" : "public InferenceInput build()",
    "returnType" : "InferenceInput",
    "comment" : " Builds the instance. ",
    "links" : [ ]
  } ],
  "methodNames" : [ "public Builder setParams(@NonNull Params value)", "public Builder setInputData(@NonNull Object... value)", "public Builder setBatchSize(int value)", "public Builder setExpectedOutputStructure(@NonNull InferenceOutput value)", "public InferenceInput build()" ],
  "variableNames" : [ "mParams", "mInputData", "mBatchSize", "mExpectedOutputStructure", "mBuilderFieldsSet" ]
}