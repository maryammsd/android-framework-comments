{
  "filePath" : "/home/maryam/clearblue/files/android-source-35/android/hardware/camera2/params/OutputConfiguration.java",
  "packageName" : "android.hardware.camera2.params",
  "className" : "OutputConfiguration",
  "comment" : "\n * A class for describing camera output, which contains a {@link Surface} and its specific\n * configuration for creating capture session.\n *\n * <p>There are several ways to instantiate, modify and use OutputConfigurations. The most common\n * and recommended usage patterns are summarized in the following list:</p>\n *<ul>\n * <li>Passing a {@link Surface} to the constructor and using the OutputConfiguration instance as\n * argument to {@link CameraDevice#createCaptureSessionByOutputConfigurations}. This is the most\n * frequent usage and clients should consider it first before other more complicated alternatives.\n * </li>\n *\n * <li>Passing only a surface source class as an argument to the constructor. This is usually\n * followed by a call to create a capture session\n * (see {@link CameraDevice#createCaptureSessionByOutputConfigurations} and a {@link Surface} add\n * call {@link #addSurface} with a valid {@link Surface}. The sequence completes with\n * {@link CameraCaptureSession#finalizeOutputConfigurations}. This is the deferred usage case which\n * aims to enhance performance by allowing the resource-intensive capture session create call to\n * execute in parallel with any {@link Surface} initialization, such as waiting for a\n * {@link android.view.SurfaceView} to be ready as part of the UI initialization.</li>\n *\n * <li>The third and most complex usage pattern involves surface sharing. Once instantiated an\n * OutputConfiguration can be enabled for surface sharing via {@link #enableSurfaceSharing}. This\n * must be done before creating a new capture session and enables calls to\n * {@link CameraCaptureSession#updateOutputConfiguration}. An OutputConfiguration with enabled\n * surface sharing can be modified via {@link #addSurface} or {@link #removeSurface}. The updates\n * to this OutputConfiguration will only come into effect after\n * {@link CameraCaptureSession#updateOutputConfiguration} returns without throwing exceptions.\n * Such updates can be done as long as the session is active. Clients should always consider the\n * additional requirements and limitations placed on the output surfaces (for more details see\n * {@link #enableSurfaceSharing}, {@link #addSurface}, {@link #removeSurface},\n * {@link CameraCaptureSession#updateOutputConfiguration}). A trade-off exists between additional\n * complexity and flexibility. If exercised correctly surface sharing can switch between different\n * output surfaces without interrupting any ongoing repeating capture requests. This saves time and\n * can significantly improve the user experience.</li>\n *\n * <li>Surface sharing can be used in combination with deferred surfaces. The rules from both cases\n * are combined and clients must call {@link #enableSurfaceSharing} before creating a capture\n * session. Attach and/or remove output surfaces via  {@link #addSurface}/{@link #removeSurface} and\n * finalize the configuration using {@link CameraCaptureSession#finalizeOutputConfigurations}.\n * {@link CameraCaptureSession#updateOutputConfiguration} can be called after the configuration\n * finalize method returns without exceptions.</li>\n *\n * <li>If the camera device supports multi-resolution output streams, {@link\n * CameraCharacteristics#SCALER_MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP} will contain the\n * formats and their corresponding stream info. The application can use an OutputConfiguration\n * created with the multi-resolution stream info queried from {@link\n * MultiResolutionStreamConfigurationMap#getOutputInfo} and\n * {@link android.hardware.camera2.MultiResolutionImageReader} to capture variable size images.\n *\n * </ul>\n *\n * <p> As of {@link android.os.Build.VERSION_CODES#P Android P}, all formats except\n * {@link ImageFormat#JPEG} and {@link ImageFormat#RAW_PRIVATE} can be used for sharing, subject to\n * device support. On prior API levels, only {@link ImageFormat#PRIVATE} format may be used.</p>\n *\n * @see CameraDevice#createCaptureSessionByOutputConfigurations\n * @see CameraCharacteristics#SCALER_MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP\n *\n ",
  "links" : [ "android.graphics.ImageFormat#JPEG", "android.hardware.camera2.CameraDevice#createCaptureSessionByOutputConfigurations", "#addSurface", "android.view.SurfaceView", "#enableSurfaceSharing", "android.view.Surface", "android.hardware.camera2.params.MultiResolutionStreamConfigurationMap#getOutputInfo", "android.os.Build.VERSION_CODES#P", "android.graphics.ImageFormat#RAW_PRIVATE", "android.hardware.camera2.CameraCaptureSession#finalizeOutputConfigurations", "android.graphics.ImageFormat#PRIVATE", "android.hardware.camera2.CameraCharacteristics#SCALER_MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP", "#removeSurface", "android.hardware.camera2.MultiResolutionImageReader", "android.hardware.camera2.CameraCaptureSession#updateOutputConfiguration" ],
  "variables" : [ {
    "name" : "ROTATION_0",
    "type" : "int",
    "comment" : "\n     * Rotation constant: 0 degree rotation (no rotation)\n     *\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "ROTATION_90",
    "type" : "int",
    "comment" : "\n     * Rotation constant: 90 degree counterclockwise rotation.\n     *\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "ROTATION_180",
    "type" : "int",
    "comment" : "\n     * Rotation constant: 180 degree counterclockwise rotation.\n     *\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "ROTATION_270",
    "type" : "int",
    "comment" : "\n     * Rotation constant: 270 degree counterclockwise rotation.\n     *\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "SURFACE_GROUP_ID_NONE",
    "type" : "int",
    "comment" : "\n     * Invalid surface group ID.\n     *\n     *<p>An {@link OutputConfiguration} with this value indicates that the included surface\n     *doesn't belong to any surface group.</p>\n     ",
    "links" : [ "android.hardware.camera2.params.OutputConfiguration" ]
  }, {
    "name" : "TIMESTAMP_BASE_DEFAULT",
    "type" : "int",
    "comment" : "\n     * Default timestamp base.\n     *\n     * <p>The camera device decides the timestamp based on the properties of the\n     * output surface.</p>\n     *\n     * <li> For a SurfaceView output surface, the timestamp base is {@link\n     * #TIMESTAMP_BASE_CHOREOGRAPHER_SYNCED}. The timestamp is overridden with choreographer\n     * pulses from the display subsystem for smoother display of camera frames when the camera\n     * device runs in fixed frame rate. The timestamp is roughly in the same time base as\n     * {@link android.os.SystemClock#uptimeMillis}.</li>\n     * <li> For an output surface of MediaRecorder, MediaCodec, or ImageReader with {@link\n     * android.hardware.HardwareBuffer#USAGE_VIDEO_ENCODE} usage flag, the timestamp base is\n     * {@link #TIMESTAMP_BASE_MONOTONIC}, which is roughly the same time base as\n     * {@link android.os.SystemClock#uptimeMillis}.</li>\n     * <li> For all other cases, the timestamp base is {@link #TIMESTAMP_BASE_SENSOR}, the same\n     * as what's specified by {@link CameraCharacteristics#SENSOR_INFO_TIMESTAMP_SOURCE}.\n     * <ul><li> For a SurfaceTexture output surface, the camera system re-spaces the delivery\n     * of output frames based on image readout intervals, reducing viewfinder jitter. The timestamps\n     * of images remain to be {@link #TIMESTAMP_BASE_SENSOR}.</li></ul></li>\n     *\n     * <p>Note that the reduction of frame jitter for SurfaceView and SurfaceTexture comes with\n     * slight increase in photon-to-photon latency, which is the time from when photons hit the\n     * scene to when the corresponding pixels show up on the screen. If the photon-to-photon latency\n     * is more important than the smoothness of viewfinder, {@link #TIMESTAMP_BASE_SENSOR} should be\n     * used instead.</p>\n     *\n     * @see #TIMESTAMP_BASE_CHOREOGRAPHER_SYNCED\n     * @see #TIMESTAMP_BASE_MONOTONIC\n     * @see #TIMESTAMP_BASE_SENSOR\n     ",
    "links" : [ "android.hardware.HardwareBuffer#USAGE_VIDEO_ENCODE", "#TIMESTAMP_BASE_CHOREOGRAPHER_SYNCED", "#TIMESTAMP_BASE_SENSOR", "android.hardware.camera2.CameraCharacteristics#SENSOR_INFO_TIMESTAMP_SOURCE", "android.os.SystemClock#uptimeMillis", "#TIMESTAMP_BASE_MONOTONIC" ]
  }, {
    "name" : "TIMESTAMP_BASE_SENSOR",
    "type" : "int",
    "comment" : "\n     * Timestamp base of {@link CameraCharacteristics#SENSOR_INFO_TIMESTAMP_SOURCE}.\n     *\n     * <p>The timestamps of the output images are in the time base as specified by {@link\n     * CameraCharacteristics#SENSOR_INFO_TIMESTAMP_SOURCE}. The application can look up the\n     * corresponding result metadata by matching the timestamp with a {@link\n     * CameraCaptureSession.CaptureCallback#onCaptureStarted}, or with a {@link\n     * CameraCaptureSession.CaptureCallback#onReadoutStarted} if readout timestamp is used.</p>\n     ",
    "links" : [ "android.hardware.camera2.CameraCharacteristics#SENSOR_INFO_TIMESTAMP_SOURCE", "CameraCaptureSession.CaptureCallback#onCaptureStarted", "CameraCaptureSession.CaptureCallback#onReadoutStarted" ]
  }, {
    "name" : "TIMESTAMP_BASE_MONOTONIC",
    "type" : "int",
    "comment" : "\n     * Timestamp base roughly the same as {@link android.os.SystemClock#uptimeMillis}.\n     *\n     * <p>The timestamps of the output images are monotonically increasing, and are roughly in the\n     * same time base as {@link android.os.SystemClock#uptimeMillis}. The timestamps with this\n     * time base can be directly used for audio-video sync in video recording.</p>\n     *\n     * <p>If the camera device's {@link CameraCharacteristics#SENSOR_INFO_TIMESTAMP_SOURCE} is\n     * REALTIME, timestamps with this time base cannot directly match the timestamps in\n     * {@link CameraCaptureSession.CaptureCallback#onCaptureStarted}, {@link\n     * CameraCaptureSession.CaptureCallback#onReadoutStarted}, or the sensor timestamps in\n     * {@link android.hardware.camera2.CaptureResult}.</p>\n     ",
    "links" : [ "android.hardware.camera2.CaptureResult", "android.hardware.camera2.CameraCharacteristics#SENSOR_INFO_TIMESTAMP_SOURCE", "android.os.SystemClock#uptimeMillis", "CameraCaptureSession.CaptureCallback#onCaptureStarted", "CameraCaptureSession.CaptureCallback#onReadoutStarted" ]
  }, {
    "name" : "TIMESTAMP_BASE_REALTIME",
    "type" : "int",
    "comment" : "\n     * Timestamp base roughly the same as {@link android.os.SystemClock#elapsedRealtime}.\n     *\n     * <p>The timestamps of the output images are roughly in the\n     * same time base as {@link android.os.SystemClock#elapsedRealtime}. The timestamps with this\n     * time base cannot be directly used for audio-video sync in video recording.</p>\n     *\n     * <p>If the camera device's {@link CameraCharacteristics#SENSOR_INFO_TIMESTAMP_SOURCE} is\n     * UNKNOWN, timestamps with this time base cannot directly match the timestamps in\n     * {@link CameraCaptureSession.CaptureCallback#onCaptureStarted}, {@link\n     * CameraCaptureSession.CaptureCallback#onReadoutStarted}, or the sensor timestamps in\n     * {@link android.hardware.camera2.CaptureResult}.</p>\n     *\n     * <p>If using a REALTIME timestamp base on a device that supports only\n     * TIMESTAMP_SOURCE_UNKNOWN, the accuracy of timestamps is only what is guaranteed in the\n     * documentation for UNKNOWN. In particular, they have no guarantees about being accurate\n     * enough to use in fusing image data with the output of inertial sensors, for features such as\n     * image stabilization or augmented reality.</p>\n     ",
    "links" : [ "android.os.SystemClock#elapsedRealtime", "android.hardware.camera2.CaptureResult", "android.hardware.camera2.CameraCharacteristics#SENSOR_INFO_TIMESTAMP_SOURCE", "CameraCaptureSession.CaptureCallback#onCaptureStarted", "CameraCaptureSession.CaptureCallback#onReadoutStarted" ]
  }, {
    "name" : "TIMESTAMP_BASE_CHOREOGRAPHER_SYNCED",
    "type" : "int",
    "comment" : "\n     * Timestamp is synchronized to choreographer.\n     *\n     * <p>The timestamp of the output images are overridden with choreographer pulses from the\n     * display subsystem for smoother display of camera frames. An output target of SurfaceView\n     * uses this time base by default. Note that the timestamp override is done for fixed camera\n     * frame rate only.</p>\n     *\n     * <p>This timestamp base isn't applicable to SurfaceTexture targets. SurfaceTexture's\n     * {@link android.graphics.SurfaceTexture#updateTexImage updateTexImage} function always\n     * uses the latest image from the camera stream. In the case of a TextureView, the image is\n     * displayed right away.</p>\n     *\n     * <p>Timestamps with this time base cannot directly match the timestamps in\n     * {@link CameraCaptureSession.CaptureCallback#onCaptureStarted}, {@link\n     * CameraCaptureSession.CaptureCallback#onReadoutStarted}, or the sensor timestamps in\n     * {@link android.hardware.camera2.CaptureResult}. This timestamp base shouldn't be used if the\n     * timestamp needs to be used for audio-video synchronization.</p>\n     ",
    "links" : [ "android.graphics.SurfaceTexture#updateTexImage", "android.hardware.camera2.CaptureResult", "CameraCaptureSession.CaptureCallback#onCaptureStarted", "CameraCaptureSession.CaptureCallback#onReadoutStarted" ]
  }, {
    "name" : "TIMESTAMP_BASE_READOUT_SENSOR",
    "type" : "int",
    "comment" : "\n     * Timestamp is the start of readout in the same time domain as TIMESTAMP_BASE_SENSOR.\n     *\n     * <p>NOTE: do not use! Use setReadoutTimestampEnabled instead.</p>\n     *\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "MIRROR_MODE_AUTO",
    "type" : "int",
    "comment" : "\n     * Automatic mirroring based on camera facing\n     *\n     * <p>This is the default mirroring mode for the camera device. With this mode,\n     * the camera output is mirrored horizontally for front-facing cameras. There is\n     * no mirroring for rear-facing and external cameras.</p>\n     ",
    "links" : [ ]
  }, {
    "name" : "MIRROR_MODE_NONE",
    "type" : "int",
    "comment" : "\n     * No mirror transform is applied\n     *\n     * <p>No mirroring is applied to the camera output regardless of the camera facing.</p>\n     ",
    "links" : [ ]
  }, {
    "name" : "MIRROR_MODE_H",
    "type" : "int",
    "comment" : "\n     * Camera output is mirrored horizontally\n     *\n     * <p>The camera output is mirrored horizontally, the same behavior as in AUTO mode for\n     * front facing camera.</p>\n     ",
    "links" : [ ]
  }, {
    "name" : "MIRROR_MODE_V",
    "type" : "int",
    "comment" : "\n     * Camera output is mirrored vertically\n     ",
    "links" : [ ]
  }, {
    "name" : "SURFACE_TYPE_UNKNOWN",
    "type" : "int",
    "comment" : "\n     * Unknown surface source type.\n     ",
    "links" : [ ]
  }, {
    "name" : "SURFACE_TYPE_SURFACE_VIEW",
    "type" : "int",
    "comment" : "\n     * The surface is obtained from {@link android.view.SurfaceView}.\n     ",
    "links" : [ "android.view.SurfaceView" ]
  }, {
    "name" : "SURFACE_TYPE_SURFACE_TEXTURE",
    "type" : "int",
    "comment" : "\n     * The surface is obtained from {@link android.graphics.SurfaceTexture}.\n     ",
    "links" : [ "android.graphics.SurfaceTexture" ]
  }, {
    "name" : "SURFACE_TYPE_MEDIA_RECORDER",
    "type" : "int",
    "comment" : "\n     * The surface is obtained from {@link android.media.MediaRecorder}.\n     ",
    "links" : [ "android.media.MediaRecorder" ]
  }, {
    "name" : "SURFACE_TYPE_MEDIA_CODEC",
    "type" : "int",
    "comment" : "\n     * The surface is obtained from {@link android.media.MediaCodec}.\n     ",
    "links" : [ "android.media.MediaCodec" ]
  }, {
    "name" : "SURFACE_TYPE_IMAGE_READER",
    "type" : "int",
    "comment" : "\n     * The surface is obtained from {@link android.media.ImageReader}.\n     ",
    "links" : [ "android.media.ImageReader" ]
  }, {
    "name" : "MAX_SURFACES_COUNT",
    "type" : "int",
    "comment" : "\n     * Maximum number of surfaces supported by one {@link OutputConfiguration}.\n     *\n     * <p>The combined number of surfaces added by the constructor and\n     * {@link OutputConfiguration#addSurface} should not exceed this value.</p>\n     *\n     ",
    "links" : [ "android.hardware.camera2.params.OutputConfiguration", "android.hardware.camera2.params.OutputConfiguration#addSurface" ]
  }, {
    "name" : "CREATOR",
    "type" : "Parcelable.Creator<OutputConfiguration>",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "TAG",
    "type" : "String",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "sNextMultiResolutionGroupId",
    "type" : "AtomicInteger",
    "comment" : " incremented every time {@link createInstancesForMultiResolutionOutput} is called.",
    "links" : [ "createInstancesForMultiResolutionOutput" ]
  }, {
    "name" : "mSurfaces",
    "type" : "ArrayList<Surface>",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mRotation",
    "type" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mSurfaceGroupId",
    "type" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mSurfaceType",
    "type" : "int",
    "comment" : " Surface source type, this is only used by the deferred surface configuration objects.",
    "links" : [ ]
  }, {
    "name" : "mConfiguredSize",
    "type" : "Size",
    "comment" : " The size, format, and dataspace of the surface when OutputConfiguration is created.",
    "links" : [ ]
  }, {
    "name" : "mConfiguredFormat",
    "type" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mConfiguredDataspace",
    "type" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "mConfiguredGenerationId",
    "type" : "int",
    "comment" : " Surface generation ID to distinguish changes to Surface native internals",
    "links" : [ ]
  }, {
    "name" : "mIsDeferredConfig",
    "type" : "boolean",
    "comment" : " Flag indicating if this config has deferred surface.",
    "links" : [ ]
  }, {
    "name" : "mIsShared",
    "type" : "boolean",
    "comment" : " Flag indicating if this config has shared surfaces",
    "links" : [ ]
  }, {
    "name" : "mPhysicalCameraId",
    "type" : "String",
    "comment" : " The physical camera id that this output configuration is for.",
    "links" : [ ]
  }, {
    "name" : "mIsMultiResolution",
    "type" : "boolean",
    "comment" : " MultiResolutionImageReader",
    "links" : [ ]
  }, {
    "name" : "mSensorPixelModesUsed",
    "type" : "ArrayList<Integer>",
    "comment" : " The sensor pixel modes that this OutputConfiguration will use",
    "links" : [ ]
  }, {
    "name" : "mDynamicRangeProfile",
    "type" : "long",
    "comment" : " Dynamic range profile",
    "links" : [ ]
  }, {
    "name" : "mColorSpace",
    "type" : "int",
    "comment" : " Color space",
    "links" : [ ]
  }, {
    "name" : "mStreamUseCase",
    "type" : "long",
    "comment" : " Stream use case",
    "links" : [ ]
  }, {
    "name" : "mTimestampBase",
    "type" : "int",
    "comment" : " Timestamp base",
    "links" : [ ]
  }, {
    "name" : "mMirrorMode",
    "type" : "int",
    "comment" : " Mirroring mode",
    "links" : [ ]
  }, {
    "name" : "mReadoutTimestampEnabled",
    "type" : "boolean",
    "comment" : " readout timestamp",
    "links" : [ ]
  }, {
    "name" : "mIsReadoutSensorTimestampBase",
    "type" : "boolean",
    "comment" : " Whether the timestamp base is set to READOUT_SENSOR",
    "links" : [ ]
  }, {
    "name" : "mUsage",
    "type" : "long",
    "comment" : " The usage flags. Only set for instances created for ImageReader without specifying surface.",
    "links" : [ ]
  } ],
  "methods" : [ {
    "name" : "public void setMultiResolutionOutput()",
    "returnType" : "void",
    "comment" : "\n     * Set the multi-resolution output flag.\n     *\n     * <p>Specify that this OutputConfiguration is part of a multi-resolution output stream group\n     * used by {@link android.hardware.camera2.MultiResolutionImageReader}.</p>\n     *\n     * <p>This function must only be called for an OutputConfiguration with a non-negative\n     * group ID. And all OutputConfigurations of a MultiResolutionImageReader will have the same\n     * group ID and have this flag set.</p>\n     *\n     * @throws IllegalStateException If surface sharing is enabled via {@link #enableSurfaceSharing}\n     *         call, or no non-negative group ID has been set.\n     * @hide\n     ",
    "links" : [ "#enableSurfaceSharing", "android.hardware.camera2.MultiResolutionImageReader" ]
  }, {
    "name" : "public void setDynamicRangeProfile(@DynamicRangeProfiles.Profile long profile)",
    "returnType" : "void",
    "comment" : "\n     * Set a specific device supported dynamic range profile.\n     *\n     * <p>Clients can choose from any profile advertised as supported in\n     * CameraCharacteristics.REQUEST_AVAILABLE_DYNAMIC_RANGE_PROFILES\n     * queried using {@link DynamicRangeProfiles#getSupportedProfiles()}.\n     * If this is not explicitly set, then the default profile will be\n     * {@link DynamicRangeProfiles#STANDARD}.</p>\n     *\n     * <p>Do note that invalid combinations between the registered output\n     * surface pixel format and the configured dynamic range profile will\n     * cause capture session initialization failure. Invalid combinations\n     * include any 10-bit dynamic range profile advertised in\n     * {@link DynamicRangeProfiles#getSupportedProfiles()} combined with\n     * an output Surface pixel format different from {@link ImageFormat#PRIVATE}\n     * (the default for Surfaces initialized by {@link android.view.SurfaceView},\n     * {@link android.view.TextureView}, {@link android.media.MediaRecorder},\n     * {@link android.media.MediaCodec} etc.)\n     * or {@link ImageFormat#YCBCR_P010}.</p>\n     ",
    "links" : [ "android.media.MediaCodec", "android.hardware.camera2.params.DynamicRangeProfiles#getSupportedProfiles()", "android.graphics.ImageFormat#PRIVATE", "android.view.SurfaceView", "android.hardware.camera2.params.DynamicRangeProfiles#STANDARD", "android.graphics.ImageFormat#YCBCR_P010", "android.view.TextureView", "android.media.MediaRecorder" ]
  }, {
    "name" : "public long getDynamicRangeProfile()",
    "returnType" : "long",
    "comment" : "\n     * Return current dynamic range profile.\n     *\n     * @return the currently set dynamic range profile\n     ",
    "links" : [ ]
  }, {
    "name" : "public void setColorSpace(@NonNull ColorSpace.Named colorSpace)",
    "returnType" : "void",
    "comment" : "\n     * Set a specific device-supported color space.\n     *\n     * <p>Clients can choose from any profile advertised as supported in\n     * {@link CameraCharacteristics#REQUEST_AVAILABLE_COLOR_SPACE_PROFILES}\n     * queried using {@link ColorSpaceProfiles#getSupportedColorSpaces}.\n     * When set, the colorSpace will override the default color spaces of the output targets,\n     * or the color space implied by the dataSpace passed into an {@link ImageReader}'s\n     * constructor.</p>\n     *\n     * @hide\n     ",
    "links" : [ "android.hardware.camera2.params.ColorSpaceProfiles#getSupportedColorSpaces", "android.hardware.camera2.CameraCharacteristics#REQUEST_AVAILABLE_COLOR_SPACE_PROFILES", "android.hardware.camera2.MultiResolutionImageReader" ]
  }, {
    "name" : "public void clearColorSpace()",
    "returnType" : "void",
    "comment" : "\n     * Clear the color space, such that the default color space will be used.\n     *\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "public ColorSpace getColorSpace()",
    "returnType" : "ColorSpace",
    "comment" : "\n     * Return the current color space.\n     *\n     * @return the currently set color space\n     * @hide\n     ",
    "links" : [ ]
  }, {
    "name" : "public static Collection<OutputConfiguration> createInstancesForMultiResolutionOutput(@NonNull MultiResolutionImageReader multiResolutionImageReader)",
    "returnType" : "Collection<OutputConfiguration>",
    "comment" : "\n     * Create a list of {@link OutputConfiguration} instances for the outputs used by a\n     * {@link android.hardware.camera2.MultiResolutionImageReader}.\n     *\n     * <p>This constructor takes an argument for a\n     * {@link android.hardware.camera2.MultiResolutionImageReader}.</p>\n     *\n     * @param multiResolutionImageReader\n     *          The multi-resolution image reader object.\n     ",
    "links" : [ "android.hardware.camera2.params.OutputConfiguration", "android.hardware.camera2.MultiResolutionImageReader" ]
  }, {
    "name" : "public static List<OutputConfiguration> createInstancesForMultiResolutionOutput(@NonNull Collection<MultiResolutionStreamInfo> streams, @Format int format)",
    "returnType" : "List<OutputConfiguration>",
    "comment" : "\n     * Create a list of {@link OutputConfiguration} instances for a\n     * {@link android.hardware.camera2.params.MultiResolutionImageReader}.\n     *\n     * <p>This method can be used to create query OutputConfigurations for a\n     * MultiResolutionImageReader that can be included in a SessionConfiguration passed into\n     * {@link CameraDeviceSetup#isSessionConfigurationSupported} before opening and setting up\n     * a camera device in full, at which point {@link #setSurfacesForMultiResolutionOutput}\n     * can be used to link to the actual MultiResolutionImageReader.</p>\n     *\n     * <p>This constructor takes same arguments used to create a {@link\n     * MultiResolutionImageReader}: a collection of {@link MultiResolutionStreamInfo}\n     * objects and the format.</p>\n     *\n     * @param streams The group of multi-resolution stream info objects, which are used to create a\n     *                multi-resolution image reader containing a number of ImageReaders.\n     * @param format The format of the MultiResolutionImageReader. This must be one of the {@link\n     *               android.graphics.ImageFormat} or {@link android.graphics.PixelFormat} constants\n     *               supported by the camera device. Note that not all formats are supported, like\n     *               {@link ImageFormat.NV21}. The supported multi-resolution reader format can be\n     *               queried by {@link MultiResolutionStreamConfigurationMap#getOutputFormats}.\n     *\n     * @return The list of {@link OutputConfiguration} objects for a MultiResolutionImageReader.\n     *\n     * @throws IllegaArgumentException If the {@code streams} is null or doesn't contain\n     *                                 at least 2 items, or if {@code format} isn't a valid camera\n     *                                 format.\n     *\n     * @see MultiResolutionImageReader\n     * @see MultiResolutionStreamInfo\n     ",
    "links" : [ "android.hardware.camera2.params.MultiResolutionImageReader", "ImageFormat.NV21", "android.hardware.camera2.params.MultiResolutionStreamConfigurationMap#getOutputFormats", "android.hardware.camera2.params.OutputConfiguration", "android.graphics.ImageFormat", "android.hardware.camera2.MultiResolutionImageReader", "#isSessionConfigurationSupported", "#setSurfacesForMultiResolutionOutput", "android.hardware.camera2.params.MultiResolutionStreamInfo", "android.graphics.PixelFormat" ]
  }, {
    "name" : "public static void setSurfacesForMultiResolutionOutput(@NonNull Collection<OutputConfiguration> outputConfigurations, @NonNull MultiResolutionImageReader multiResolutionImageReader)",
    "returnType" : "void",
    "comment" : "\n     * Set the OutputConfiguration surfaces corresponding to the {@link MultiResolutionImageReader}.\n     *\n     * <p>This function should be used together with {@link\n     * #createInstancesForMultiResolutionOutput}. The application calls {@link\n     * #createInstancesForMultiResolutionOutput} first to create a list of\n     * OutputConfiguration objects without the actual MultiResolutionImageReader.\n     * Once the MultiResolutionImageReader is created later during full camera setup, the\n     * application then calls this function to assign the surfaces to the OutputConfiguration\n     * instances.</p>\n     *\n     * @param outputConfigurations The OutputConfiguration objects created by {@link\n     *                             #createInstancesFromMultiResolutionOutput}\n     * @param multiResolutionImageReader The MultiResolutionImageReader object created from the same\n     *                                   MultiResolutionStreamInfo parameters as\n     *                                   {@code outputConfigurations}.\n     * @throws IllegalArgumentException If {@code outputConfigurations} or {@code\n     *                                  multiResolutionImageReader} is {@code null}, the {@code\n     *                                  outputConfigurations} and {@code multiResolutionImageReader}\n     *                                  sizes don't match, or if the\n     *                                  {@code multiResolutionImageReader}'s surfaces don't match\n     *                                  with the {@code outputConfigurations}.\n     * @throws IllegalStateException If {@code outputConfigurations} already contains valid output\n     *                               surfaces.\n     ",
    "links" : [ "#createInstancesForMultiResolutionOutput", "android.hardware.camera2.MultiResolutionImageReader", "#createInstancesFromMultiResolutionOutput" ]
  }, {
    "name" : "public void enableSurfaceSharing()",
    "returnType" : "void",
    "comment" : "\n     * Enable multiple surfaces sharing the same OutputConfiguration\n     *\n     * <p>For advanced use cases, a camera application may require more streams than the combination\n     * guaranteed by {@link CameraDevice#createCaptureSession}. In this case, more than one\n     * compatible surface can be attached to an OutputConfiguration so that they map to one\n     * camera stream, and the outputs share memory buffers when possible. Due to buffer sharing\n     * clients should be careful when adding surface outputs that modify their input data. If such\n     * case exists, camera clients should have an additional mechanism to synchronize read and write\n     * access between individual consumers.</p>\n     *\n     * <p>Two surfaces are compatible in the below cases:</p>\n     *\n     * <li> Surfaces with the same size, format, dataSpace, and Surface source class. In this case,\n     * {@link CameraDevice#createCaptureSessionByOutputConfigurations} is guaranteed to succeed.\n     *\n     * <li> Surfaces with the same size, format, and dataSpace, but different Surface source classes\n     * that are generally not compatible. However, on some devices, the underlying camera device is\n     * able to use the same buffer layout for both surfaces. The only way to discover if this is the\n     * case is to create a capture session with that output configuration. For example, if the\n     * camera device uses the same private buffer format between a SurfaceView/SurfaceTexture and a\n     * MediaRecorder/MediaCodec, {@link CameraDevice#createCaptureSessionByOutputConfigurations}\n     * will succeed. Otherwise, it fails with {@link\n     * CameraCaptureSession.StateCallback#onConfigureFailed}.\n     * </ol>\n     *\n     * <p>To enable surface sharing, this function must be called before {@link\n     * CameraDevice#createCaptureSessionByOutputConfigurations} or {@link\n     * CameraDevice#createReprocessableCaptureSessionByConfigurations}. Calling this function after\n     * {@link CameraDevice#createCaptureSessionByOutputConfigurations} has no effect.</p>\n     *\n     * <p>Up to {@link #getMaxSharedSurfaceCount} surfaces can be shared for an OutputConfiguration.\n     * The supported surfaces for sharing must be of type SurfaceTexture, SurfaceView,\n     * MediaRecorder, MediaCodec, or implementation defined ImageReader.</p>\n     *\n     * <p>This function must not be called from OutputConfigurations created by {@link\n     * #createInstancesForMultiResolutionOutput}.</p>\n     *\n     * @throws IllegalStateException If this OutputConfiguration is created via {@link\n     * #createInstancesForMultiResolutionOutput} to back a MultiResolutionImageReader.\n     ",
    "links" : [ "android.hardware.camera2.CameraDevice#createCaptureSessionByOutputConfigurations", "#createInstancesForMultiResolutionOutput", "android.hardware.camera2.CameraDevice#createReprocessableCaptureSessionByConfigurations", "#getMaxSharedSurfaceCount", "CameraCaptureSession.StateCallback#onConfigureFailed", "android.hardware.camera2.CameraDevice#createCaptureSession" ]
  }, {
    "name" : "public void setPhysicalCameraId(@Nullable String physicalCameraId)",
    "returnType" : "void",
    "comment" : "\n     * Set the id of the physical camera for this OutputConfiguration\n     *\n     * <p>In the case one logical camera is made up of multiple physical cameras, it could be\n     * desirable for the camera application to request streams from individual physical cameras.\n     * This call achieves it by mapping the OutputConfiguration to the physical camera id.</p>\n     *\n     * <p>The valid physical camera ids can be queried by {@link\n     * CameraCharacteristics#getPhysicalCameraIds}.</p>\n     *\n     * <p>Passing in a null physicalCameraId means that the OutputConfiguration is for a logical\n     * stream.</p>\n     *\n     * <p>This function must be called before {@link\n     * CameraDevice#createCaptureSessionByOutputConfigurations} or {@link\n     * CameraDevice#createReprocessableCaptureSessionByConfigurations}. Calling this function\n     * after {@link CameraDevice#createCaptureSessionByOutputConfigurations} or {@link\n     * CameraDevice#createReprocessableCaptureSessionByConfigurations} has no effect.</p>\n     *\n     * <p>As of {@link android.os.Build.VERSION_CODES#S Android 12}, an image buffer from a\n     * physical camera stream can be used for reprocessing to logical camera streams and streams\n     * from the same physical camera if the camera device supports multi-resolution input and output\n     * streams. See {@link CameraCharacteristics#SCALER_MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP}\n     * for details. The behaviors of reprocessing from a non-physical camera stream to a physical\n     * camera stream, and from a physical camera stream to a physical camera stream of different\n     * physical camera, are device-specific and not guaranteed to be supported.</p>\n     *\n     * <p>On prior API levels, the surface belonging to a physical camera OutputConfiguration must\n     * not be used as input or output of a reprocessing request. </p>\n     ",
    "links" : [ "android.hardware.camera2.CameraDevice#createCaptureSessionByOutputConfigurations", "android.os.Build.VERSION_CODES#S", "android.hardware.camera2.CameraDevice#createReprocessableCaptureSessionByConfigurations", "android.hardware.camera2.CameraCharacteristics#SCALER_MULTI_RESOLUTION_STREAM_CONFIGURATION_MAP", "android.hardware.camera2.CameraCharacteristics#getPhysicalCameraIds" ]
  }, {
    "name" : "public void addSensorPixelModeUsed(@SensorPixelMode int sensorPixelModeUsed)",
    "returnType" : "void",
    "comment" : "\n     * Add a sensor pixel mode that this OutputConfiguration will be used in.\n     *\n     * <p> In the case that this output stream configuration (format, width, height) is\n     * available through {@link android.hardware.camera2.CameraCharacteristics#SCALER_STREAM_CONFIGURATION_MAP}\n     * configurations and\n     * {@link android.hardware.camera2.CameraCharacteristics#SCALER_STREAM_CONFIGURATION_MAP_MAXIMUM_RESOLUTION},\n     * configurations, the camera sub-system will assume that this {@link OutputConfiguration} will\n     * be used only with {@link android.hardware.camera2.CaptureRequest}s which has\n     * {@link android.hardware.camera2.CaptureRequest#SENSOR_PIXEL_MODE} set to\n     * {@link android.hardware.camera2.CameraMetadata#SENSOR_PIXEL_MODE_DEFAULT}.\n     * In such cases, if clients intend to use the\n     * {@link OutputConfiguration}(s) in a {@link android.hardware.camera2.CaptureRequest} with\n     * other sensor pixel modes, they must specify which\n     * {@link android.hardware.camera2.CaptureRequest#SENSOR_PIXEL_MODE}(s) they will use this\n     * {@link OutputConfiguration} with, by calling this method.\n     *\n     * In case this output stream configuration (format, width, height) is only in\n     * {@link android.hardware.camera2.CameraCharacteristics#SCALER_STREAM_CONFIGURATION_MAP_MAXIMUM_RESOLUTION},\n     * configurations, this output target must only be used with\n     * {@link android.hardware.camera2.CaptureRequest}s which has\n     * {@link android.hardware.camera2.CaptureRequest#SENSOR_PIXEL_MODE} set to\n     * {@link android.hardware.camera2.CameraMetadata#SENSOR_PIXEL_MODE_MAXIMUM_RESOLUTION} and that\n     * is what the camera sub-system will assume. If clients add\n     * {@link android.hardware.camera2.CameraMetadata#SENSOR_PIXEL_MODE_DEFAULT} in this\n     * case, session configuration will fail, if this {@link OutputConfiguration} is included.\n     *\n     * In case this output stream configuration (format, width, height) is only in\n     * {@link android.hardware.camera2.CameraCharacteristics#SCALER_STREAM_CONFIGURATION_MAP},\n     * configurations, this output target must only be used with\n     * {@link android.hardware.camera2.CaptureRequest}s which has\n     * {@link android.hardware.camera2.CaptureRequest#SENSOR_PIXEL_MODE} set to\n     * {@link android.hardware.camera2.CameraMetadata#SENSOR_PIXEL_MODE_DEFAULT} and that is what\n     * the camera sub-system will assume. If clients add\n     * {@link android.hardware.camera2.CameraMetadata#SENSOR_PIXEL_MODE_MAXIMUM_RESOLUTION} in this\n     * case, session configuration will fail, if this {@link OutputConfiguration} is included.\n     *\n     * @param sensorPixelModeUsed The sensor pixel mode this OutputConfiguration will be used with\n     * </p>\n     *\n     ",
    "links" : [ "android.hardware.camera2.CameraMetadata#SENSOR_PIXEL_MODE_DEFAULT", "android.hardware.camera2.params.OutputConfiguration", "android.hardware.camera2.CameraCharacteristics#SCALER_STREAM_CONFIGURATION_MAP_MAXIMUM_RESOLUTION", "android.hardware.camera2.CameraMetadata#SENSOR_PIXEL_MODE_MAXIMUM_RESOLUTION", "android.hardware.camera2.CameraCharacteristics#SCALER_STREAM_CONFIGURATION_MAP", "android.hardware.camera2.CaptureRequest", "android.hardware.camera2.CaptureRequest#SENSOR_PIXEL_MODE" ]
  }, {
    "name" : "public void removeSensorPixelModeUsed(@SensorPixelMode int sensorPixelModeUsed)",
    "returnType" : "void",
    "comment" : "\n     * Remove a sensor pixel mode, previously added through addSensorPixelModeUsed, from this\n     * OutputConfiguration.\n     *\n     * <p> Sensor pixel modes added via calls to {@link #addSensorPixelModeUsed} can also be removed\n     * from the OutputConfiguration.</p>\n     *\n     * @param sensorPixelModeUsed The sensor pixel mode to be removed.\n     *\n     * @throws IllegalArgumentException If the sensor pixel mode wasn't previously added\n     *                                  through {@link #addSensorPixelModeUsed}.\n     ",
    "links" : [ "#addSensorPixelModeUsed" ]
  }, {
    "name" : "public boolean isForPhysicalCamera()",
    "returnType" : "boolean",
    "comment" : "\n     * Check if this configuration is for a physical camera.\n     *\n     * <p>This returns true if the output configuration was for a physical camera making up a\n     * logical multi camera via {@link OutputConfiguration#setPhysicalCameraId}.</p>\n     * @hide\n     ",
    "links" : [ "android.hardware.camera2.params.OutputConfiguration#setPhysicalCameraId" ]
  }, {
    "name" : "public boolean isDeferredConfiguration()",
    "returnType" : "boolean",
    "comment" : "\n     * Check if this configuration has deferred configuration.\n     *\n     * <p>This will return true if the output configuration was constructed with {@link\n     * android.view.SurfaceView} or {@link android.graphics.SurfaceTexture} deferred by\n     * {@link OutputConfiguration#OutputConfiguration(Size, Class)}. It will return true even after\n     * the deferred surface is added later by {@link OutputConfiguration#addSurface}.</p>\n     *\n     * @return true if this configuration has deferred surface.\n     * @hide\n     ",
    "links" : [ "android.graphics.SurfaceTexture", "android.hardware.camera2.params.OutputConfiguration#addSurface", "android.view.SurfaceView", "android.hardware.camera2.params.OutputConfiguration#OutputConfiguration(Size" ]
  }, {
    "name" : "public void addSurface(@NonNull Surface surface)",
    "returnType" : "void",
    "comment" : "\n     * Add a surface to this OutputConfiguration.\n     *\n     * <p> This function can be called before or after {@link\n     * CameraDevice#createCaptureSessionByOutputConfigurations}. If it's called after,\n     * the application must finalize the capture session with\n     * {@link CameraCaptureSession#finalizeOutputConfigurations}. It is possible to call this method\n     * after the output configurations have been finalized only in cases of enabled surface sharing\n     * see {@link #enableSurfaceSharing}. The modified output configuration must be updated with\n     * {@link CameraCaptureSession#updateOutputConfiguration}. If this function is called before\n     * session creation, {@link CameraCaptureSession#finalizeOutputConfigurations} doesn't need to\n     * be called.</p>\n     *\n     * <p> If the OutputConfiguration was constructed by {@link\n     * OutputConfiguration#OutputConfiguration(Size, Class)}, the added surface must be obtained:\n     * <ul>\n     * <li>from {@link android.view.SurfaceView} by calling\n     * {@link android.view.SurfaceHolder#getSurface}</li>\n     * <li>from {@link android.graphics.SurfaceTexture} by calling\n     * {@link android.view.Surface#Surface(android.graphics.SurfaceTexture)}</li>\n     * <li>from {@link android.media.MediaRecorder} by calling\n     * {@link android.media.MediaRecorder#getSurface} or {@link\n     * android.media.MediaCodec#createPersistentInputSurface}</li>\n     * <li>from {@link android.media.MediaCodce} by calling\n     * {@link android.media.MediaCodec#createInputSurface} or {@link\n     * android.media.MediaCodec#createPersistentInputSource}</li>\n     * </ul>\n     *\n     * <p> If the OutputConfiguration was constructed by {@link #OutputConfiguration(int, Size)}\n     * or its variants, the added surface must be obtained from {@link android.media.ImageReader}\n     * by calling {@link android.media.ImageReader#getSurface}.</p>\n     *\n     * <p> If the OutputConfiguration was constructed by other constructors, the added\n     * surface must be compatible with the existing surface. See {@link #enableSurfaceSharing} for\n     * details of compatible surfaces.</p>\n     *\n     * <p> If the OutputConfiguration already contains a Surface, {@link #enableSurfaceSharing} must\n     * be called before calling this function to add a new Surface.</p>\n     *\n     * @param surface The surface to be added.\n     * @throws IllegalArgumentException if the Surface is invalid, the Surface's\n     *         dataspace/format doesn't match, or adding the Surface would exceed number of\n     *         shared surfaces supported.\n     * @throws IllegalStateException if the Surface was already added to this OutputConfiguration,\n     *         or if the OutputConfiguration is not shared and it already has a surface associated\n     *         with it.\n     ",
    "links" : [ "android.view.SurfaceHolder#getSurface", "android.graphics.SurfaceTexture", "android.hardware.camera2.CameraDevice#createCaptureSessionByOutputConfigurations", "android.media.MediaCodec#createPersistentInputSurface", "#enableSurfaceSharing", "android.view.SurfaceView", "android.media.MediaCodec#createInputSurface", "android.media.ImageReader", "#OutputConfiguration(int", "android.hardware.camera2.params.OutputConfiguration#OutputConfiguration(Size", "android.media.MediaCodec#createPersistentInputSource", "android.media.MediaRecorder", "android.media.MediaRecorder#getSurface", "android.media.ImageReader#getSurface", "android.hardware.camera2.CameraCaptureSession#finalizeOutputConfigurations", "android.media.MediaCodce", "android.view.Surface#Surface(android.graphics.SurfaceTexture)", "android.hardware.camera2.CameraCaptureSession#updateOutputConfiguration" ]
  }, {
    "name" : "public void removeSurface(@NonNull Surface surface)",
    "returnType" : "void",
    "comment" : "\n     * Remove a surface from this OutputConfiguration.\n     *\n     * <p> Surfaces added via calls to {@link #addSurface} can also be removed from the\n     *  OutputConfiguration. The only notable exception is the surface associated with\n     *  the OutputConfiguration (see {@link #getSurface}) which was passed as part of the\n     *  constructor or was added first in the case of\n     *  {@link OutputConfiguration#OutputConfiguration(Size, Class)}, {@link\n     *  OutputConfiguration#OutputConfiguration(int, Size)}, {@link\n     *  OutputConfiguration#OutputConfiguration(int, Size, long)}, {@link\n     *  OutputConfiguration#OutputConfiguration(int, int, Size)}, {@link\n     *  OutputConfiguration#OutputConfiguration(int, int, Size, long)}.</p>\n     *\n     * @param surface The surface to be removed.\n     *\n     * @throws IllegalArgumentException If the surface is associated with this OutputConfiguration\n     *                                  (see {@link #getSurface}) or the surface didn't get added\n     *                                  with {@link #addSurface}.\n     ",
    "links" : [ "#getSurface", "#addSurface", "android.hardware.camera2.params.OutputConfiguration#OutputConfiguration(int", "android.hardware.camera2.params.OutputConfiguration#OutputConfiguration(Size" ]
  }, {
    "name" : "public void setStreamUseCase(@StreamUseCase long streamUseCase)",
    "returnType" : "void",
    "comment" : "\n     * Set stream use case for this OutputConfiguration\n     *\n     * <p>Stream use case is used to describe the purpose of the stream, whether it's for live\n     * preview, still image capture, video recording, or their combinations. This flag is useful\n     * for scenarios where the immediate consumer target isn't sufficient to indicate the stream's\n     * usage.</p>\n     *\n     * <p>The main difference between stream use case and capture intent is that the former\n     * enables the camera device to optimize camera hardware and software pipelines based on user\n     * scenarios for each stream, whereas the latter is mainly a hint to camera to decide\n     * optimal 3A strategy that's applicable to the whole session. The camera device carries out\n     * configurations such as selecting tuning parameters, choosing camera sensor mode, and\n     * constructing image processing pipeline based on the streams's use cases. Capture intents are\n     * then used to fine tune 3A behaviors such as adjusting AE/AF convergence speed, and capture\n     * intents may change during the lifetime of a session. For example, for a session with a\n     * PREVIEW_VIDEO_STILL use case stream and a STILL_CAPTURE use case stream, the capture intents\n     * may be PREVIEW with fast 3A convergence speed and flash metering with automatic control for\n     * live preview, STILL_CAPTURE with best 3A parameters for still photo capture, or VIDEO_RECORD\n     * with slower 3A convergence speed for better video playback experience.</p>\n     *\n     * <p>The supported stream use cases supported by a camera device can be queried by\n     * {@link android.hardware.camera2.CameraCharacteristics#SCALER_AVAILABLE_STREAM_USE_CASES}.</p>\n     *\n     * <p>The mandatory stream combinations involving stream use cases can be found at {@link\n     * android.hardware.camera2.CameraDevice#createCaptureSession}, as well as queried via\n     * {@link android.hardware.camera2.params.MandatoryStreamCombination}. The application is\n     * strongly recommended to select one of the guaranteed stream combinations where all streams'\n     * use cases are set to non-DEFAULT values. If the application chooses a stream combination\n     * not in the mandatory list, the camera device may ignore some use case flags due to\n     * hardware constraints or implementation details.</p>\n     *\n     * <p>This function must be called before {@link CameraDevice#createCaptureSession} or {@link\n     * CameraDevice#createCaptureSessionByOutputConfigurations}. Calling this function after\n     * {@link CameraDevice#createCaptureSession} or\n     * {@link CameraDevice#createCaptureSessionByOutputConfigurations} has no effect to the camera\n     * session.</p>\n     *\n     * @param streamUseCase The stream use case to be set.\n     *\n     * @throws IllegalArgumentException If the streamUseCase isn't within the range of valid\n     *                                  values.\n     ",
    "links" : [ "android.hardware.camera2.CameraDevice#createCaptureSessionByOutputConfigurations", "android.hardware.camera2.params.MandatoryStreamCombination", "android.hardware.camera2.CameraDevice#createCaptureSession", "android.hardware.camera2.CameraCharacteristics#SCALER_AVAILABLE_STREAM_USE_CASES" ]
  }, {
    "name" : "public long getStreamUseCase()",
    "returnType" : "long",
    "comment" : "\n     * Get the current stream use case\n     *\n     * <p>If no {@link #setStreamUseCase} is called first, this function returns\n     * {@link CameraCharacteristics#SCALER_AVAILABLE_STREAM_USE_CASES_DEFAULT DEFAULT}.</p>\n     *\n     * @return the currently set stream use case\n     ",
    "links" : [ "android.hardware.camera2.CameraCharacteristics#SCALER_AVAILABLE_STREAM_USE_CASES_DEFAULT", "#setStreamUseCase" ]
  }, {
    "name" : "public void setTimestampBase(@TimestampBase int timestampBase)",
    "returnType" : "void",
    "comment" : "\n     * Set timestamp base for this output target\n     *\n     * <p>Timestamp base describes the time domain of images from this\n     * camera output and its relationship with {@link\n     * CameraCharacteristics#SENSOR_INFO_TIMESTAMP_SOURCE}.</p>\n     *\n     * <p>If this function is not called, the timestamp base for this output\n     * is {@link #TIMESTAMP_BASE_DEFAULT}, with which the camera device adjusts\n     * timestamps based on the output target.</p>\n     *\n     * <p>See {@link #TIMESTAMP_BASE_DEFAULT}, {@link #TIMESTAMP_BASE_SENSOR},\n     * and {@link #TIMESTAMP_BASE_CHOREOGRAPHER_SYNCED} for details of each timestamp base.</p>\n     *\n     * @param timestampBase The timestamp base to be set.\n     *\n     * @throws IllegalArgumentException If the timestamp base isn't within the range of valid\n     *                                  values.\n     ",
    "links" : [ "#TIMESTAMP_BASE_DEFAULT", "#TIMESTAMP_BASE_CHOREOGRAPHER_SYNCED", "#TIMESTAMP_BASE_SENSOR", "android.hardware.camera2.CameraCharacteristics#SENSOR_INFO_TIMESTAMP_SOURCE" ]
  }, {
    "name" : "public int getTimestampBase()",
    "returnType" : "int",
    "comment" : "\n     * Get the current timestamp base\n     *\n     * <p>If no {@link #setTimestampBase} is called first, this function returns\n     * {@link #TIMESTAMP_BASE_DEFAULT}.</p>\n     *\n     * @return The currently set timestamp base\n     ",
    "links" : [ "#TIMESTAMP_BASE_DEFAULT", "#setTimestampBase" ]
  }, {
    "name" : "public void setMirrorMode(@MirrorMode int mirrorMode)",
    "returnType" : "void",
    "comment" : "\n     * Set the mirroring mode for this output target\n     *\n     * <p>If this function is not called, the mirroring mode for this output is\n     * {@link #MIRROR_MODE_AUTO}, with which the camera API will mirror the output images\n     * horizontally for front facing camera.</p>\n     *\n     * <p>For efficiency, the mirror effect is applied as a transform flag, so it is only effective\n     * in some outputs. It works automatically for SurfaceView and TextureView outputs. For manual\n     * use of SurfaceTexture, it is reflected in the value of\n     * {@link android.graphics.SurfaceTexture#getTransformMatrix}. For other end points, such as\n     * ImageReader, MediaRecorder, or MediaCodec, the mirror mode has no effect. If mirroring is\n     * needed for such outputs, the application needs to mirror the image buffers itself before\n     * passing them onward.</p>\n     ",
    "links" : [ "#MIRROR_MODE_AUTO", "android.graphics.SurfaceTexture#getTransformMatrix" ]
  }, {
    "name" : "public int getMirrorMode()",
    "returnType" : "int",
    "comment" : "\n     * Get the current mirroring mode\n     *\n     * <p>If no {@link #setMirrorMode} is called first, this function returns\n     * {@link #MIRROR_MODE_AUTO}.</p>\n     *\n     * @return The currently set mirroring mode\n     ",
    "links" : [ "#MIRROR_MODE_AUTO", "#setMirrorMode" ]
  }, {
    "name" : "public void setReadoutTimestampEnabled(boolean on)",
    "returnType" : "void",
    "comment" : "\n     * Use the camera sensor's readout time for the image timestamp.\n     *\n     * <p>The start of the camera sensor readout after exposure. For a rolling shutter camera\n     * sensor, the timestamp is typically equal to {@code (the start of exposure time) +\n     * (exposure time) + (certain fixed offset)}. The fixed offset can vary per session, depending\n     * on the underlying sensor configuration. The benefit of using readout time is that when\n     * camera runs in a fixed frame rate, the timestamp intervals between frames are constant.</p>\n     *\n     * <p>Readout timestamp is supported only if {@link\n     * CameraCharacteristics#SENSOR_READOUT_TIMESTAMP} is\n     * {@link CameraMetadata#SENSOR_READOUT_TIMESTAMP_HARDWARE}.</p>\n     *\n     * <p>As long as readout timestamp is supported, if the timestamp base is\n     * {@link #TIMESTAMP_BASE_CHOREOGRAPHER_SYNCED}, or if the timestamp base is DEFAULT for a\n     * SurfaceView output, the image timestamps for the output are always readout time regardless\n     * of whether this function is called.</p>\n     *\n     * @param on The output image timestamp is the start of exposure time if false, and\n     *           the start of readout time if true.\n     ",
    "links" : [ "android.hardware.camera2.CameraCharacteristics#SENSOR_READOUT_TIMESTAMP", "android.hardware.camera2.CameraMetadata#SENSOR_READOUT_TIMESTAMP_HARDWARE", "#TIMESTAMP_BASE_CHOREOGRAPHER_SYNCED" ]
  }, {
    "name" : "public boolean isReadoutTimestampEnabled()",
    "returnType" : "boolean",
    "comment" : " Whether readout timestamp is used for this OutputConfiguration.\n     *\n     * @see #setReadoutTimestampEnabled\n     ",
    "links" : [ ]
  }, {
    "name" : "public int getMaxSharedSurfaceCount()",
    "returnType" : "int",
    "comment" : "\n     * Get the maximum supported shared {@link Surface} count.\n     *\n     * @return the maximum number of surfaces that can be added per each OutputConfiguration.\n     *\n     * @see #enableSurfaceSharing\n     ",
    "links" : [ "android.view.Surface" ]
  }, {
    "name" : "public Surface getSurface()",
    "returnType" : "Surface",
    "comment" : "\n     * Get the {@link Surface} associated with this {@link OutputConfiguration}.\n     *\n     * If more than one surface is associated with this {@link OutputConfiguration}, return the\n     * first one as specified in the constructor or {@link OutputConfiguration#addSurface}.\n     ",
    "links" : [ "android.hardware.camera2.params.OutputConfiguration", "android.hardware.camera2.params.OutputConfiguration#addSurface", "android.view.Surface" ]
  }, {
    "name" : "public List<Surface> getSurfaces()",
    "returnType" : "List<Surface>",
    "comment" : "\n     * Get the immutable list of surfaces associated with this {@link OutputConfiguration}.\n     *\n     * @return the list of surfaces associated with this {@link OutputConfiguration} as specified in\n     * the constructor and {@link OutputConfiguration#addSurface}. The list should not be modified.\n     ",
    "links" : [ "android.hardware.camera2.params.OutputConfiguration", "android.hardware.camera2.params.OutputConfiguration#addSurface" ]
  }, {
    "name" : "public int getRotation()",
    "returnType" : "int",
    "comment" : "\n     * Get the rotation associated with this {@link OutputConfiguration}.\n     *\n     * @return the rotation associated with this {@link OutputConfiguration}.\n     *         Value will be one of ROTATION_[0, 90, 180, 270]\n     *\n     * @hide\n     ",
    "links" : [ "android.hardware.camera2.params.OutputConfiguration" ]
  }, {
    "name" : "public int getSurfaceGroupId()",
    "returnType" : "int",
    "comment" : "\n     * Get the surface group ID associated with this {@link OutputConfiguration}.\n     *\n     * @return the surface group ID associated with this {@link OutputConfiguration}.\n     *         The default value is {@value #SURFACE_GROUP_ID_NONE}.\n     ",
    "links" : [ "android.hardware.camera2.params.OutputConfiguration" ]
  }, {
    "name" : "public Size getConfiguredSize()",
    "returnType" : "Size",
    "comment" : "\n     * Get the configured size associated with this {@link OutputConfiguration}.\n     *\n     * @return The configured size associated with this {@link OutputConfiguration}.\n     *\n     * @hide\n     ",
    "links" : [ "android.hardware.camera2.params.OutputConfiguration" ]
  }, {
    "name" : "public String getPhysicalCameraId()",
    "returnType" : "String",
    "comment" : "\n     * Get the physical camera ID associated with this {@link OutputConfiguration}.\n     *\n     * <p>If this OutputConfiguration isn't targeting a physical camera of a logical\n     * multi-camera, this function returns {@code null}.</p>\n     *\n     * @return The physical camera Id associated with this {@link OutputConfiguration}.\n     *\n     * @hide\n     ",
    "links" : [ "android.hardware.camera2.params.OutputConfiguration" ]
  }, {
    "name" : "public int describeContents()",
    "returnType" : "int",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private static int[] convertIntegerToIntList(List<Integer> integerList)",
    "returnType" : "int[]",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "private static ArrayList<Integer> convertIntArrayToIntegerList(int[] intArray)",
    "returnType" : "ArrayList<Integer>",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public void writeToParcel(Parcel dest, int flags)",
    "returnType" : "void",
    "comment" : "",
    "links" : [ ]
  }, {
    "name" : "public boolean equals(@Nullable Object obj)",
    "returnType" : "boolean",
    "comment" : "\n     * Check if this {@link OutputConfiguration} is equal to another {@link OutputConfiguration}.\n     *\n     * <p>Two output configurations are only equal if and only if the underlying surfaces, surface\n     * properties (width, height, format, dataspace) when the output configurations are created,\n     * and all other configuration parameters are equal. </p>\n     *\n     * @return {@code true} if the objects were equal, {@code false} otherwise\n     ",
    "links" : [ "android.hardware.camera2.params.OutputConfiguration" ]
  }, {
    "name" : "private static int getAndIncreaseMultiResolutionGroupId()",
    "returnType" : "int",
    "comment" : "\n     * Get and increase the next MultiResolution group id.\n     *\n     * If the ID reaches -1, skip it.\n     ",
    "links" : [ ]
  }, {
    "name" : "public int hashCode()",
    "returnType" : "int",
    "comment" : "\n     * {@inheritDoc}\n     ",
    "links" : [ ]
  } ],
  "methodNames" : [ "public void setMultiResolutionOutput()", "public void setDynamicRangeProfile(@DynamicRangeProfiles.Profile long profile)", "public long getDynamicRangeProfile()", "public void setColorSpace(@NonNull ColorSpace.Named colorSpace)", "public void clearColorSpace()", "public ColorSpace getColorSpace()", "public static Collection<OutputConfiguration> createInstancesForMultiResolutionOutput(@NonNull MultiResolutionImageReader multiResolutionImageReader)", "public static List<OutputConfiguration> createInstancesForMultiResolutionOutput(@NonNull Collection<MultiResolutionStreamInfo> streams, @Format int format)", "public static void setSurfacesForMultiResolutionOutput(@NonNull Collection<OutputConfiguration> outputConfigurations, @NonNull MultiResolutionImageReader multiResolutionImageReader)", "public void enableSurfaceSharing()", "public void setPhysicalCameraId(@Nullable String physicalCameraId)", "public void addSensorPixelModeUsed(@SensorPixelMode int sensorPixelModeUsed)", "public void removeSensorPixelModeUsed(@SensorPixelMode int sensorPixelModeUsed)", "public boolean isForPhysicalCamera()", "public boolean isDeferredConfiguration()", "public void addSurface(@NonNull Surface surface)", "public void removeSurface(@NonNull Surface surface)", "public void setStreamUseCase(@StreamUseCase long streamUseCase)", "public long getStreamUseCase()", "public void setTimestampBase(@TimestampBase int timestampBase)", "public int getTimestampBase()", "public void setMirrorMode(@MirrorMode int mirrorMode)", "public int getMirrorMode()", "public void setReadoutTimestampEnabled(boolean on)", "public boolean isReadoutTimestampEnabled()", "public int getMaxSharedSurfaceCount()", "public Surface getSurface()", "public List<Surface> getSurfaces()", "public int getRotation()", "public int getSurfaceGroupId()", "public Size getConfiguredSize()", "public String getPhysicalCameraId()", "public int describeContents()", "private static int[] convertIntegerToIntList(List<Integer> integerList)", "private static ArrayList<Integer> convertIntArrayToIntegerList(int[] intArray)", "public void writeToParcel(Parcel dest, int flags)", "public boolean equals(@Nullable Object obj)", "private static int getAndIncreaseMultiResolutionGroupId()", "public int hashCode()" ],
  "variableNames" : [ "ROTATION_0", "ROTATION_90", "ROTATION_180", "ROTATION_270", "SURFACE_GROUP_ID_NONE", "TIMESTAMP_BASE_DEFAULT", "TIMESTAMP_BASE_SENSOR", "TIMESTAMP_BASE_MONOTONIC", "TIMESTAMP_BASE_REALTIME", "TIMESTAMP_BASE_CHOREOGRAPHER_SYNCED", "TIMESTAMP_BASE_READOUT_SENSOR", "MIRROR_MODE_AUTO", "MIRROR_MODE_NONE", "MIRROR_MODE_H", "MIRROR_MODE_V", "SURFACE_TYPE_UNKNOWN", "SURFACE_TYPE_SURFACE_VIEW", "SURFACE_TYPE_SURFACE_TEXTURE", "SURFACE_TYPE_MEDIA_RECORDER", "SURFACE_TYPE_MEDIA_CODEC", "SURFACE_TYPE_IMAGE_READER", "MAX_SURFACES_COUNT", "CREATOR", "TAG", "sNextMultiResolutionGroupId", "mSurfaces", "mRotation", "mSurfaceGroupId", "mSurfaceType", "mConfiguredSize", "mConfiguredFormat", "mConfiguredDataspace", "mConfiguredGenerationId", "mIsDeferredConfig", "mIsShared", "mPhysicalCameraId", "mIsMultiResolution", "mSensorPixelModesUsed", "mDynamicRangeProfile", "mColorSpace", "mStreamUseCase", "mTimestampBase", "mMirrorMode", "mReadoutTimestampEnabled", "mIsReadoutSensorTimestampBase", "mUsage" ]
}